{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusicGenreClassification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhyatiMahendru/MusicGenreClassification/blob/master/MusicGenreClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "gz4XqyDOPKxW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Music Genre Classification: Rock v/s Hip-Hop"
      ]
    },
    {
      "metadata": {
        "id": "iEe-LLrVw7LB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#importing required dependencies and libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hxiXRhnsxCjz",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "68584c97-fa2a-44b0-b106-7452a52c6e10"
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5816fd8b-8700-458a-8f95-3f641f3aa270\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-5816fd8b-8700-458a-8f95-3f641f3aa270\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving echonest-metrics.json to echonest-metrics.json\n",
            "Saving fma-rock-vs-hiphop.csv to fma-rock-vs-hiphop (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a9By7kDAxGRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "4442cd6d-7461-4e91-c43d-3bd9cdc267fb"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "tracks = pd.read_csv(io.BytesIO(uploaded['fma-rock-vs-hiphop.csv']))\n",
        "echonest_metrics = pd.read_json(io.BytesIO(uploaded['echonest-metrics.json']))\n",
        "echo_tracks = pd.merge(echonest_metrics, tracks[[\"track_id\", \"genre_top\"]], on = \"track_id\")\n",
        "echo_tracks.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 4802 entries, 0 to 4801\n",
            "Data columns (total 10 columns):\n",
            "track_id            4802 non-null int64\n",
            "acousticness        4802 non-null float64\n",
            "danceability        4802 non-null float64\n",
            "energy              4802 non-null float64\n",
            "instrumentalness    4802 non-null float64\n",
            "liveness            4802 non-null float64\n",
            "speechiness         4802 non-null float64\n",
            "tempo               4802 non-null float64\n",
            "valence             4802 non-null float64\n",
            "genre_top           4802 non-null object\n",
            "dtypes: float64(8), int64(1), object(1)\n",
            "memory usage: 412.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xyvZkfIOxrJq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "66a73b04-6602-4eef-d460-b2e6ad71e343"
      },
      "cell_type": "code",
      "source": [
        "corr_metrics = echo_tracks.corr()\n",
        "corr_metrics.style.background_gradient()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row0_col0 {\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row0_col1 {\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row0_col2 {\n",
              "            background-color:  #d2d2e7;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row0_col3 {\n",
              "            background-color:  #b5c4df;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row0_col4 {\n",
              "            background-color:  #f5eef6;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row0_col5 {\n",
              "            background-color:  #e9e5f1;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row0_col6 {\n",
              "            background-color:  #d1d2e6;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row0_col7 {\n",
              "            background-color:  #e1dfed;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row0_col8 {\n",
              "            background-color:  #dedcec;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row1_col0 {\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row1_col1 {\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row1_col2 {\n",
              "            background-color:  #e0dded;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row1_col3 {\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row1_col4 {\n",
              "            background-color:  #97b7d7;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row1_col5 {\n",
              "            background-color:  #f3edf5;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row1_col6 {\n",
              "            background-color:  #b8c6e0;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row1_col7 {\n",
              "            background-color:  #e1dfed;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row1_col8 {\n",
              "            background-color:  #e2dfee;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row2_col0 {\n",
              "            background-color:  #bdc8e1;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row2_col1 {\n",
              "            background-color:  #d0d1e6;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row2_col2 {\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row2_col3 {\n",
              "            background-color:  #fbf3f9;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row2_col4 {\n",
              "            background-color:  #f3edf5;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row2_col5 {\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row2_col6 {\n",
              "            background-color:  #80aed2;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row2_col7 {\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row2_col8 {\n",
              "            background-color:  #529bc7;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row3_col0 {\n",
              "            background-color:  #a7bddb;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row3_col1 {\n",
              "            background-color:  #f5eff6;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row3_col2 {\n",
              "            background-color:  #fef6fa;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row3_col3 {\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row3_col4 {\n",
              "            background-color:  #c4cbe3;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row3_col5 {\n",
              "            background-color:  #dcdaeb;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row3_col6 {\n",
              "            background-color:  #dedcec;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row3_col7 {\n",
              "            background-color:  #adc1dd;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row3_col8 {\n",
              "            background-color:  #d9d8ea;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row4_col0 {\n",
              "            background-color:  #f4eef6;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row4_col1 {\n",
              "            background-color:  #97b7d7;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row4_col2 {\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row4_col3 {\n",
              "            background-color:  #d2d3e7;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row4_col4 {\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row4_col5 {\n",
              "            background-color:  #fdf5fa;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row4_col6 {\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row4_col7 {\n",
              "            background-color:  #d9d8ea;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row4_col8 {\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row5_col0 {\n",
              "            background-color:  #bdc8e1;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row5_col1 {\n",
              "            background-color:  #ced0e6;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row5_col2 {\n",
              "            background-color:  #ede8f3;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row5_col3 {\n",
              "            background-color:  #bdc8e1;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row5_col4 {\n",
              "            background-color:  #dbdaeb;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row5_col5 {\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row5_col6 {\n",
              "            background-color:  #c0c9e2;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row5_col7 {\n",
              "            background-color:  #dcdaeb;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row5_col8 {\n",
              "            background-color:  #e8e4f0;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row6_col0 {\n",
              "            background-color:  #d0d1e6;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row6_col1 {\n",
              "            background-color:  #b8c6e0;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row6_col2 {\n",
              "            background-color:  #93b5d6;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row6_col3 {\n",
              "            background-color:  #eae6f1;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row6_col4 {\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row6_col5 {\n",
              "            background-color:  #eae6f1;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row6_col6 {\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row6_col7 {\n",
              "            background-color:  #dbdaeb;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row6_col8 {\n",
              "            background-color:  #bfc9e1;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row7_col0 {\n",
              "            background-color:  #d0d1e6;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row7_col1 {\n",
              "            background-color:  #d0d1e6;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row7_col2 {\n",
              "            background-color:  #fef6fa;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row7_col3 {\n",
              "            background-color:  #a7bddb;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row7_col4 {\n",
              "            background-color:  #c5cce3;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row7_col5 {\n",
              "            background-color:  #f0eaf4;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row7_col6 {\n",
              "            background-color:  #c8cde4;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row7_col7 {\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row7_col8 {\n",
              "            background-color:  #d6d6e9;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row8_col0 {\n",
              "            background-color:  #c6cce3;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row8_col1 {\n",
              "            background-color:  #cdd0e5;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row8_col2 {\n",
              "            background-color:  #4c99c5;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row8_col3 {\n",
              "            background-color:  #d1d2e6;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row8_col4 {\n",
              "            background-color:  #efe9f3;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row8_col5 {\n",
              "            background-color:  #f7f0f7;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row8_col6 {\n",
              "            background-color:  #a5bddb;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row8_col7 {\n",
              "            background-color:  #d3d4e7;\n",
              "            color:  #000000;\n",
              "        }    #T_0156d1a8_65b5_11e9_9361_0242ac1c0002row8_col8 {\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }</style><table id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >track_id</th>        <th class=\"col_heading level0 col1\" >acousticness</th>        <th class=\"col_heading level0 col2\" >danceability</th>        <th class=\"col_heading level0 col3\" >energy</th>        <th class=\"col_heading level0 col4\" >instrumentalness</th>        <th class=\"col_heading level0 col5\" >liveness</th>        <th class=\"col_heading level0 col6\" >speechiness</th>        <th class=\"col_heading level0 col7\" >tempo</th>        <th class=\"col_heading level0 col8\" >valence</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >track_id</th>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row0_col0\" class=\"data row0 col0\" >1</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row0_col1\" class=\"data row0 col1\" >-0.372282</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row0_col2\" class=\"data row0 col2\" >0.0494541</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row0_col3\" class=\"data row0 col3\" >0.140703</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row0_col4\" class=\"data row0 col4\" >-0.275623</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row0_col5\" class=\"data row0 col5\" >0.0482307</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row0_col6\" class=\"data row0 col6\" >-0.0269951</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row0_col7\" class=\"data row0 col7\" >-0.0253918</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row0_col8\" class=\"data row0 col8\" >0.0100698</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >acousticness</th>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row1_col0\" class=\"data row1 col0\" >-0.372282</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row1_col1\" class=\"data row1 col1\" >1</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row1_col2\" class=\"data row1 col2\" >-0.0289537</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row1_col3\" class=\"data row1 col3\" >-0.281619</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row1_col4\" class=\"data row1 col4\" >0.19478</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row1_col5\" class=\"data row1 col5\" >-0.0199914</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row1_col6\" class=\"data row1 col6\" >0.072204</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row1_col7\" class=\"data row1 col7\" >-0.0263097</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row1_col8\" class=\"data row1 col8\" >-0.0138406</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >danceability</th>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row2_col0\" class=\"data row2 col0\" >0.0494541</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row2_col1\" class=\"data row2 col1\" >-0.0289537</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row2_col2\" class=\"data row2 col2\" >1</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row2_col3\" class=\"data row2 col3\" >-0.242032</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row2_col4\" class=\"data row2 col4\" >-0.255217</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row2_col5\" class=\"data row2 col5\" >-0.106584</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row2_col6\" class=\"data row2 col6\" >0.276206</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row2_col7\" class=\"data row2 col7\" >-0.242089</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row2_col8\" class=\"data row2 col8\" >0.473165</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >energy</th>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row3_col0\" class=\"data row3 col0\" >0.140703</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row3_col1\" class=\"data row3 col1\" >-0.281619</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row3_col2\" class=\"data row3 col2\" >-0.242032</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row3_col3\" class=\"data row3 col3\" >1</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row3_col4\" class=\"data row3 col4\" >0.0282377</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row3_col5\" class=\"data row3 col5\" >0.113331</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row3_col6\" class=\"data row3 col6\" >-0.109983</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row3_col7\" class=\"data row3 col7\" >0.195227</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row3_col8\" class=\"data row3 col8\" >0.0386027</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >instrumentalness</th>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row4_col0\" class=\"data row4 col0\" >-0.275623</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row4_col1\" class=\"data row4 col1\" >0.19478</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row4_col2\" class=\"data row4 col2\" >-0.255217</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row4_col3\" class=\"data row4 col3\" >0.0282377</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row4_col4\" class=\"data row4 col4\" >1</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row4_col5\" class=\"data row4 col5\" >-0.0910218</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row4_col6\" class=\"data row4 col6\" >-0.366762</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row4_col7\" class=\"data row4 col7\" >0.022215</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row4_col8\" class=\"data row4 col8\" >-0.219967</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >liveness</th>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row5_col0\" class=\"data row5 col0\" >0.0482307</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row5_col1\" class=\"data row5 col1\" >-0.0199914</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row5_col2\" class=\"data row5 col2\" >-0.106584</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row5_col3\" class=\"data row5 col3\" >0.113331</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row5_col4\" class=\"data row5 col4\" >-0.0910218</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row5_col5\" class=\"data row5 col5\" >1</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row5_col6\" class=\"data row5 col6\" >0.0411725</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row5_col7\" class=\"data row5 col7\" >0.00273169</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row5_col8\" class=\"data row5 col8\" >-0.0450931</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >speechiness</th>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row6_col0\" class=\"data row6 col0\" >-0.0269951</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row6_col1\" class=\"data row6 col1\" >0.072204</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row6_col2\" class=\"data row6 col2\" >0.276206</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row6_col3\" class=\"data row6 col3\" >-0.109983</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row6_col4\" class=\"data row6 col4\" >-0.366762</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row6_col5\" class=\"data row6 col5\" >0.0411725</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row6_col6\" class=\"data row6 col6\" >1</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row6_col7\" class=\"data row6 col7\" >0.00824055</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row6_col8\" class=\"data row6 col8\" >0.149894</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >tempo</th>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row7_col0\" class=\"data row7 col0\" >-0.0253918</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row7_col1\" class=\"data row7 col1\" >-0.0263097</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row7_col2\" class=\"data row7 col2\" >-0.242089</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row7_col3\" class=\"data row7 col3\" >0.195227</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row7_col4\" class=\"data row7 col4\" >0.022215</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row7_col5\" class=\"data row7 col5\" >0.00273169</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row7_col6\" class=\"data row7 col6\" >0.00824055</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row7_col7\" class=\"data row7 col7\" >1</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row7_col8\" class=\"data row7 col8\" >0.0522212</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >valence</th>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row8_col0\" class=\"data row8 col0\" >0.0100698</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row8_col1\" class=\"data row8 col1\" >-0.0138406</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row8_col2\" class=\"data row8 col2\" >0.473165</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row8_col3\" class=\"data row8 col3\" >0.0386027</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row8_col4\" class=\"data row8 col4\" >-0.219967</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row8_col5\" class=\"data row8 col5\" >-0.0450931</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row8_col6\" class=\"data row8 col6\" >0.149894</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row8_col7\" class=\"data row8 col7\" >0.0522212</td>\n",
              "                        <td id=\"T_0156d1a8_65b5_11e9_9361_0242ac1c0002row8_col8\" class=\"data row8 col8\" >1</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7ff0434c0390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "IPeLUYtEzdpQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "X = echo_tracks.drop(['track_id','genre_top'], axis = 1)\n",
        "Y = echo_tracks.loc[:, 'genre_top']\n",
        "trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.33, random_state = 33, stratify = Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q28lrBwZz3VF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "scaler = StandardScaler()\n",
        "trainX = scaler.fit_transform(trainX)\n",
        "testX = scaler.transform(testX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K0-olbGUz7-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f1dfe30c-255a-43ce-907b-91a701aac2a3"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "clf1 = LogisticRegression(random_state = 0, max_iter = 800)\n",
        "clf1.fit(trainX, trainY)\n",
        "pred1 = clf1.predict(testX)\n",
        "print(accuracy_score(testY, pred1))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9015772870662461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "uRdB7Quy0quo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1577ef5f-280c-4b4a-842c-7de470ed8b29"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "clf2 = DecisionTreeClassifier()\n",
        "clf2.fit(trainX, trainY)\n",
        "pred2 = clf2.predict(testX)\n",
        "print(accuracy_score(testY, pred2))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8782334384858044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j0CkZJ8q0unG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4fd046f4-a256-4ad9-cbb0-42a09bac8699"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "clf5 = KNeighborsClassifier(n_neighbors = 10)\n",
        "clf5.fit(trainX, trainY)\n",
        "pred5 = clf5.predict(testX)\n",
        "print(accuracy_score(testY, pred5))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9141955835962146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P9IZyc-1068h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e545be30-ba9d-44ad-b239-9f71874084a9"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "clf6 = GaussianNB()\n",
        "clf6.fit(trainX, trainY)\n",
        "pred6 = clf6.predict(testX)\n",
        "print(accuracy_score(testY, pred6))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8958990536277602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xty387Wi1SG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e42402c-80cb-4bd8-88e0-0b00245d57d9"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "clf3 = SVC(gamma='scale', decision_function_shape='ovo')\n",
        "clf3.fit(trainX, trainY)\n",
        "pred3 = clf3.predict(testX)\n",
        "print(accuracy_score(testY, pred3))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9211356466876972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hzu3kN0Q1WYI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "np.random.seed(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6K5izl5W1Zbd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(trainY)\n",
        "encoded_Y = encoder.transform(trainY)\n",
        "encoded_test_Y = encoder.transform(testY)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)\n",
        "dummy_test_y = np_utils.to_categorical(encoded_test_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CjTc5zz81iVa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(256, input_shape=(8,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# model.add(Dense(300))\n",
        "# model.add(Activation('sigmoid'))\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# model.add(Dense(256))\n",
        "# model.add(Activation('sigmoid'))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x4LIfWO51nem",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 27322
        },
        "outputId": "5804452c-80d2-4b11-d5ce-d157dde1d5b3"
      },
      "cell_type": "code",
      "source": [
        "model.fit(trainX, dummy_y, epochs=800, batch_size = 32, validation_data=(testX, dummy_test_y))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 3217 samples, validate on 1585 samples\n",
            "Epoch 1/800\n",
            "3217/3217 [==============================] - 1s 227us/step - loss: 0.3750 - acc: 0.8517 - val_loss: 0.2524 - val_acc: 0.9066\n",
            "Epoch 2/800\n",
            "3217/3217 [==============================] - 0s 120us/step - loss: 0.2846 - acc: 0.8878 - val_loss: 0.2286 - val_acc: 0.9123\n",
            "Epoch 3/800\n",
            "3217/3217 [==============================] - 0s 120us/step - loss: 0.2650 - acc: 0.8956 - val_loss: 0.2279 - val_acc: 0.9123\n",
            "Epoch 4/800\n",
            "3217/3217 [==============================] - 0s 118us/step - loss: 0.2410 - acc: 0.9077 - val_loss: 0.2116 - val_acc: 0.9180\n",
            "Epoch 5/800\n",
            "3217/3217 [==============================] - 0s 116us/step - loss: 0.2470 - acc: 0.9036 - val_loss: 0.2048 - val_acc: 0.9218\n",
            "Epoch 6/800\n",
            "3217/3217 [==============================] - 0s 116us/step - loss: 0.2372 - acc: 0.9123 - val_loss: 0.2051 - val_acc: 0.9167\n",
            "Epoch 7/800\n",
            "3217/3217 [==============================] - 0s 117us/step - loss: 0.2288 - acc: 0.9111 - val_loss: 0.2021 - val_acc: 0.9205\n",
            "Epoch 8/800\n",
            "3217/3217 [==============================] - 0s 114us/step - loss: 0.2277 - acc: 0.9142 - val_loss: 0.2094 - val_acc: 0.9218\n",
            "Epoch 9/800\n",
            "3217/3217 [==============================] - 0s 115us/step - loss: 0.2237 - acc: 0.9182 - val_loss: 0.1989 - val_acc: 0.9256\n",
            "Epoch 10/800\n",
            "3217/3217 [==============================] - 0s 112us/step - loss: 0.2222 - acc: 0.9117 - val_loss: 0.1979 - val_acc: 0.9211\n",
            "Epoch 11/800\n",
            "3217/3217 [==============================] - 0s 114us/step - loss: 0.2119 - acc: 0.9154 - val_loss: 0.2006 - val_acc: 0.9211\n",
            "Epoch 12/800\n",
            "3217/3217 [==============================] - 0s 114us/step - loss: 0.2177 - acc: 0.9151 - val_loss: 0.1977 - val_acc: 0.9237\n",
            "Epoch 13/800\n",
            "3217/3217 [==============================] - 0s 115us/step - loss: 0.2103 - acc: 0.9198 - val_loss: 0.1919 - val_acc: 0.9262\n",
            "Epoch 14/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.2094 - acc: 0.9182 - val_loss: 0.1925 - val_acc: 0.9243\n",
            "Epoch 15/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.2079 - acc: 0.9195 - val_loss: 0.1946 - val_acc: 0.9268\n",
            "Epoch 16/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.2091 - acc: 0.9176 - val_loss: 0.1968 - val_acc: 0.9218\n",
            "Epoch 17/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.2024 - acc: 0.9220 - val_loss: 0.1907 - val_acc: 0.9249\n",
            "Epoch 18/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.2004 - acc: 0.9251 - val_loss: 0.1890 - val_acc: 0.9262\n",
            "Epoch 19/800\n",
            "3217/3217 [==============================] - 0s 111us/step - loss: 0.2015 - acc: 0.9235 - val_loss: 0.1910 - val_acc: 0.9287\n",
            "Epoch 20/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.2016 - acc: 0.9238 - val_loss: 0.1876 - val_acc: 0.9262\n",
            "Epoch 21/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.2010 - acc: 0.9223 - val_loss: 0.1938 - val_acc: 0.9243\n",
            "Epoch 22/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.2070 - acc: 0.9198 - val_loss: 0.1910 - val_acc: 0.9281\n",
            "Epoch 23/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1970 - acc: 0.9248 - val_loss: 0.2001 - val_acc: 0.9237\n",
            "Epoch 24/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1977 - acc: 0.9220 - val_loss: 0.1855 - val_acc: 0.9249\n",
            "Epoch 25/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1952 - acc: 0.9229 - val_loss: 0.1939 - val_acc: 0.9249\n",
            "Epoch 26/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1971 - acc: 0.9263 - val_loss: 0.1889 - val_acc: 0.9268\n",
            "Epoch 27/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1940 - acc: 0.9254 - val_loss: 0.2009 - val_acc: 0.9230\n",
            "Epoch 28/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1934 - acc: 0.9263 - val_loss: 0.1863 - val_acc: 0.9274\n",
            "Epoch 29/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1914 - acc: 0.9266 - val_loss: 0.1858 - val_acc: 0.9281\n",
            "Epoch 30/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1913 - acc: 0.9260 - val_loss: 0.1893 - val_acc: 0.9281\n",
            "Epoch 31/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1870 - acc: 0.9288 - val_loss: 0.1884 - val_acc: 0.9287\n",
            "Epoch 32/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1887 - acc: 0.9266 - val_loss: 0.1868 - val_acc: 0.9293\n",
            "Epoch 33/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1890 - acc: 0.9279 - val_loss: 0.1892 - val_acc: 0.9274\n",
            "Epoch 34/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1864 - acc: 0.9288 - val_loss: 0.1950 - val_acc: 0.9274\n",
            "Epoch 35/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1897 - acc: 0.9273 - val_loss: 0.1848 - val_acc: 0.9293\n",
            "Epoch 36/800\n",
            "3217/3217 [==============================] - 0s 108us/step - loss: 0.1814 - acc: 0.9304 - val_loss: 0.1887 - val_acc: 0.9287\n",
            "Epoch 37/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1858 - acc: 0.9260 - val_loss: 0.1894 - val_acc: 0.9262\n",
            "Epoch 38/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1790 - acc: 0.9304 - val_loss: 0.1852 - val_acc: 0.9256\n",
            "Epoch 39/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1799 - acc: 0.9307 - val_loss: 0.1951 - val_acc: 0.9274\n",
            "Epoch 40/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1846 - acc: 0.9273 - val_loss: 0.1898 - val_acc: 0.9274\n",
            "Epoch 41/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1805 - acc: 0.9294 - val_loss: 0.1857 - val_acc: 0.9306\n",
            "Epoch 42/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1848 - acc: 0.9319 - val_loss: 0.1871 - val_acc: 0.9312\n",
            "Epoch 43/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.1762 - acc: 0.9338 - val_loss: 0.1923 - val_acc: 0.9293\n",
            "Epoch 44/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1752 - acc: 0.9322 - val_loss: 0.1880 - val_acc: 0.9287\n",
            "Epoch 45/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1748 - acc: 0.9329 - val_loss: 0.1896 - val_acc: 0.9300\n",
            "Epoch 46/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1808 - acc: 0.9316 - val_loss: 0.1887 - val_acc: 0.9300\n",
            "Epoch 47/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1745 - acc: 0.9304 - val_loss: 0.1890 - val_acc: 0.9268\n",
            "Epoch 48/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1788 - acc: 0.9301 - val_loss: 0.1852 - val_acc: 0.9325\n",
            "Epoch 49/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1754 - acc: 0.9307 - val_loss: 0.1886 - val_acc: 0.9325\n",
            "Epoch 50/800\n",
            "3217/3217 [==============================] - 0s 113us/step - loss: 0.1765 - acc: 0.9319 - val_loss: 0.1894 - val_acc: 0.9287\n",
            "Epoch 51/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.1674 - acc: 0.9347 - val_loss: 0.1877 - val_acc: 0.9287\n",
            "Epoch 52/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1695 - acc: 0.9341 - val_loss: 0.1882 - val_acc: 0.9312\n",
            "Epoch 53/800\n",
            "3217/3217 [==============================] - 0s 108us/step - loss: 0.1722 - acc: 0.9353 - val_loss: 0.1928 - val_acc: 0.9281\n",
            "Epoch 54/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.1694 - acc: 0.9357 - val_loss: 0.1880 - val_acc: 0.9338\n",
            "Epoch 55/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1689 - acc: 0.9347 - val_loss: 0.1866 - val_acc: 0.9319\n",
            "Epoch 56/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1677 - acc: 0.9350 - val_loss: 0.1873 - val_acc: 0.9325\n",
            "Epoch 57/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1647 - acc: 0.9366 - val_loss: 0.1903 - val_acc: 0.9300\n",
            "Epoch 58/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1720 - acc: 0.9347 - val_loss: 0.1868 - val_acc: 0.9312\n",
            "Epoch 59/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1661 - acc: 0.9385 - val_loss: 0.1860 - val_acc: 0.9287\n",
            "Epoch 60/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1664 - acc: 0.9372 - val_loss: 0.1984 - val_acc: 0.9281\n",
            "Epoch 61/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1617 - acc: 0.9388 - val_loss: 0.1927 - val_acc: 0.9306\n",
            "Epoch 62/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1592 - acc: 0.9353 - val_loss: 0.1910 - val_acc: 0.9256\n",
            "Epoch 63/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.1636 - acc: 0.9385 - val_loss: 0.1906 - val_acc: 0.9312\n",
            "Epoch 64/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1627 - acc: 0.9357 - val_loss: 0.1905 - val_acc: 0.9319\n",
            "Epoch 65/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1698 - acc: 0.9353 - val_loss: 0.1872 - val_acc: 0.9331\n",
            "Epoch 66/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1600 - acc: 0.9394 - val_loss: 0.1868 - val_acc: 0.9306\n",
            "Epoch 67/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1570 - acc: 0.9388 - val_loss: 0.1905 - val_acc: 0.9300\n",
            "Epoch 68/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1621 - acc: 0.9372 - val_loss: 0.1944 - val_acc: 0.9300\n",
            "Epoch 69/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1629 - acc: 0.9366 - val_loss: 0.1934 - val_acc: 0.9293\n",
            "Epoch 70/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1616 - acc: 0.9381 - val_loss: 0.1871 - val_acc: 0.9300\n",
            "Epoch 71/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1597 - acc: 0.9391 - val_loss: 0.1940 - val_acc: 0.9300\n",
            "Epoch 72/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1562 - acc: 0.9409 - val_loss: 0.2010 - val_acc: 0.9262\n",
            "Epoch 73/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1587 - acc: 0.9403 - val_loss: 0.1917 - val_acc: 0.9312\n",
            "Epoch 74/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1588 - acc: 0.9360 - val_loss: 0.1953 - val_acc: 0.9312\n",
            "Epoch 75/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1543 - acc: 0.9419 - val_loss: 0.1924 - val_acc: 0.9312\n",
            "Epoch 76/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1522 - acc: 0.9428 - val_loss: 0.2007 - val_acc: 0.9281\n",
            "Epoch 77/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1525 - acc: 0.9406 - val_loss: 0.1955 - val_acc: 0.9268\n",
            "Epoch 78/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1552 - acc: 0.9406 - val_loss: 0.1945 - val_acc: 0.9306\n",
            "Epoch 79/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1555 - acc: 0.9416 - val_loss: 0.1907 - val_acc: 0.9312\n",
            "Epoch 80/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1570 - acc: 0.9431 - val_loss: 0.1918 - val_acc: 0.9281\n",
            "Epoch 81/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.1505 - acc: 0.9406 - val_loss: 0.1975 - val_acc: 0.9243\n",
            "Epoch 82/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.1447 - acc: 0.9440 - val_loss: 0.2008 - val_acc: 0.9287\n",
            "Epoch 83/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1573 - acc: 0.9391 - val_loss: 0.1966 - val_acc: 0.9356\n",
            "Epoch 84/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1493 - acc: 0.9409 - val_loss: 0.1951 - val_acc: 0.9331\n",
            "Epoch 85/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1539 - acc: 0.9450 - val_loss: 0.1921 - val_acc: 0.9325\n",
            "Epoch 86/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1528 - acc: 0.9406 - val_loss: 0.1959 - val_acc: 0.9281\n",
            "Epoch 87/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1495 - acc: 0.9425 - val_loss: 0.1925 - val_acc: 0.9262\n",
            "Epoch 88/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1503 - acc: 0.9431 - val_loss: 0.2050 - val_acc: 0.9237\n",
            "Epoch 89/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1477 - acc: 0.9428 - val_loss: 0.1941 - val_acc: 0.9274\n",
            "Epoch 90/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1499 - acc: 0.9431 - val_loss: 0.2129 - val_acc: 0.9268\n",
            "Epoch 91/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1430 - acc: 0.9475 - val_loss: 0.1979 - val_acc: 0.9281\n",
            "Epoch 92/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1458 - acc: 0.9425 - val_loss: 0.1929 - val_acc: 0.9262\n",
            "Epoch 93/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1519 - acc: 0.9409 - val_loss: 0.2060 - val_acc: 0.9268\n",
            "Epoch 94/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1545 - acc: 0.9412 - val_loss: 0.2036 - val_acc: 0.9325\n",
            "Epoch 95/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1459 - acc: 0.9428 - val_loss: 0.1986 - val_acc: 0.9268\n",
            "Epoch 96/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1482 - acc: 0.9412 - val_loss: 0.1998 - val_acc: 0.9281\n",
            "Epoch 97/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1443 - acc: 0.9419 - val_loss: 0.1974 - val_acc: 0.9293\n",
            "Epoch 98/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1451 - acc: 0.9440 - val_loss: 0.2029 - val_acc: 0.9274\n",
            "Epoch 99/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1423 - acc: 0.9431 - val_loss: 0.1964 - val_acc: 0.9262\n",
            "Epoch 100/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1421 - acc: 0.9456 - val_loss: 0.2054 - val_acc: 0.9262\n",
            "Epoch 101/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1386 - acc: 0.9447 - val_loss: 0.2017 - val_acc: 0.9300\n",
            "Epoch 102/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1486 - acc: 0.9431 - val_loss: 0.1990 - val_acc: 0.9268\n",
            "Epoch 103/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1453 - acc: 0.9409 - val_loss: 0.2081 - val_acc: 0.9237\n",
            "Epoch 104/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1428 - acc: 0.9478 - val_loss: 0.1993 - val_acc: 0.9268\n",
            "Epoch 105/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1354 - acc: 0.9465 - val_loss: 0.2035 - val_acc: 0.9268\n",
            "Epoch 106/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.1388 - acc: 0.9459 - val_loss: 0.1994 - val_acc: 0.9293\n",
            "Epoch 107/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1334 - acc: 0.9468 - val_loss: 0.2075 - val_acc: 0.9312\n",
            "Epoch 108/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1344 - acc: 0.9500 - val_loss: 0.2180 - val_acc: 0.9256\n",
            "Epoch 109/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1406 - acc: 0.9478 - val_loss: 0.2119 - val_acc: 0.9268\n",
            "Epoch 110/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1387 - acc: 0.9475 - val_loss: 0.2016 - val_acc: 0.9274\n",
            "Epoch 111/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1333 - acc: 0.9496 - val_loss: 0.2024 - val_acc: 0.9293\n",
            "Epoch 112/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1409 - acc: 0.9428 - val_loss: 0.2092 - val_acc: 0.9268\n",
            "Epoch 113/800\n",
            "3217/3217 [==============================] - 0s 113us/step - loss: 0.1371 - acc: 0.9465 - val_loss: 0.2004 - val_acc: 0.9287\n",
            "Epoch 114/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1448 - acc: 0.9456 - val_loss: 0.2008 - val_acc: 0.9256\n",
            "Epoch 115/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1406 - acc: 0.9459 - val_loss: 0.2041 - val_acc: 0.9268\n",
            "Epoch 116/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1313 - acc: 0.9515 - val_loss: 0.2143 - val_acc: 0.9256\n",
            "Epoch 117/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1358 - acc: 0.9484 - val_loss: 0.2178 - val_acc: 0.9249\n",
            "Epoch 118/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1384 - acc: 0.9459 - val_loss: 0.2068 - val_acc: 0.9249\n",
            "Epoch 119/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1302 - acc: 0.9487 - val_loss: 0.2080 - val_acc: 0.9274\n",
            "Epoch 120/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1306 - acc: 0.9518 - val_loss: 0.2082 - val_acc: 0.9281\n",
            "Epoch 121/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1317 - acc: 0.9459 - val_loss: 0.2087 - val_acc: 0.9312\n",
            "Epoch 122/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1346 - acc: 0.9456 - val_loss: 0.2077 - val_acc: 0.9274\n",
            "Epoch 123/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1274 - acc: 0.9512 - val_loss: 0.2075 - val_acc: 0.9262\n",
            "Epoch 124/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1304 - acc: 0.9518 - val_loss: 0.2149 - val_acc: 0.9256\n",
            "Epoch 125/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1296 - acc: 0.9450 - val_loss: 0.2110 - val_acc: 0.9293\n",
            "Epoch 126/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1338 - acc: 0.9462 - val_loss: 0.2138 - val_acc: 0.9274\n",
            "Epoch 127/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1257 - acc: 0.9537 - val_loss: 0.2068 - val_acc: 0.9262\n",
            "Epoch 128/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1344 - acc: 0.9500 - val_loss: 0.2113 - val_acc: 0.9312\n",
            "Epoch 129/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1293 - acc: 0.9481 - val_loss: 0.2162 - val_acc: 0.9287\n",
            "Epoch 130/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1227 - acc: 0.9496 - val_loss: 0.2122 - val_acc: 0.9287\n",
            "Epoch 131/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1257 - acc: 0.9506 - val_loss: 0.2263 - val_acc: 0.9249\n",
            "Epoch 132/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1277 - acc: 0.9496 - val_loss: 0.2146 - val_acc: 0.9243\n",
            "Epoch 133/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1247 - acc: 0.9503 - val_loss: 0.2182 - val_acc: 0.9268\n",
            "Epoch 134/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1286 - acc: 0.9500 - val_loss: 0.2197 - val_acc: 0.9237\n",
            "Epoch 135/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.1236 - acc: 0.9534 - val_loss: 0.2221 - val_acc: 0.9243\n",
            "Epoch 136/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.1231 - acc: 0.9537 - val_loss: 0.2165 - val_acc: 0.9262\n",
            "Epoch 137/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1223 - acc: 0.9515 - val_loss: 0.2229 - val_acc: 0.9243\n",
            "Epoch 138/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1221 - acc: 0.9534 - val_loss: 0.2115 - val_acc: 0.9281\n",
            "Epoch 139/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1218 - acc: 0.9528 - val_loss: 0.2169 - val_acc: 0.9256\n",
            "Epoch 140/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1282 - acc: 0.9500 - val_loss: 0.2181 - val_acc: 0.9268\n",
            "Epoch 141/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1219 - acc: 0.9534 - val_loss: 0.2247 - val_acc: 0.9256\n",
            "Epoch 142/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1288 - acc: 0.9518 - val_loss: 0.2185 - val_acc: 0.9262\n",
            "Epoch 143/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1210 - acc: 0.9543 - val_loss: 0.2269 - val_acc: 0.9249\n",
            "Epoch 144/800\n",
            "3217/3217 [==============================] - 0s 112us/step - loss: 0.1184 - acc: 0.9546 - val_loss: 0.2206 - val_acc: 0.9218\n",
            "Epoch 145/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1197 - acc: 0.9528 - val_loss: 0.2202 - val_acc: 0.9237\n",
            "Epoch 146/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1202 - acc: 0.9540 - val_loss: 0.2264 - val_acc: 0.9256\n",
            "Epoch 147/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1189 - acc: 0.9537 - val_loss: 0.2181 - val_acc: 0.9249\n",
            "Epoch 148/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1177 - acc: 0.9515 - val_loss: 0.2215 - val_acc: 0.9237\n",
            "Epoch 149/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1179 - acc: 0.9512 - val_loss: 0.2275 - val_acc: 0.9249\n",
            "Epoch 150/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1221 - acc: 0.9506 - val_loss: 0.2245 - val_acc: 0.9199\n",
            "Epoch 151/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1134 - acc: 0.9587 - val_loss: 0.2251 - val_acc: 0.9230\n",
            "Epoch 152/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1217 - acc: 0.9559 - val_loss: 0.2205 - val_acc: 0.9249\n",
            "Epoch 153/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1141 - acc: 0.9596 - val_loss: 0.2271 - val_acc: 0.9237\n",
            "Epoch 154/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1160 - acc: 0.9528 - val_loss: 0.2233 - val_acc: 0.9256\n",
            "Epoch 155/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1130 - acc: 0.9562 - val_loss: 0.2292 - val_acc: 0.9224\n",
            "Epoch 156/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1174 - acc: 0.9546 - val_loss: 0.2284 - val_acc: 0.9249\n",
            "Epoch 157/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1142 - acc: 0.9565 - val_loss: 0.2299 - val_acc: 0.9237\n",
            "Epoch 158/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1079 - acc: 0.9593 - val_loss: 0.2346 - val_acc: 0.9224\n",
            "Epoch 159/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1128 - acc: 0.9546 - val_loss: 0.2414 - val_acc: 0.9230\n",
            "Epoch 160/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1150 - acc: 0.9540 - val_loss: 0.2339 - val_acc: 0.9237\n",
            "Epoch 161/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.1097 - acc: 0.9562 - val_loss: 0.2388 - val_acc: 0.9256\n",
            "Epoch 162/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1121 - acc: 0.9583 - val_loss: 0.2317 - val_acc: 0.9268\n",
            "Epoch 163/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1118 - acc: 0.9562 - val_loss: 0.2424 - val_acc: 0.9224\n",
            "Epoch 164/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1103 - acc: 0.9568 - val_loss: 0.2317 - val_acc: 0.9230\n",
            "Epoch 165/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1109 - acc: 0.9555 - val_loss: 0.2354 - val_acc: 0.9224\n",
            "Epoch 166/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1096 - acc: 0.9568 - val_loss: 0.2430 - val_acc: 0.9224\n",
            "Epoch 167/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1090 - acc: 0.9534 - val_loss: 0.2454 - val_acc: 0.9224\n",
            "Epoch 168/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1169 - acc: 0.9587 - val_loss: 0.2392 - val_acc: 0.9230\n",
            "Epoch 169/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1101 - acc: 0.9568 - val_loss: 0.2427 - val_acc: 0.9230\n",
            "Epoch 170/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1110 - acc: 0.9555 - val_loss: 0.2425 - val_acc: 0.9256\n",
            "Epoch 171/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1122 - acc: 0.9546 - val_loss: 0.2437 - val_acc: 0.9243\n",
            "Epoch 172/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1031 - acc: 0.9618 - val_loss: 0.2419 - val_acc: 0.9218\n",
            "Epoch 173/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1035 - acc: 0.9593 - val_loss: 0.2374 - val_acc: 0.9205\n",
            "Epoch 174/800\n",
            "3217/3217 [==============================] - 0s 111us/step - loss: 0.1031 - acc: 0.9568 - val_loss: 0.2380 - val_acc: 0.9230\n",
            "Epoch 175/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.1062 - acc: 0.9546 - val_loss: 0.2459 - val_acc: 0.9211\n",
            "Epoch 176/800\n",
            "3217/3217 [==============================] - 0s 108us/step - loss: 0.1057 - acc: 0.9602 - val_loss: 0.2513 - val_acc: 0.9237\n",
            "Epoch 177/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1067 - acc: 0.9587 - val_loss: 0.2487 - val_acc: 0.9218\n",
            "Epoch 178/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1001 - acc: 0.9630 - val_loss: 0.2476 - val_acc: 0.9281\n",
            "Epoch 179/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1058 - acc: 0.9555 - val_loss: 0.2542 - val_acc: 0.9256\n",
            "Epoch 180/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1046 - acc: 0.9574 - val_loss: 0.2532 - val_acc: 0.9256\n",
            "Epoch 181/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1019 - acc: 0.9599 - val_loss: 0.2633 - val_acc: 0.9243\n",
            "Epoch 182/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1009 - acc: 0.9605 - val_loss: 0.2562 - val_acc: 0.9211\n",
            "Epoch 183/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1026 - acc: 0.9627 - val_loss: 0.2468 - val_acc: 0.9256\n",
            "Epoch 184/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1076 - acc: 0.9565 - val_loss: 0.2525 - val_acc: 0.9268\n",
            "Epoch 185/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1042 - acc: 0.9568 - val_loss: 0.2533 - val_acc: 0.9218\n",
            "Epoch 186/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1084 - acc: 0.9549 - val_loss: 0.2474 - val_acc: 0.9249\n",
            "Epoch 187/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1075 - acc: 0.9599 - val_loss: 0.2446 - val_acc: 0.9192\n",
            "Epoch 188/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1031 - acc: 0.9571 - val_loss: 0.2436 - val_acc: 0.9224\n",
            "Epoch 189/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0972 - acc: 0.9624 - val_loss: 0.2558 - val_acc: 0.9224\n",
            "Epoch 190/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0960 - acc: 0.9621 - val_loss: 0.2566 - val_acc: 0.9237\n",
            "Epoch 191/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1007 - acc: 0.9605 - val_loss: 0.2693 - val_acc: 0.9211\n",
            "Epoch 192/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0955 - acc: 0.9639 - val_loss: 0.2650 - val_acc: 0.9230\n",
            "Epoch 193/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0992 - acc: 0.9587 - val_loss: 0.2538 - val_acc: 0.9224\n",
            "Epoch 194/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0993 - acc: 0.9605 - val_loss: 0.2584 - val_acc: 0.9224\n",
            "Epoch 195/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1023 - acc: 0.9599 - val_loss: 0.2642 - val_acc: 0.9230\n",
            "Epoch 196/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1018 - acc: 0.9602 - val_loss: 0.2580 - val_acc: 0.9230\n",
            "Epoch 197/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0952 - acc: 0.9608 - val_loss: 0.2628 - val_acc: 0.9174\n",
            "Epoch 198/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1002 - acc: 0.9611 - val_loss: 0.2579 - val_acc: 0.9230\n",
            "Epoch 199/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0890 - acc: 0.9649 - val_loss: 0.2623 - val_acc: 0.9186\n",
            "Epoch 200/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1003 - acc: 0.9611 - val_loss: 0.2586 - val_acc: 0.9186\n",
            "Epoch 201/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1003 - acc: 0.9580 - val_loss: 0.2697 - val_acc: 0.9268\n",
            "Epoch 202/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0971 - acc: 0.9655 - val_loss: 0.2511 - val_acc: 0.9218\n",
            "Epoch 203/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0926 - acc: 0.9646 - val_loss: 0.2684 - val_acc: 0.9256\n",
            "Epoch 204/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0980 - acc: 0.9615 - val_loss: 0.2606 - val_acc: 0.9205\n",
            "Epoch 205/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0980 - acc: 0.9574 - val_loss: 0.2572 - val_acc: 0.9237\n",
            "Epoch 206/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0931 - acc: 0.9649 - val_loss: 0.2820 - val_acc: 0.9249\n",
            "Epoch 207/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0996 - acc: 0.9643 - val_loss: 0.2527 - val_acc: 0.9256\n",
            "Epoch 208/800\n",
            "3217/3217 [==============================] - 0s 111us/step - loss: 0.0850 - acc: 0.9633 - val_loss: 0.2612 - val_acc: 0.9243\n",
            "Epoch 209/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0961 - acc: 0.9627 - val_loss: 0.2516 - val_acc: 0.9243\n",
            "Epoch 210/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0965 - acc: 0.9621 - val_loss: 0.2634 - val_acc: 0.9249\n",
            "Epoch 211/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0983 - acc: 0.9587 - val_loss: 0.2544 - val_acc: 0.9218\n",
            "Epoch 212/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0954 - acc: 0.9627 - val_loss: 0.2549 - val_acc: 0.9243\n",
            "Epoch 213/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.0946 - acc: 0.9615 - val_loss: 0.2645 - val_acc: 0.9218\n",
            "Epoch 214/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0900 - acc: 0.9655 - val_loss: 0.2731 - val_acc: 0.9174\n",
            "Epoch 215/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0902 - acc: 0.9611 - val_loss: 0.2756 - val_acc: 0.9205\n",
            "Epoch 216/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0923 - acc: 0.9618 - val_loss: 0.2740 - val_acc: 0.9211\n",
            "Epoch 217/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0876 - acc: 0.9664 - val_loss: 0.2823 - val_acc: 0.9211\n",
            "Epoch 218/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0895 - acc: 0.9655 - val_loss: 0.2751 - val_acc: 0.9218\n",
            "Epoch 219/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0908 - acc: 0.9621 - val_loss: 0.2584 - val_acc: 0.9256\n",
            "Epoch 220/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0875 - acc: 0.9643 - val_loss: 0.2678 - val_acc: 0.9262\n",
            "Epoch 221/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0922 - acc: 0.9608 - val_loss: 0.2692 - val_acc: 0.9268\n",
            "Epoch 222/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0835 - acc: 0.9683 - val_loss: 0.2753 - val_acc: 0.9249\n",
            "Epoch 223/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0871 - acc: 0.9671 - val_loss: 0.2760 - val_acc: 0.9237\n",
            "Epoch 224/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0907 - acc: 0.9633 - val_loss: 0.2782 - val_acc: 0.9224\n",
            "Epoch 225/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0903 - acc: 0.9618 - val_loss: 0.2744 - val_acc: 0.9243\n",
            "Epoch 226/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0824 - acc: 0.9643 - val_loss: 0.2759 - val_acc: 0.9268\n",
            "Epoch 227/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0911 - acc: 0.9674 - val_loss: 0.2683 - val_acc: 0.9224\n",
            "Epoch 228/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0833 - acc: 0.9683 - val_loss: 0.2845 - val_acc: 0.9218\n",
            "Epoch 229/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0893 - acc: 0.9624 - val_loss: 0.2862 - val_acc: 0.9199\n",
            "Epoch 230/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0870 - acc: 0.9671 - val_loss: 0.2755 - val_acc: 0.9243\n",
            "Epoch 231/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0840 - acc: 0.9689 - val_loss: 0.2708 - val_acc: 0.9224\n",
            "Epoch 232/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0904 - acc: 0.9633 - val_loss: 0.3023 - val_acc: 0.9224\n",
            "Epoch 233/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0886 - acc: 0.9655 - val_loss: 0.2828 - val_acc: 0.9186\n",
            "Epoch 234/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0858 - acc: 0.9677 - val_loss: 0.2858 - val_acc: 0.9224\n",
            "Epoch 235/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0877 - acc: 0.9646 - val_loss: 0.2831 - val_acc: 0.9205\n",
            "Epoch 236/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0816 - acc: 0.9667 - val_loss: 0.2806 - val_acc: 0.9218\n",
            "Epoch 237/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0827 - acc: 0.9671 - val_loss: 0.3007 - val_acc: 0.9192\n",
            "Epoch 238/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0858 - acc: 0.9664 - val_loss: 0.2856 - val_acc: 0.9211\n",
            "Epoch 239/800\n",
            "3217/3217 [==============================] - 0s 110us/step - loss: 0.0796 - acc: 0.9661 - val_loss: 0.2871 - val_acc: 0.9224\n",
            "Epoch 240/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0878 - acc: 0.9674 - val_loss: 0.2834 - val_acc: 0.9205\n",
            "Epoch 241/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0805 - acc: 0.9658 - val_loss: 0.2829 - val_acc: 0.9211\n",
            "Epoch 242/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0761 - acc: 0.9705 - val_loss: 0.2912 - val_acc: 0.9205\n",
            "Epoch 243/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0818 - acc: 0.9695 - val_loss: 0.2863 - val_acc: 0.9230\n",
            "Epoch 244/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0894 - acc: 0.9655 - val_loss: 0.2859 - val_acc: 0.9218\n",
            "Epoch 245/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0805 - acc: 0.9646 - val_loss: 0.2888 - val_acc: 0.9237\n",
            "Epoch 246/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0783 - acc: 0.9686 - val_loss: 0.2950 - val_acc: 0.9199\n",
            "Epoch 247/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0836 - acc: 0.9661 - val_loss: 0.2889 - val_acc: 0.9256\n",
            "Epoch 248/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0756 - acc: 0.9692 - val_loss: 0.2905 - val_acc: 0.9243\n",
            "Epoch 249/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.0815 - acc: 0.9695 - val_loss: 0.3068 - val_acc: 0.9174\n",
            "Epoch 250/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0825 - acc: 0.9677 - val_loss: 0.2891 - val_acc: 0.9224\n",
            "Epoch 251/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0729 - acc: 0.9717 - val_loss: 0.3084 - val_acc: 0.9205\n",
            "Epoch 252/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0844 - acc: 0.9658 - val_loss: 0.3009 - val_acc: 0.9230\n",
            "Epoch 253/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0758 - acc: 0.9702 - val_loss: 0.3028 - val_acc: 0.9224\n",
            "Epoch 254/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0854 - acc: 0.9671 - val_loss: 0.3075 - val_acc: 0.9205\n",
            "Epoch 255/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0818 - acc: 0.9661 - val_loss: 0.3067 - val_acc: 0.9218\n",
            "Epoch 256/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0783 - acc: 0.9683 - val_loss: 0.3097 - val_acc: 0.9224\n",
            "Epoch 257/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0837 - acc: 0.9667 - val_loss: 0.2954 - val_acc: 0.9243\n",
            "Epoch 258/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0768 - acc: 0.9689 - val_loss: 0.2966 - val_acc: 0.9262\n",
            "Epoch 259/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0793 - acc: 0.9702 - val_loss: 0.2974 - val_acc: 0.9205\n",
            "Epoch 260/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0744 - acc: 0.9695 - val_loss: 0.3112 - val_acc: 0.9249\n",
            "Epoch 261/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0796 - acc: 0.9661 - val_loss: 0.2951 - val_acc: 0.9274\n",
            "Epoch 262/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0697 - acc: 0.9698 - val_loss: 0.3158 - val_acc: 0.9224\n",
            "Epoch 263/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0749 - acc: 0.9702 - val_loss: 0.3043 - val_acc: 0.9243\n",
            "Epoch 264/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0753 - acc: 0.9689 - val_loss: 0.3173 - val_acc: 0.9224\n",
            "Epoch 265/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0755 - acc: 0.9708 - val_loss: 0.3239 - val_acc: 0.9205\n",
            "Epoch 266/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.0798 - acc: 0.9692 - val_loss: 0.3076 - val_acc: 0.9230\n",
            "Epoch 267/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0752 - acc: 0.9723 - val_loss: 0.3172 - val_acc: 0.9230\n",
            "Epoch 268/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0774 - acc: 0.9698 - val_loss: 0.3092 - val_acc: 0.9218\n",
            "Epoch 269/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0701 - acc: 0.9726 - val_loss: 0.3147 - val_acc: 0.9249\n",
            "Epoch 270/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0712 - acc: 0.9723 - val_loss: 0.3128 - val_acc: 0.9256\n",
            "Epoch 271/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0789 - acc: 0.9723 - val_loss: 0.3308 - val_acc: 0.9199\n",
            "Epoch 272/800\n",
            "3217/3217 [==============================] - 0s 112us/step - loss: 0.0738 - acc: 0.9736 - val_loss: 0.3044 - val_acc: 0.9230\n",
            "Epoch 273/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0818 - acc: 0.9698 - val_loss: 0.2965 - val_acc: 0.9237\n",
            "Epoch 274/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0745 - acc: 0.9705 - val_loss: 0.2988 - val_acc: 0.9262\n",
            "Epoch 275/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0772 - acc: 0.9671 - val_loss: 0.3016 - val_acc: 0.9274\n",
            "Epoch 276/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0781 - acc: 0.9692 - val_loss: 0.3094 - val_acc: 0.9243\n",
            "Epoch 277/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0714 - acc: 0.9708 - val_loss: 0.3173 - val_acc: 0.9262\n",
            "Epoch 278/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0828 - acc: 0.9680 - val_loss: 0.3336 - val_acc: 0.9205\n",
            "Epoch 279/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0665 - acc: 0.9745 - val_loss: 0.3292 - val_acc: 0.9230\n",
            "Epoch 280/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0722 - acc: 0.9711 - val_loss: 0.3176 - val_acc: 0.9237\n",
            "Epoch 281/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0717 - acc: 0.9714 - val_loss: 0.3283 - val_acc: 0.9224\n",
            "Epoch 282/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0770 - acc: 0.9711 - val_loss: 0.3253 - val_acc: 0.9186\n",
            "Epoch 283/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0796 - acc: 0.9714 - val_loss: 0.3071 - val_acc: 0.9199\n",
            "Epoch 284/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0753 - acc: 0.9671 - val_loss: 0.3109 - val_acc: 0.9224\n",
            "Epoch 285/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0707 - acc: 0.9717 - val_loss: 0.3286 - val_acc: 0.9230\n",
            "Epoch 286/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0712 - acc: 0.9711 - val_loss: 0.3191 - val_acc: 0.9192\n",
            "Epoch 287/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0707 - acc: 0.9714 - val_loss: 0.3187 - val_acc: 0.9192\n",
            "Epoch 288/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0713 - acc: 0.9733 - val_loss: 0.3082 - val_acc: 0.9224\n",
            "Epoch 289/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0661 - acc: 0.9720 - val_loss: 0.3175 - val_acc: 0.9230\n",
            "Epoch 290/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0657 - acc: 0.9736 - val_loss: 0.3247 - val_acc: 0.9218\n",
            "Epoch 291/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0691 - acc: 0.9742 - val_loss: 0.3403 - val_acc: 0.9230\n",
            "Epoch 292/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0671 - acc: 0.9705 - val_loss: 0.3302 - val_acc: 0.9224\n",
            "Epoch 293/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0708 - acc: 0.9733 - val_loss: 0.3269 - val_acc: 0.9211\n",
            "Epoch 294/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0724 - acc: 0.9723 - val_loss: 0.3153 - val_acc: 0.9237\n",
            "Epoch 295/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0647 - acc: 0.9739 - val_loss: 0.3333 - val_acc: 0.9199\n",
            "Epoch 296/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0702 - acc: 0.9711 - val_loss: 0.3475 - val_acc: 0.9148\n",
            "Epoch 297/800\n",
            "3217/3217 [==============================] - 0s 108us/step - loss: 0.0675 - acc: 0.9751 - val_loss: 0.3196 - val_acc: 0.9211\n",
            "Epoch 298/800\n",
            "3217/3217 [==============================] - 0s 108us/step - loss: 0.0666 - acc: 0.9751 - val_loss: 0.3353 - val_acc: 0.9205\n",
            "Epoch 299/800\n",
            "3217/3217 [==============================] - 0s 111us/step - loss: 0.0682 - acc: 0.9705 - val_loss: 0.3281 - val_acc: 0.9230\n",
            "Epoch 300/800\n",
            "3217/3217 [==============================] - 0s 110us/step - loss: 0.0731 - acc: 0.9714 - val_loss: 0.3297 - val_acc: 0.9199\n",
            "Epoch 301/800\n",
            "3217/3217 [==============================] - 0s 111us/step - loss: 0.0684 - acc: 0.9714 - val_loss: 0.3317 - val_acc: 0.9249\n",
            "Epoch 302/800\n",
            "3217/3217 [==============================] - 0s 109us/step - loss: 0.0713 - acc: 0.9702 - val_loss: 0.3238 - val_acc: 0.9243\n",
            "Epoch 303/800\n",
            "3217/3217 [==============================] - 0s 119us/step - loss: 0.0657 - acc: 0.9748 - val_loss: 0.3338 - val_acc: 0.9192\n",
            "Epoch 304/800\n",
            "3217/3217 [==============================] - 0s 109us/step - loss: 0.0702 - acc: 0.9730 - val_loss: 0.3355 - val_acc: 0.9155\n",
            "Epoch 305/800\n",
            "3217/3217 [==============================] - 0s 110us/step - loss: 0.0616 - acc: 0.9758 - val_loss: 0.3289 - val_acc: 0.9230\n",
            "Epoch 306/800\n",
            "3217/3217 [==============================] - 0s 113us/step - loss: 0.0698 - acc: 0.9695 - val_loss: 0.3314 - val_acc: 0.9186\n",
            "Epoch 307/800\n",
            "3217/3217 [==============================] - 0s 109us/step - loss: 0.0652 - acc: 0.9754 - val_loss: 0.3397 - val_acc: 0.9167\n",
            "Epoch 308/800\n",
            "3217/3217 [==============================] - 0s 114us/step - loss: 0.0704 - acc: 0.9730 - val_loss: 0.3424 - val_acc: 0.9186\n",
            "Epoch 309/800\n",
            "3217/3217 [==============================] - 0s 110us/step - loss: 0.0708 - acc: 0.9726 - val_loss: 0.3308 - val_acc: 0.9249\n",
            "Epoch 310/800\n",
            "3217/3217 [==============================] - 0s 110us/step - loss: 0.0753 - acc: 0.9695 - val_loss: 0.3347 - val_acc: 0.9249\n",
            "Epoch 311/800\n",
            "3217/3217 [==============================] - 0s 111us/step - loss: 0.0675 - acc: 0.9739 - val_loss: 0.3406 - val_acc: 0.9243\n",
            "Epoch 312/800\n",
            "3217/3217 [==============================] - 0s 110us/step - loss: 0.0646 - acc: 0.9745 - val_loss: 0.3458 - val_acc: 0.9218\n",
            "Epoch 313/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0619 - acc: 0.9779 - val_loss: 0.3471 - val_acc: 0.9211\n",
            "Epoch 314/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0605 - acc: 0.9745 - val_loss: 0.3503 - val_acc: 0.9199\n",
            "Epoch 315/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0645 - acc: 0.9733 - val_loss: 0.3496 - val_acc: 0.9224\n",
            "Epoch 316/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0661 - acc: 0.9717 - val_loss: 0.3397 - val_acc: 0.9237\n",
            "Epoch 317/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0616 - acc: 0.9739 - val_loss: 0.3479 - val_acc: 0.9224\n",
            "Epoch 318/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0596 - acc: 0.9789 - val_loss: 0.3422 - val_acc: 0.9243\n",
            "Epoch 319/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0639 - acc: 0.9758 - val_loss: 0.3434 - val_acc: 0.9192\n",
            "Epoch 320/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0678 - acc: 0.9764 - val_loss: 0.3352 - val_acc: 0.9218\n",
            "Epoch 321/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0669 - acc: 0.9751 - val_loss: 0.3284 - val_acc: 0.9205\n",
            "Epoch 322/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0624 - acc: 0.9748 - val_loss: 0.3373 - val_acc: 0.9224\n",
            "Epoch 323/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0656 - acc: 0.9723 - val_loss: 0.3381 - val_acc: 0.9186\n",
            "Epoch 324/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0625 - acc: 0.9767 - val_loss: 0.3432 - val_acc: 0.9167\n",
            "Epoch 325/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0702 - acc: 0.9748 - val_loss: 0.3422 - val_acc: 0.9155\n",
            "Epoch 326/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0659 - acc: 0.9745 - val_loss: 0.3443 - val_acc: 0.9205\n",
            "Epoch 327/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0594 - acc: 0.9782 - val_loss: 0.3463 - val_acc: 0.9237\n",
            "Epoch 328/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0645 - acc: 0.9779 - val_loss: 0.3370 - val_acc: 0.9237\n",
            "Epoch 329/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0688 - acc: 0.9742 - val_loss: 0.3418 - val_acc: 0.9224\n",
            "Epoch 330/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0635 - acc: 0.9742 - val_loss: 0.3284 - val_acc: 0.9243\n",
            "Epoch 331/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0590 - acc: 0.9758 - val_loss: 0.3465 - val_acc: 0.9256\n",
            "Epoch 332/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0714 - acc: 0.9758 - val_loss: 0.3416 - val_acc: 0.9281\n",
            "Epoch 333/800\n",
            "3217/3217 [==============================] - 0s 109us/step - loss: 0.0594 - acc: 0.9748 - val_loss: 0.3426 - val_acc: 0.9268\n",
            "Epoch 334/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0591 - acc: 0.9736 - val_loss: 0.3277 - val_acc: 0.9224\n",
            "Epoch 335/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0658 - acc: 0.9736 - val_loss: 0.3367 - val_acc: 0.9243\n",
            "Epoch 336/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0607 - acc: 0.9758 - val_loss: 0.3301 - val_acc: 0.9268\n",
            "Epoch 337/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.0619 - acc: 0.9754 - val_loss: 0.3372 - val_acc: 0.9268\n",
            "Epoch 338/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0638 - acc: 0.9770 - val_loss: 0.3449 - val_acc: 0.9262\n",
            "Epoch 339/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0578 - acc: 0.9792 - val_loss: 0.3323 - val_acc: 0.9237\n",
            "Epoch 340/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0584 - acc: 0.9779 - val_loss: 0.3378 - val_acc: 0.9256\n",
            "Epoch 341/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0623 - acc: 0.9748 - val_loss: 0.3451 - val_acc: 0.9211\n",
            "Epoch 342/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0592 - acc: 0.9758 - val_loss: 0.3568 - val_acc: 0.9224\n",
            "Epoch 343/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0590 - acc: 0.9767 - val_loss: 0.3561 - val_acc: 0.9192\n",
            "Epoch 344/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0626 - acc: 0.9758 - val_loss: 0.3370 - val_acc: 0.9249\n",
            "Epoch 345/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0574 - acc: 0.9758 - val_loss: 0.3540 - val_acc: 0.9218\n",
            "Epoch 346/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0614 - acc: 0.9761 - val_loss: 0.3646 - val_acc: 0.9237\n",
            "Epoch 347/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0601 - acc: 0.9779 - val_loss: 0.3620 - val_acc: 0.9174\n",
            "Epoch 348/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0569 - acc: 0.9770 - val_loss: 0.3632 - val_acc: 0.9161\n",
            "Epoch 349/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0579 - acc: 0.9779 - val_loss: 0.3608 - val_acc: 0.9224\n",
            "Epoch 350/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0603 - acc: 0.9739 - val_loss: 0.3569 - val_acc: 0.9211\n",
            "Epoch 351/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0585 - acc: 0.9776 - val_loss: 0.3643 - val_acc: 0.9205\n",
            "Epoch 352/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0517 - acc: 0.9770 - val_loss: 0.3598 - val_acc: 0.9243\n",
            "Epoch 353/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0651 - acc: 0.9730 - val_loss: 0.3581 - val_acc: 0.9192\n",
            "Epoch 354/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0603 - acc: 0.9751 - val_loss: 0.3466 - val_acc: 0.9211\n",
            "Epoch 355/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0629 - acc: 0.9767 - val_loss: 0.3541 - val_acc: 0.9205\n",
            "Epoch 356/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.0546 - acc: 0.9798 - val_loss: 0.3526 - val_acc: 0.9249\n",
            "Epoch 357/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0596 - acc: 0.9767 - val_loss: 0.3605 - val_acc: 0.9237\n",
            "Epoch 358/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0589 - acc: 0.9789 - val_loss: 0.3722 - val_acc: 0.9230\n",
            "Epoch 359/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0598 - acc: 0.9758 - val_loss: 0.3660 - val_acc: 0.9268\n",
            "Epoch 360/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0566 - acc: 0.9789 - val_loss: 0.3690 - val_acc: 0.9230\n",
            "Epoch 361/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0539 - acc: 0.9792 - val_loss: 0.3619 - val_acc: 0.9230\n",
            "Epoch 362/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0521 - acc: 0.9807 - val_loss: 0.3620 - val_acc: 0.9230\n",
            "Epoch 363/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0543 - acc: 0.9779 - val_loss: 0.3679 - val_acc: 0.9256\n",
            "Epoch 364/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0460 - acc: 0.9801 - val_loss: 0.3723 - val_acc: 0.9237\n",
            "Epoch 365/800\n",
            "3217/3217 [==============================] - 0s 110us/step - loss: 0.0567 - acc: 0.9779 - val_loss: 0.3824 - val_acc: 0.9155\n",
            "Epoch 366/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0570 - acc: 0.9776 - val_loss: 0.3757 - val_acc: 0.9237\n",
            "Epoch 367/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0623 - acc: 0.9726 - val_loss: 0.3692 - val_acc: 0.9224\n",
            "Epoch 368/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0525 - acc: 0.9789 - val_loss: 0.3512 - val_acc: 0.9237\n",
            "Epoch 369/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0588 - acc: 0.9758 - val_loss: 0.3614 - val_acc: 0.9243\n",
            "Epoch 370/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0536 - acc: 0.9782 - val_loss: 0.3543 - val_acc: 0.9230\n",
            "Epoch 371/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0559 - acc: 0.9782 - val_loss: 0.3622 - val_acc: 0.9237\n",
            "Epoch 372/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0567 - acc: 0.9779 - val_loss: 0.3720 - val_acc: 0.9211\n",
            "Epoch 373/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0591 - acc: 0.9748 - val_loss: 0.3727 - val_acc: 0.9230\n",
            "Epoch 374/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0517 - acc: 0.9804 - val_loss: 0.3703 - val_acc: 0.9268\n",
            "Epoch 375/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0581 - acc: 0.9773 - val_loss: 0.3472 - val_acc: 0.9230\n",
            "Epoch 376/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0551 - acc: 0.9776 - val_loss: 0.3536 - val_acc: 0.9211\n",
            "Epoch 377/800\n",
            "3217/3217 [==============================] - 0s 112us/step - loss: 0.0548 - acc: 0.9798 - val_loss: 0.3726 - val_acc: 0.9199\n",
            "Epoch 378/800\n",
            "3217/3217 [==============================] - 0s 109us/step - loss: 0.0543 - acc: 0.9798 - val_loss: 0.3847 - val_acc: 0.9230\n",
            "Epoch 379/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0584 - acc: 0.9761 - val_loss: 0.3873 - val_acc: 0.9230\n",
            "Epoch 380/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0617 - acc: 0.9736 - val_loss: 0.3676 - val_acc: 0.9224\n",
            "Epoch 381/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0521 - acc: 0.9807 - val_loss: 0.3788 - val_acc: 0.9249\n",
            "Epoch 382/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0545 - acc: 0.9773 - val_loss: 0.3747 - val_acc: 0.9205\n",
            "Epoch 383/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0542 - acc: 0.9782 - val_loss: 0.3793 - val_acc: 0.9211\n",
            "Epoch 384/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0575 - acc: 0.9767 - val_loss: 0.3603 - val_acc: 0.9199\n",
            "Epoch 385/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0494 - acc: 0.9801 - val_loss: 0.3704 - val_acc: 0.9230\n",
            "Epoch 386/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0498 - acc: 0.9801 - val_loss: 0.3798 - val_acc: 0.9256\n",
            "Epoch 387/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0553 - acc: 0.9770 - val_loss: 0.3709 - val_acc: 0.9218\n",
            "Epoch 388/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0512 - acc: 0.9804 - val_loss: 0.3775 - val_acc: 0.9211\n",
            "Epoch 389/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0607 - acc: 0.9792 - val_loss: 0.3551 - val_acc: 0.9224\n",
            "Epoch 390/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0504 - acc: 0.9786 - val_loss: 0.3815 - val_acc: 0.9243\n",
            "Epoch 391/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0534 - acc: 0.9798 - val_loss: 0.3922 - val_acc: 0.9256\n",
            "Epoch 392/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0493 - acc: 0.9801 - val_loss: 0.3846 - val_acc: 0.9230\n",
            "Epoch 393/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0494 - acc: 0.9810 - val_loss: 0.3909 - val_acc: 0.9243\n",
            "Epoch 394/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0442 - acc: 0.9829 - val_loss: 0.3994 - val_acc: 0.9199\n",
            "Epoch 395/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0548 - acc: 0.9782 - val_loss: 0.3888 - val_acc: 0.9237\n",
            "Epoch 396/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0563 - acc: 0.9782 - val_loss: 0.3889 - val_acc: 0.9230\n",
            "Epoch 397/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0545 - acc: 0.9801 - val_loss: 0.3828 - val_acc: 0.9249\n",
            "Epoch 398/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0497 - acc: 0.9786 - val_loss: 0.3831 - val_acc: 0.9211\n",
            "Epoch 399/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0549 - acc: 0.9795 - val_loss: 0.3810 - val_acc: 0.9180\n",
            "Epoch 400/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0474 - acc: 0.9817 - val_loss: 0.3823 - val_acc: 0.9224\n",
            "Epoch 401/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0490 - acc: 0.9801 - val_loss: 0.3859 - val_acc: 0.9186\n",
            "Epoch 402/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0517 - acc: 0.9789 - val_loss: 0.3851 - val_acc: 0.9237\n",
            "Epoch 403/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0487 - acc: 0.9820 - val_loss: 0.3713 - val_acc: 0.9243\n",
            "Epoch 404/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0514 - acc: 0.9789 - val_loss: 0.3877 - val_acc: 0.9230\n",
            "Epoch 405/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0542 - acc: 0.9789 - val_loss: 0.3888 - val_acc: 0.9211\n",
            "Epoch 406/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0540 - acc: 0.9801 - val_loss: 0.3879 - val_acc: 0.9205\n",
            "Epoch 407/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0522 - acc: 0.9786 - val_loss: 0.3905 - val_acc: 0.9230\n",
            "Epoch 408/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0470 - acc: 0.9810 - val_loss: 0.3913 - val_acc: 0.9211\n",
            "Epoch 409/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0484 - acc: 0.9801 - val_loss: 0.3906 - val_acc: 0.9192\n",
            "Epoch 410/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0545 - acc: 0.9823 - val_loss: 0.4048 - val_acc: 0.9224\n",
            "Epoch 411/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0514 - acc: 0.9795 - val_loss: 0.3986 - val_acc: 0.9262\n",
            "Epoch 412/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0527 - acc: 0.9817 - val_loss: 0.3944 - val_acc: 0.9224\n",
            "Epoch 413/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0497 - acc: 0.9820 - val_loss: 0.3910 - val_acc: 0.9148\n",
            "Epoch 414/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0480 - acc: 0.9807 - val_loss: 0.3863 - val_acc: 0.9186\n",
            "Epoch 415/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.0546 - acc: 0.9786 - val_loss: 0.3935 - val_acc: 0.9174\n",
            "Epoch 416/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0471 - acc: 0.9795 - val_loss: 0.3963 - val_acc: 0.9211\n",
            "Epoch 417/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0488 - acc: 0.9792 - val_loss: 0.4049 - val_acc: 0.9224\n",
            "Epoch 418/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.0459 - acc: 0.9851 - val_loss: 0.4117 - val_acc: 0.9192\n",
            "Epoch 419/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0447 - acc: 0.9835 - val_loss: 0.4183 - val_acc: 0.9211\n",
            "Epoch 420/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0445 - acc: 0.9820 - val_loss: 0.4107 - val_acc: 0.9243\n",
            "Epoch 421/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0545 - acc: 0.9764 - val_loss: 0.3940 - val_acc: 0.9218\n",
            "Epoch 422/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0515 - acc: 0.9792 - val_loss: 0.3771 - val_acc: 0.9256\n",
            "Epoch 423/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0467 - acc: 0.9845 - val_loss: 0.3925 - val_acc: 0.9256\n",
            "Epoch 424/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0439 - acc: 0.9838 - val_loss: 0.3979 - val_acc: 0.9249\n",
            "Epoch 425/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0466 - acc: 0.9807 - val_loss: 0.3969 - val_acc: 0.9256\n",
            "Epoch 426/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0489 - acc: 0.9786 - val_loss: 0.4002 - val_acc: 0.9199\n",
            "Epoch 427/800\n",
            "3217/3217 [==============================] - 0s 113us/step - loss: 0.0476 - acc: 0.9817 - val_loss: 0.3948 - val_acc: 0.9243\n",
            "Epoch 428/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0482 - acc: 0.9801 - val_loss: 0.4050 - val_acc: 0.9199\n",
            "Epoch 429/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0495 - acc: 0.9789 - val_loss: 0.4080 - val_acc: 0.9256\n",
            "Epoch 430/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0426 - acc: 0.9845 - val_loss: 0.3990 - val_acc: 0.9256\n",
            "Epoch 431/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0507 - acc: 0.9820 - val_loss: 0.4001 - val_acc: 0.9218\n",
            "Epoch 432/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0454 - acc: 0.9826 - val_loss: 0.3856 - val_acc: 0.9230\n",
            "Epoch 433/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0485 - acc: 0.9798 - val_loss: 0.3835 - val_acc: 0.9230\n",
            "Epoch 434/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0448 - acc: 0.9813 - val_loss: 0.4055 - val_acc: 0.9243\n",
            "Epoch 435/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0448 - acc: 0.9835 - val_loss: 0.4160 - val_acc: 0.9243\n",
            "Epoch 436/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0457 - acc: 0.9820 - val_loss: 0.4013 - val_acc: 0.9205\n",
            "Epoch 437/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0539 - acc: 0.9776 - val_loss: 0.3907 - val_acc: 0.9205\n",
            "Epoch 438/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0464 - acc: 0.9823 - val_loss: 0.4020 - val_acc: 0.9199\n",
            "Epoch 439/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0466 - acc: 0.9801 - val_loss: 0.3945 - val_acc: 0.9249\n",
            "Epoch 440/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0482 - acc: 0.9804 - val_loss: 0.3867 - val_acc: 0.9237\n",
            "Epoch 441/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0481 - acc: 0.9807 - val_loss: 0.4003 - val_acc: 0.9211\n",
            "Epoch 442/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0419 - acc: 0.9841 - val_loss: 0.3893 - val_acc: 0.9237\n",
            "Epoch 443/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0441 - acc: 0.9820 - val_loss: 0.3965 - val_acc: 0.9230\n",
            "Epoch 444/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0445 - acc: 0.9826 - val_loss: 0.3984 - val_acc: 0.9237\n",
            "Epoch 445/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0429 - acc: 0.9841 - val_loss: 0.4103 - val_acc: 0.9230\n",
            "Epoch 446/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0447 - acc: 0.9826 - val_loss: 0.4087 - val_acc: 0.9224\n",
            "Epoch 447/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0461 - acc: 0.9820 - val_loss: 0.4172 - val_acc: 0.9211\n",
            "Epoch 448/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0408 - acc: 0.9851 - val_loss: 0.4059 - val_acc: 0.9224\n",
            "Epoch 449/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0436 - acc: 0.9820 - val_loss: 0.4104 - val_acc: 0.9211\n",
            "Epoch 450/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0395 - acc: 0.9848 - val_loss: 0.4108 - val_acc: 0.9249\n",
            "Epoch 451/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0465 - acc: 0.9807 - val_loss: 0.4159 - val_acc: 0.9218\n",
            "Epoch 452/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0403 - acc: 0.9838 - val_loss: 0.4004 - val_acc: 0.9218\n",
            "Epoch 453/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0511 - acc: 0.9823 - val_loss: 0.4180 - val_acc: 0.9205\n",
            "Epoch 454/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0399 - acc: 0.9851 - val_loss: 0.4354 - val_acc: 0.9243\n",
            "Epoch 455/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0497 - acc: 0.9798 - val_loss: 0.4516 - val_acc: 0.9199\n",
            "Epoch 456/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0415 - acc: 0.9820 - val_loss: 0.4181 - val_acc: 0.9237\n",
            "Epoch 457/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0479 - acc: 0.9801 - val_loss: 0.3968 - val_acc: 0.9249\n",
            "Epoch 458/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0407 - acc: 0.9848 - val_loss: 0.4181 - val_acc: 0.9192\n",
            "Epoch 459/800\n",
            "3217/3217 [==============================] - 0s 109us/step - loss: 0.0440 - acc: 0.9835 - val_loss: 0.4192 - val_acc: 0.9199\n",
            "Epoch 460/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0424 - acc: 0.9826 - val_loss: 0.4189 - val_acc: 0.9192\n",
            "Epoch 461/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0396 - acc: 0.9829 - val_loss: 0.4285 - val_acc: 0.9211\n",
            "Epoch 462/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0416 - acc: 0.9845 - val_loss: 0.4292 - val_acc: 0.9237\n",
            "Epoch 463/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0507 - acc: 0.9786 - val_loss: 0.4110 - val_acc: 0.9224\n",
            "Epoch 464/800\n",
            "3217/3217 [==============================] - 0s 108us/step - loss: 0.0455 - acc: 0.9829 - val_loss: 0.4211 - val_acc: 0.9205\n",
            "Epoch 465/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0425 - acc: 0.9845 - val_loss: 0.4103 - val_acc: 0.9243\n",
            "Epoch 466/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0462 - acc: 0.9795 - val_loss: 0.4119 - val_acc: 0.9224\n",
            "Epoch 467/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0439 - acc: 0.9829 - val_loss: 0.4289 - val_acc: 0.9199\n",
            "Epoch 468/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0419 - acc: 0.9835 - val_loss: 0.4195 - val_acc: 0.9224\n",
            "Epoch 469/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0479 - acc: 0.9841 - val_loss: 0.4218 - val_acc: 0.9218\n",
            "Epoch 470/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0433 - acc: 0.9863 - val_loss: 0.4350 - val_acc: 0.9218\n",
            "Epoch 471/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0443 - acc: 0.9810 - val_loss: 0.4189 - val_acc: 0.9237\n",
            "Epoch 472/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0477 - acc: 0.9813 - val_loss: 0.4105 - val_acc: 0.9211\n",
            "Epoch 473/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0441 - acc: 0.9838 - val_loss: 0.4165 - val_acc: 0.9243\n",
            "Epoch 474/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0417 - acc: 0.9835 - val_loss: 0.4301 - val_acc: 0.9174\n",
            "Epoch 475/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0405 - acc: 0.9823 - val_loss: 0.4295 - val_acc: 0.9211\n",
            "Epoch 476/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0352 - acc: 0.9854 - val_loss: 0.4410 - val_acc: 0.9211\n",
            "Epoch 477/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0402 - acc: 0.9807 - val_loss: 0.4386 - val_acc: 0.9199\n",
            "Epoch 478/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0443 - acc: 0.9826 - val_loss: 0.4268 - val_acc: 0.9205\n",
            "Epoch 479/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0457 - acc: 0.9804 - val_loss: 0.4281 - val_acc: 0.9237\n",
            "Epoch 480/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0442 - acc: 0.9851 - val_loss: 0.4158 - val_acc: 0.9224\n",
            "Epoch 481/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0413 - acc: 0.9838 - val_loss: 0.4165 - val_acc: 0.9230\n",
            "Epoch 482/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0362 - acc: 0.9863 - val_loss: 0.4275 - val_acc: 0.9243\n",
            "Epoch 483/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0400 - acc: 0.9851 - val_loss: 0.4364 - val_acc: 0.9199\n",
            "Epoch 484/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0441 - acc: 0.9829 - val_loss: 0.4170 - val_acc: 0.9205\n",
            "Epoch 485/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0413 - acc: 0.9841 - val_loss: 0.4189 - val_acc: 0.9211\n",
            "Epoch 486/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0449 - acc: 0.9813 - val_loss: 0.4181 - val_acc: 0.9218\n",
            "Epoch 487/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0458 - acc: 0.9841 - val_loss: 0.4245 - val_acc: 0.9218\n",
            "Epoch 488/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0456 - acc: 0.9829 - val_loss: 0.4428 - val_acc: 0.9249\n",
            "Epoch 489/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0374 - acc: 0.9857 - val_loss: 0.4509 - val_acc: 0.9230\n",
            "Epoch 490/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0425 - acc: 0.9838 - val_loss: 0.4235 - val_acc: 0.9192\n",
            "Epoch 491/800\n",
            "3217/3217 [==============================] - 0s 109us/step - loss: 0.0408 - acc: 0.9851 - val_loss: 0.4411 - val_acc: 0.9256\n",
            "Epoch 492/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0370 - acc: 0.9854 - val_loss: 0.4256 - val_acc: 0.9186\n",
            "Epoch 493/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0428 - acc: 0.9823 - val_loss: 0.4270 - val_acc: 0.9192\n",
            "Epoch 494/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0393 - acc: 0.9845 - val_loss: 0.4289 - val_acc: 0.9262\n",
            "Epoch 495/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.0380 - acc: 0.9860 - val_loss: 0.4282 - val_acc: 0.9224\n",
            "Epoch 496/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0394 - acc: 0.9832 - val_loss: 0.4155 - val_acc: 0.9224\n",
            "Epoch 497/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0437 - acc: 0.9838 - val_loss: 0.4204 - val_acc: 0.9224\n",
            "Epoch 498/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0358 - acc: 0.9848 - val_loss: 0.4303 - val_acc: 0.9256\n",
            "Epoch 499/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0406 - acc: 0.9838 - val_loss: 0.4402 - val_acc: 0.9224\n",
            "Epoch 500/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0344 - acc: 0.9873 - val_loss: 0.4457 - val_acc: 0.9256\n",
            "Epoch 501/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0441 - acc: 0.9832 - val_loss: 0.4235 - val_acc: 0.9256\n",
            "Epoch 502/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0436 - acc: 0.9829 - val_loss: 0.4235 - val_acc: 0.9224\n",
            "Epoch 503/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0377 - acc: 0.9848 - val_loss: 0.4298 - val_acc: 0.9249\n",
            "Epoch 504/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0380 - acc: 0.9869 - val_loss: 0.4480 - val_acc: 0.9205\n",
            "Epoch 505/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0413 - acc: 0.9841 - val_loss: 0.4535 - val_acc: 0.9230\n",
            "Epoch 506/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0383 - acc: 0.9832 - val_loss: 0.4400 - val_acc: 0.9224\n",
            "Epoch 507/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0397 - acc: 0.9860 - val_loss: 0.4302 - val_acc: 0.9224\n",
            "Epoch 508/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0435 - acc: 0.9832 - val_loss: 0.4385 - val_acc: 0.9167\n",
            "Epoch 509/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0337 - acc: 0.9851 - val_loss: 0.4386 - val_acc: 0.9192\n",
            "Epoch 510/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0382 - acc: 0.9860 - val_loss: 0.4432 - val_acc: 0.9211\n",
            "Epoch 511/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0391 - acc: 0.9813 - val_loss: 0.4407 - val_acc: 0.9211\n",
            "Epoch 512/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0335 - acc: 0.9873 - val_loss: 0.4589 - val_acc: 0.9224\n",
            "Epoch 513/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0363 - acc: 0.9832 - val_loss: 0.4642 - val_acc: 0.9218\n",
            "Epoch 514/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0407 - acc: 0.9851 - val_loss: 0.4469 - val_acc: 0.9237\n",
            "Epoch 515/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0453 - acc: 0.9832 - val_loss: 0.4501 - val_acc: 0.9256\n",
            "Epoch 516/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0381 - acc: 0.9866 - val_loss: 0.4383 - val_acc: 0.9167\n",
            "Epoch 517/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0376 - acc: 0.9854 - val_loss: 0.4550 - val_acc: 0.9205\n",
            "Epoch 518/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0424 - acc: 0.9841 - val_loss: 0.4589 - val_acc: 0.9161\n",
            "Epoch 519/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0397 - acc: 0.9848 - val_loss: 0.4517 - val_acc: 0.9205\n",
            "Epoch 520/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0389 - acc: 0.9841 - val_loss: 0.4454 - val_acc: 0.9224\n",
            "Epoch 521/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0396 - acc: 0.9845 - val_loss: 0.4530 - val_acc: 0.9186\n",
            "Epoch 522/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0392 - acc: 0.9845 - val_loss: 0.4550 - val_acc: 0.9199\n",
            "Epoch 523/800\n",
            "3217/3217 [==============================] - 0s 118us/step - loss: 0.0390 - acc: 0.9863 - val_loss: 0.4436 - val_acc: 0.9192\n",
            "Epoch 524/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0308 - acc: 0.9863 - val_loss: 0.4480 - val_acc: 0.9237\n",
            "Epoch 525/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0456 - acc: 0.9823 - val_loss: 0.4503 - val_acc: 0.9211\n",
            "Epoch 526/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0352 - acc: 0.9876 - val_loss: 0.4481 - val_acc: 0.9180\n",
            "Epoch 527/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0384 - acc: 0.9845 - val_loss: 0.4332 - val_acc: 0.9205\n",
            "Epoch 528/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0390 - acc: 0.9860 - val_loss: 0.4366 - val_acc: 0.9249\n",
            "Epoch 529/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0365 - acc: 0.9854 - val_loss: 0.4546 - val_acc: 0.9205\n",
            "Epoch 530/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0412 - acc: 0.9845 - val_loss: 0.4424 - val_acc: 0.9192\n",
            "Epoch 531/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0390 - acc: 0.9860 - val_loss: 0.4448 - val_acc: 0.9174\n",
            "Epoch 532/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0394 - acc: 0.9820 - val_loss: 0.4459 - val_acc: 0.9230\n",
            "Epoch 533/800\n",
            "3217/3217 [==============================] - 0s 115us/step - loss: 0.0355 - acc: 0.9876 - val_loss: 0.4430 - val_acc: 0.9211\n",
            "Epoch 534/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0394 - acc: 0.9860 - val_loss: 0.4361 - val_acc: 0.9230\n",
            "Epoch 535/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0420 - acc: 0.9841 - val_loss: 0.4460 - val_acc: 0.9186\n",
            "Epoch 536/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0356 - acc: 0.9860 - val_loss: 0.4409 - val_acc: 0.9192\n",
            "Epoch 537/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0407 - acc: 0.9851 - val_loss: 0.4420 - val_acc: 0.9199\n",
            "Epoch 538/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0403 - acc: 0.9826 - val_loss: 0.4456 - val_acc: 0.9211\n",
            "Epoch 539/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0413 - acc: 0.9860 - val_loss: 0.4498 - val_acc: 0.9186\n",
            "Epoch 540/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0366 - acc: 0.9888 - val_loss: 0.4524 - val_acc: 0.9155\n",
            "Epoch 541/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0368 - acc: 0.9857 - val_loss: 0.4473 - val_acc: 0.9129\n",
            "Epoch 542/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0338 - acc: 0.9894 - val_loss: 0.4388 - val_acc: 0.9192\n",
            "Epoch 543/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0376 - acc: 0.9857 - val_loss: 0.4566 - val_acc: 0.9174\n",
            "Epoch 544/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0304 - acc: 0.9857 - val_loss: 0.4595 - val_acc: 0.9199\n",
            "Epoch 545/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0380 - acc: 0.9857 - val_loss: 0.4511 - val_acc: 0.9199\n",
            "Epoch 546/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0319 - acc: 0.9888 - val_loss: 0.4591 - val_acc: 0.9192\n",
            "Epoch 547/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0403 - acc: 0.9854 - val_loss: 0.4633 - val_acc: 0.9186\n",
            "Epoch 548/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0360 - acc: 0.9866 - val_loss: 0.4496 - val_acc: 0.9205\n",
            "Epoch 549/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0365 - acc: 0.9863 - val_loss: 0.4500 - val_acc: 0.9237\n",
            "Epoch 550/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0306 - acc: 0.9873 - val_loss: 0.4540 - val_acc: 0.9230\n",
            "Epoch 551/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0362 - acc: 0.9879 - val_loss: 0.4474 - val_acc: 0.9174\n",
            "Epoch 552/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0421 - acc: 0.9845 - val_loss: 0.4528 - val_acc: 0.9186\n",
            "Epoch 553/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0318 - acc: 0.9885 - val_loss: 0.4681 - val_acc: 0.9211\n",
            "Epoch 554/800\n",
            "3217/3217 [==============================] - 0s 111us/step - loss: 0.0463 - acc: 0.9851 - val_loss: 0.4930 - val_acc: 0.9161\n",
            "Epoch 555/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0374 - acc: 0.9863 - val_loss: 0.4616 - val_acc: 0.9199\n",
            "Epoch 556/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0343 - acc: 0.9860 - val_loss: 0.4667 - val_acc: 0.9180\n",
            "Epoch 557/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0410 - acc: 0.9866 - val_loss: 0.4548 - val_acc: 0.9205\n",
            "Epoch 558/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0393 - acc: 0.9848 - val_loss: 0.4399 - val_acc: 0.9224\n",
            "Epoch 559/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0437 - acc: 0.9845 - val_loss: 0.4716 - val_acc: 0.9224\n",
            "Epoch 560/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0409 - acc: 0.9829 - val_loss: 0.4394 - val_acc: 0.9205\n",
            "Epoch 561/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.0353 - acc: 0.9860 - val_loss: 0.4486 - val_acc: 0.9192\n",
            "Epoch 562/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0371 - acc: 0.9888 - val_loss: 0.4508 - val_acc: 0.9211\n",
            "Epoch 563/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0337 - acc: 0.9866 - val_loss: 0.4648 - val_acc: 0.9224\n",
            "Epoch 564/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0389 - acc: 0.9841 - val_loss: 0.4643 - val_acc: 0.9205\n",
            "Epoch 565/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0294 - acc: 0.9882 - val_loss: 0.4811 - val_acc: 0.9224\n",
            "Epoch 566/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0333 - acc: 0.9876 - val_loss: 0.4622 - val_acc: 0.9218\n",
            "Epoch 567/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0347 - acc: 0.9879 - val_loss: 0.4600 - val_acc: 0.9230\n",
            "Epoch 568/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0333 - acc: 0.9873 - val_loss: 0.4723 - val_acc: 0.9230\n",
            "Epoch 569/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0359 - acc: 0.9863 - val_loss: 0.4691 - val_acc: 0.9186\n",
            "Epoch 570/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0350 - acc: 0.9869 - val_loss: 0.4610 - val_acc: 0.9174\n",
            "Epoch 571/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0342 - acc: 0.9863 - val_loss: 0.4705 - val_acc: 0.9186\n",
            "Epoch 572/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0415 - acc: 0.9841 - val_loss: 0.4511 - val_acc: 0.9161\n",
            "Epoch 573/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0315 - acc: 0.9879 - val_loss: 0.4549 - val_acc: 0.9180\n",
            "Epoch 574/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0418 - acc: 0.9857 - val_loss: 0.4691 - val_acc: 0.9192\n",
            "Epoch 575/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0386 - acc: 0.9854 - val_loss: 0.4664 - val_acc: 0.9205\n",
            "Epoch 576/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0330 - acc: 0.9876 - val_loss: 0.4645 - val_acc: 0.9218\n",
            "Epoch 577/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0363 - acc: 0.9882 - val_loss: 0.4721 - val_acc: 0.9186\n",
            "Epoch 578/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0338 - acc: 0.9854 - val_loss: 0.4535 - val_acc: 0.9218\n",
            "Epoch 579/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0312 - acc: 0.9885 - val_loss: 0.4891 - val_acc: 0.9199\n",
            "Epoch 580/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0312 - acc: 0.9873 - val_loss: 0.4654 - val_acc: 0.9205\n",
            "Epoch 581/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0350 - acc: 0.9876 - val_loss: 0.4680 - val_acc: 0.9224\n",
            "Epoch 582/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0360 - acc: 0.9857 - val_loss: 0.4776 - val_acc: 0.9174\n",
            "Epoch 583/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0365 - acc: 0.9866 - val_loss: 0.4625 - val_acc: 0.9192\n",
            "Epoch 584/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0424 - acc: 0.9838 - val_loss: 0.4528 - val_acc: 0.9199\n",
            "Epoch 585/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0311 - acc: 0.9885 - val_loss: 0.4541 - val_acc: 0.9205\n",
            "Epoch 586/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0410 - acc: 0.9851 - val_loss: 0.4544 - val_acc: 0.9249\n",
            "Epoch 587/800\n",
            "3217/3217 [==============================] - 0s 113us/step - loss: 0.0346 - acc: 0.9838 - val_loss: 0.4497 - val_acc: 0.9230\n",
            "Epoch 588/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0309 - acc: 0.9885 - val_loss: 0.4535 - val_acc: 0.9218\n",
            "Epoch 589/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0332 - acc: 0.9885 - val_loss: 0.4722 - val_acc: 0.9192\n",
            "Epoch 590/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0380 - acc: 0.9851 - val_loss: 0.4824 - val_acc: 0.9192\n",
            "Epoch 591/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0333 - acc: 0.9888 - val_loss: 0.4816 - val_acc: 0.9180\n",
            "Epoch 592/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0312 - acc: 0.9869 - val_loss: 0.4840 - val_acc: 0.9192\n",
            "Epoch 593/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0266 - acc: 0.9897 - val_loss: 0.4845 - val_acc: 0.9224\n",
            "Epoch 594/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0386 - acc: 0.9854 - val_loss: 0.4884 - val_acc: 0.9237\n",
            "Epoch 595/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0315 - acc: 0.9894 - val_loss: 0.4768 - val_acc: 0.9192\n",
            "Epoch 596/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0320 - acc: 0.9882 - val_loss: 0.4848 - val_acc: 0.9192\n",
            "Epoch 597/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0327 - acc: 0.9901 - val_loss: 0.4789 - val_acc: 0.9218\n",
            "Epoch 598/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0357 - acc: 0.9873 - val_loss: 0.4876 - val_acc: 0.9199\n",
            "Epoch 599/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0360 - acc: 0.9860 - val_loss: 0.4675 - val_acc: 0.9205\n",
            "Epoch 600/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0370 - acc: 0.9873 - val_loss: 0.4561 - val_acc: 0.9224\n",
            "Epoch 601/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0314 - acc: 0.9888 - val_loss: 0.4818 - val_acc: 0.9205\n",
            "Epoch 602/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0293 - acc: 0.9885 - val_loss: 0.4621 - val_acc: 0.9199\n",
            "Epoch 603/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0380 - acc: 0.9854 - val_loss: 0.4755 - val_acc: 0.9205\n",
            "Epoch 604/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0457 - acc: 0.9845 - val_loss: 0.4596 - val_acc: 0.9161\n",
            "Epoch 605/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0360 - acc: 0.9863 - val_loss: 0.4856 - val_acc: 0.9192\n",
            "Epoch 606/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0411 - acc: 0.9851 - val_loss: 0.4642 - val_acc: 0.9199\n",
            "Epoch 607/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0355 - acc: 0.9863 - val_loss: 0.4626 - val_acc: 0.9199\n",
            "Epoch 608/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0296 - acc: 0.9882 - val_loss: 0.4622 - val_acc: 0.9211\n",
            "Epoch 609/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0334 - acc: 0.9869 - val_loss: 0.4638 - val_acc: 0.9148\n",
            "Epoch 610/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0298 - acc: 0.9873 - val_loss: 0.4712 - val_acc: 0.9224\n",
            "Epoch 611/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0265 - acc: 0.9904 - val_loss: 0.4643 - val_acc: 0.9180\n",
            "Epoch 612/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0315 - acc: 0.9876 - val_loss: 0.4813 - val_acc: 0.9174\n",
            "Epoch 613/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0344 - acc: 0.9851 - val_loss: 0.4718 - val_acc: 0.9211\n",
            "Epoch 614/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0359 - acc: 0.9866 - val_loss: 0.4839 - val_acc: 0.9186\n",
            "Epoch 615/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0353 - acc: 0.9857 - val_loss: 0.4831 - val_acc: 0.9211\n",
            "Epoch 616/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0359 - acc: 0.9879 - val_loss: 0.4635 - val_acc: 0.9218\n",
            "Epoch 617/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0315 - acc: 0.9897 - val_loss: 0.4828 - val_acc: 0.9117\n",
            "Epoch 618/800\n",
            "3217/3217 [==============================] - 0s 113us/step - loss: 0.0395 - acc: 0.9851 - val_loss: 0.4797 - val_acc: 0.9180\n",
            "Epoch 619/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0319 - acc: 0.9879 - val_loss: 0.4603 - val_acc: 0.9155\n",
            "Epoch 620/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0389 - acc: 0.9863 - val_loss: 0.4718 - val_acc: 0.9186\n",
            "Epoch 621/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0345 - acc: 0.9876 - val_loss: 0.4750 - val_acc: 0.9186\n",
            "Epoch 622/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0407 - acc: 0.9848 - val_loss: 0.4546 - val_acc: 0.9199\n",
            "Epoch 623/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0379 - acc: 0.9869 - val_loss: 0.4491 - val_acc: 0.9161\n",
            "Epoch 624/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0343 - acc: 0.9851 - val_loss: 0.4482 - val_acc: 0.9211\n",
            "Epoch 625/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0353 - acc: 0.9848 - val_loss: 0.4365 - val_acc: 0.9218\n",
            "Epoch 626/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0380 - acc: 0.9851 - val_loss: 0.4594 - val_acc: 0.9192\n",
            "Epoch 627/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0341 - acc: 0.9869 - val_loss: 0.4669 - val_acc: 0.9230\n",
            "Epoch 628/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0264 - acc: 0.9901 - val_loss: 0.4727 - val_acc: 0.9205\n",
            "Epoch 629/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0324 - acc: 0.9894 - val_loss: 0.4660 - val_acc: 0.9192\n",
            "Epoch 630/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0255 - acc: 0.9907 - val_loss: 0.4512 - val_acc: 0.9230\n",
            "Epoch 631/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0306 - acc: 0.9873 - val_loss: 0.4702 - val_acc: 0.9230\n",
            "Epoch 632/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0410 - acc: 0.9854 - val_loss: 0.4611 - val_acc: 0.9224\n",
            "Epoch 633/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0318 - acc: 0.9882 - val_loss: 0.4602 - val_acc: 0.9199\n",
            "Epoch 634/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0338 - acc: 0.9869 - val_loss: 0.4632 - val_acc: 0.9199\n",
            "Epoch 635/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0318 - acc: 0.9888 - val_loss: 0.4590 - val_acc: 0.9192\n",
            "Epoch 636/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0254 - acc: 0.9910 - val_loss: 0.4767 - val_acc: 0.9192\n",
            "Epoch 637/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0335 - acc: 0.9891 - val_loss: 0.4679 - val_acc: 0.9205\n",
            "Epoch 638/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0395 - acc: 0.9848 - val_loss: 0.4665 - val_acc: 0.9205\n",
            "Epoch 639/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0411 - acc: 0.9838 - val_loss: 0.4541 - val_acc: 0.9211\n",
            "Epoch 640/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0328 - acc: 0.9873 - val_loss: 0.4599 - val_acc: 0.9180\n",
            "Epoch 641/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0347 - acc: 0.9866 - val_loss: 0.4806 - val_acc: 0.9129\n",
            "Epoch 642/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0282 - acc: 0.9882 - val_loss: 0.4720 - val_acc: 0.9155\n",
            "Epoch 643/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0332 - acc: 0.9894 - val_loss: 0.4798 - val_acc: 0.9186\n",
            "Epoch 644/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0321 - acc: 0.9891 - val_loss: 0.4533 - val_acc: 0.9192\n",
            "Epoch 645/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0292 - acc: 0.9885 - val_loss: 0.4901 - val_acc: 0.9192\n",
            "Epoch 646/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0318 - acc: 0.9885 - val_loss: 0.4651 - val_acc: 0.9199\n",
            "Epoch 647/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0376 - acc: 0.9838 - val_loss: 0.4734 - val_acc: 0.9161\n",
            "Epoch 648/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0337 - acc: 0.9845 - val_loss: 0.4721 - val_acc: 0.9230\n",
            "Epoch 649/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0360 - acc: 0.9848 - val_loss: 0.4624 - val_acc: 0.9211\n",
            "Epoch 650/800\n",
            "3217/3217 [==============================] - 0s 111us/step - loss: 0.0318 - acc: 0.9888 - val_loss: 0.4922 - val_acc: 0.9192\n",
            "Epoch 651/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0341 - acc: 0.9869 - val_loss: 0.4732 - val_acc: 0.9256\n",
            "Epoch 652/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0270 - acc: 0.9882 - val_loss: 0.4903 - val_acc: 0.9243\n",
            "Epoch 653/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0317 - acc: 0.9873 - val_loss: 0.4785 - val_acc: 0.9237\n",
            "Epoch 654/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0277 - acc: 0.9882 - val_loss: 0.4629 - val_acc: 0.9230\n",
            "Epoch 655/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0359 - acc: 0.9863 - val_loss: 0.4662 - val_acc: 0.9237\n",
            "Epoch 656/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0352 - acc: 0.9888 - val_loss: 0.4595 - val_acc: 0.9224\n",
            "Epoch 657/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0250 - acc: 0.9891 - val_loss: 0.4692 - val_acc: 0.9237\n",
            "Epoch 658/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0327 - acc: 0.9897 - val_loss: 0.4716 - val_acc: 0.9211\n",
            "Epoch 659/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0323 - acc: 0.9866 - val_loss: 0.4597 - val_acc: 0.9218\n",
            "Epoch 660/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0256 - acc: 0.9888 - val_loss: 0.4749 - val_acc: 0.9224\n",
            "Epoch 661/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0309 - acc: 0.9891 - val_loss: 0.4873 - val_acc: 0.9180\n",
            "Epoch 662/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0352 - acc: 0.9888 - val_loss: 0.4752 - val_acc: 0.9167\n",
            "Epoch 663/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0250 - acc: 0.9910 - val_loss: 0.4977 - val_acc: 0.9199\n",
            "Epoch 664/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0220 - acc: 0.9925 - val_loss: 0.5036 - val_acc: 0.9199\n",
            "Epoch 665/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0368 - acc: 0.9851 - val_loss: 0.4878 - val_acc: 0.9192\n",
            "Epoch 666/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0361 - acc: 0.9863 - val_loss: 0.4913 - val_acc: 0.9211\n",
            "Epoch 667/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0331 - acc: 0.9888 - val_loss: 0.4784 - val_acc: 0.9199\n",
            "Epoch 668/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0378 - acc: 0.9879 - val_loss: 0.4664 - val_acc: 0.9211\n",
            "Epoch 669/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0335 - acc: 0.9876 - val_loss: 0.4731 - val_acc: 0.9199\n",
            "Epoch 670/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0251 - acc: 0.9919 - val_loss: 0.5018 - val_acc: 0.9186\n",
            "Epoch 671/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0316 - acc: 0.9897 - val_loss: 0.4733 - val_acc: 0.9186\n",
            "Epoch 672/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0323 - acc: 0.9888 - val_loss: 0.4552 - val_acc: 0.9218\n",
            "Epoch 673/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0343 - acc: 0.9869 - val_loss: 0.4712 - val_acc: 0.9186\n",
            "Epoch 674/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0302 - acc: 0.9866 - val_loss: 0.4841 - val_acc: 0.9180\n",
            "Epoch 675/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0352 - acc: 0.9857 - val_loss: 0.4930 - val_acc: 0.9167\n",
            "Epoch 676/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0327 - acc: 0.9857 - val_loss: 0.4836 - val_acc: 0.9192\n",
            "Epoch 677/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0280 - acc: 0.9894 - val_loss: 0.4744 - val_acc: 0.9230\n",
            "Epoch 678/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0307 - acc: 0.9894 - val_loss: 0.4824 - val_acc: 0.9180\n",
            "Epoch 679/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0307 - acc: 0.9863 - val_loss: 0.4733 - val_acc: 0.9199\n",
            "Epoch 680/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0315 - acc: 0.9869 - val_loss: 0.4738 - val_acc: 0.9211\n",
            "Epoch 681/800\n",
            "3217/3217 [==============================] - 0s 113us/step - loss: 0.0305 - acc: 0.9891 - val_loss: 0.4899 - val_acc: 0.9211\n",
            "Epoch 682/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0299 - acc: 0.9879 - val_loss: 0.5045 - val_acc: 0.9192\n",
            "Epoch 683/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0296 - acc: 0.9876 - val_loss: 0.5006 - val_acc: 0.9199\n",
            "Epoch 684/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0288 - acc: 0.9901 - val_loss: 0.4873 - val_acc: 0.9186\n",
            "Epoch 685/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0331 - acc: 0.9885 - val_loss: 0.4811 - val_acc: 0.9180\n",
            "Epoch 686/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0318 - acc: 0.9863 - val_loss: 0.4789 - val_acc: 0.9174\n",
            "Epoch 687/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0326 - acc: 0.9879 - val_loss: 0.4835 - val_acc: 0.9186\n",
            "Epoch 688/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0310 - acc: 0.9860 - val_loss: 0.4819 - val_acc: 0.9199\n",
            "Epoch 689/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0311 - acc: 0.9913 - val_loss: 0.5063 - val_acc: 0.9205\n",
            "Epoch 690/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0352 - acc: 0.9882 - val_loss: 0.4850 - val_acc: 0.9211\n",
            "Epoch 691/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0281 - acc: 0.9894 - val_loss: 0.4721 - val_acc: 0.9180\n",
            "Epoch 692/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0288 - acc: 0.9907 - val_loss: 0.4989 - val_acc: 0.9174\n",
            "Epoch 693/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0305 - acc: 0.9882 - val_loss: 0.4857 - val_acc: 0.9205\n",
            "Epoch 694/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0404 - acc: 0.9866 - val_loss: 0.4759 - val_acc: 0.9174\n",
            "Epoch 695/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0333 - acc: 0.9885 - val_loss: 0.4760 - val_acc: 0.9205\n",
            "Epoch 696/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0255 - acc: 0.9891 - val_loss: 0.4917 - val_acc: 0.9192\n",
            "Epoch 697/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0288 - acc: 0.9897 - val_loss: 0.5062 - val_acc: 0.9199\n",
            "Epoch 698/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0337 - acc: 0.9876 - val_loss: 0.4983 - val_acc: 0.9192\n",
            "Epoch 699/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0348 - acc: 0.9863 - val_loss: 0.4861 - val_acc: 0.9199\n",
            "Epoch 700/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0296 - acc: 0.9882 - val_loss: 0.5093 - val_acc: 0.9205\n",
            "Epoch 701/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0293 - acc: 0.9891 - val_loss: 0.5006 - val_acc: 0.9205\n",
            "Epoch 702/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0297 - acc: 0.9882 - val_loss: 0.4894 - val_acc: 0.9218\n",
            "Epoch 703/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0297 - acc: 0.9876 - val_loss: 0.5177 - val_acc: 0.9230\n",
            "Epoch 704/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0348 - acc: 0.9863 - val_loss: 0.4898 - val_acc: 0.9230\n",
            "Epoch 705/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0366 - acc: 0.9866 - val_loss: 0.4781 - val_acc: 0.9205\n",
            "Epoch 706/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0252 - acc: 0.9907 - val_loss: 0.4985 - val_acc: 0.9211\n",
            "Epoch 707/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0289 - acc: 0.9904 - val_loss: 0.5054 - val_acc: 0.9205\n",
            "Epoch 708/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0274 - acc: 0.9891 - val_loss: 0.5064 - val_acc: 0.9249\n",
            "Epoch 709/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0372 - acc: 0.9866 - val_loss: 0.5010 - val_acc: 0.9211\n",
            "Epoch 710/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0326 - acc: 0.9888 - val_loss: 0.5084 - val_acc: 0.9192\n",
            "Epoch 711/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0241 - acc: 0.9897 - val_loss: 0.5203 - val_acc: 0.9205\n",
            "Epoch 712/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0241 - acc: 0.9913 - val_loss: 0.5051 - val_acc: 0.9287\n",
            "Epoch 713/800\n",
            "3217/3217 [==============================] - 0s 116us/step - loss: 0.0252 - acc: 0.9916 - val_loss: 0.5095 - val_acc: 0.9256\n",
            "Epoch 714/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0277 - acc: 0.9910 - val_loss: 0.4937 - val_acc: 0.9256\n",
            "Epoch 715/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0316 - acc: 0.9894 - val_loss: 0.4961 - val_acc: 0.9230\n",
            "Epoch 716/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0314 - acc: 0.9879 - val_loss: 0.4925 - val_acc: 0.9230\n",
            "Epoch 717/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0308 - acc: 0.9904 - val_loss: 0.4898 - val_acc: 0.9249\n",
            "Epoch 718/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0294 - acc: 0.9894 - val_loss: 0.5010 - val_acc: 0.9211\n",
            "Epoch 719/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0300 - acc: 0.9882 - val_loss: 0.4966 - val_acc: 0.9249\n",
            "Epoch 720/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0300 - acc: 0.9863 - val_loss: 0.5093 - val_acc: 0.9249\n",
            "Epoch 721/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0309 - acc: 0.9907 - val_loss: 0.4851 - val_acc: 0.9237\n",
            "Epoch 722/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0339 - acc: 0.9879 - val_loss: 0.4678 - val_acc: 0.9218\n",
            "Epoch 723/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0288 - acc: 0.9891 - val_loss: 0.4869 - val_acc: 0.9249\n",
            "Epoch 724/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0320 - acc: 0.9879 - val_loss: 0.4877 - val_acc: 0.9224\n",
            "Epoch 725/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0332 - acc: 0.9882 - val_loss: 0.4882 - val_acc: 0.9205\n",
            "Epoch 726/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0316 - acc: 0.9876 - val_loss: 0.4890 - val_acc: 0.9205\n",
            "Epoch 727/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0334 - acc: 0.9891 - val_loss: 0.4861 - val_acc: 0.9192\n",
            "Epoch 728/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0332 - acc: 0.9894 - val_loss: 0.4889 - val_acc: 0.9180\n",
            "Epoch 729/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0291 - acc: 0.9891 - val_loss: 0.5009 - val_acc: 0.9174\n",
            "Epoch 730/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0313 - acc: 0.9891 - val_loss: 0.5023 - val_acc: 0.9205\n",
            "Epoch 731/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0298 - acc: 0.9891 - val_loss: 0.5045 - val_acc: 0.9161\n",
            "Epoch 732/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0308 - acc: 0.9866 - val_loss: 0.5198 - val_acc: 0.9180\n",
            "Epoch 733/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0237 - acc: 0.9907 - val_loss: 0.5182 - val_acc: 0.9167\n",
            "Epoch 734/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0278 - acc: 0.9891 - val_loss: 0.5095 - val_acc: 0.9167\n",
            "Epoch 735/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0364 - acc: 0.9866 - val_loss: 0.5115 - val_acc: 0.9192\n",
            "Epoch 736/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0298 - acc: 0.9897 - val_loss: 0.4892 - val_acc: 0.9167\n",
            "Epoch 737/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0258 - acc: 0.9910 - val_loss: 0.5150 - val_acc: 0.9192\n",
            "Epoch 738/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0270 - acc: 0.9907 - val_loss: 0.5134 - val_acc: 0.9192\n",
            "Epoch 739/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0305 - acc: 0.9879 - val_loss: 0.5074 - val_acc: 0.9174\n",
            "Epoch 740/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0240 - acc: 0.9913 - val_loss: 0.5331 - val_acc: 0.9186\n",
            "Epoch 741/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0297 - acc: 0.9876 - val_loss: 0.5182 - val_acc: 0.9211\n",
            "Epoch 742/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0275 - acc: 0.9897 - val_loss: 0.5171 - val_acc: 0.9174\n",
            "Epoch 743/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0250 - acc: 0.9904 - val_loss: 0.5430 - val_acc: 0.9167\n",
            "Epoch 744/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0284 - acc: 0.9916 - val_loss: 0.5241 - val_acc: 0.9167\n",
            "Epoch 745/800\n",
            "3217/3217 [==============================] - 0s 109us/step - loss: 0.0324 - acc: 0.9882 - val_loss: 0.5355 - val_acc: 0.9211\n",
            "Epoch 746/800\n",
            "3217/3217 [==============================] - 0s 110us/step - loss: 0.0362 - acc: 0.9876 - val_loss: 0.5107 - val_acc: 0.9192\n",
            "Epoch 747/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0367 - acc: 0.9869 - val_loss: 0.5291 - val_acc: 0.9199\n",
            "Epoch 748/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0255 - acc: 0.9901 - val_loss: 0.5235 - val_acc: 0.9205\n",
            "Epoch 749/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0299 - acc: 0.9876 - val_loss: 0.5178 - val_acc: 0.9180\n",
            "Epoch 750/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0291 - acc: 0.9879 - val_loss: 0.5234 - val_acc: 0.9224\n",
            "Epoch 751/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0272 - acc: 0.9904 - val_loss: 0.5049 - val_acc: 0.9192\n",
            "Epoch 752/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0257 - acc: 0.9888 - val_loss: 0.5176 - val_acc: 0.9174\n",
            "Epoch 753/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0260 - acc: 0.9907 - val_loss: 0.4997 - val_acc: 0.9205\n",
            "Epoch 754/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0262 - acc: 0.9935 - val_loss: 0.4953 - val_acc: 0.9186\n",
            "Epoch 755/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0301 - acc: 0.9879 - val_loss: 0.4960 - val_acc: 0.9218\n",
            "Epoch 756/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0296 - acc: 0.9888 - val_loss: 0.5177 - val_acc: 0.9256\n",
            "Epoch 757/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0253 - acc: 0.9907 - val_loss: 0.5042 - val_acc: 0.9211\n",
            "Epoch 758/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0292 - acc: 0.9901 - val_loss: 0.4997 - val_acc: 0.9256\n",
            "Epoch 759/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0239 - acc: 0.9922 - val_loss: 0.4990 - val_acc: 0.9218\n",
            "Epoch 760/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0254 - acc: 0.9907 - val_loss: 0.5100 - val_acc: 0.9180\n",
            "Epoch 761/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0303 - acc: 0.9910 - val_loss: 0.4941 - val_acc: 0.9205\n",
            "Epoch 762/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0249 - acc: 0.9904 - val_loss: 0.5034 - val_acc: 0.9199\n",
            "Epoch 763/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0257 - acc: 0.9891 - val_loss: 0.5002 - val_acc: 0.9237\n",
            "Epoch 764/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0279 - acc: 0.9904 - val_loss: 0.4979 - val_acc: 0.9205\n",
            "Epoch 765/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0209 - acc: 0.9932 - val_loss: 0.5092 - val_acc: 0.9167\n",
            "Epoch 766/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0295 - acc: 0.9894 - val_loss: 0.5160 - val_acc: 0.9186\n",
            "Epoch 767/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0291 - acc: 0.9876 - val_loss: 0.5174 - val_acc: 0.9243\n",
            "Epoch 768/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0276 - acc: 0.9897 - val_loss: 0.4979 - val_acc: 0.9199\n",
            "Epoch 769/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0240 - acc: 0.9919 - val_loss: 0.5126 - val_acc: 0.9211\n",
            "Epoch 770/800\n",
            "3217/3217 [==============================] - 0s 108us/step - loss: 0.0244 - acc: 0.9913 - val_loss: 0.5059 - val_acc: 0.9224\n",
            "Epoch 771/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0250 - acc: 0.9925 - val_loss: 0.5179 - val_acc: 0.9256\n",
            "Epoch 772/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0234 - acc: 0.9910 - val_loss: 0.5151 - val_acc: 0.9224\n",
            "Epoch 773/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0222 - acc: 0.9922 - val_loss: 0.5193 - val_acc: 0.9224\n",
            "Epoch 774/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0234 - acc: 0.9913 - val_loss: 0.5234 - val_acc: 0.9237\n",
            "Epoch 775/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0251 - acc: 0.9913 - val_loss: 0.5304 - val_acc: 0.9199\n",
            "Epoch 776/800\n",
            "3217/3217 [==============================] - 0s 112us/step - loss: 0.0240 - acc: 0.9897 - val_loss: 0.5351 - val_acc: 0.9192\n",
            "Epoch 777/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0260 - acc: 0.9897 - val_loss: 0.5278 - val_acc: 0.9205\n",
            "Epoch 778/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0260 - acc: 0.9916 - val_loss: 0.5477 - val_acc: 0.9230\n",
            "Epoch 779/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0288 - acc: 0.9891 - val_loss: 0.5362 - val_acc: 0.9218\n",
            "Epoch 780/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0216 - acc: 0.9919 - val_loss: 0.5440 - val_acc: 0.9186\n",
            "Epoch 781/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0309 - acc: 0.9907 - val_loss: 0.5251 - val_acc: 0.9174\n",
            "Epoch 782/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0269 - acc: 0.9907 - val_loss: 0.5376 - val_acc: 0.9211\n",
            "Epoch 783/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.0288 - acc: 0.9894 - val_loss: 0.5163 - val_acc: 0.9192\n",
            "Epoch 784/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0255 - acc: 0.9910 - val_loss: 0.5126 - val_acc: 0.9237\n",
            "Epoch 785/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0205 - acc: 0.9929 - val_loss: 0.5191 - val_acc: 0.9205\n",
            "Epoch 786/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0295 - acc: 0.9913 - val_loss: 0.4941 - val_acc: 0.9199\n",
            "Epoch 787/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0274 - acc: 0.9907 - val_loss: 0.5149 - val_acc: 0.9211\n",
            "Epoch 788/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0198 - acc: 0.9916 - val_loss: 0.5149 - val_acc: 0.9230\n",
            "Epoch 789/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0224 - acc: 0.9919 - val_loss: 0.5310 - val_acc: 0.9218\n",
            "Epoch 790/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0364 - acc: 0.9873 - val_loss: 0.5269 - val_acc: 0.9243\n",
            "Epoch 791/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0281 - acc: 0.9873 - val_loss: 0.5333 - val_acc: 0.9224\n",
            "Epoch 792/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0269 - acc: 0.9885 - val_loss: 0.5467 - val_acc: 0.9205\n",
            "Epoch 793/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0258 - acc: 0.9907 - val_loss: 0.5212 - val_acc: 0.9237\n",
            "Epoch 794/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0270 - acc: 0.9897 - val_loss: 0.5477 - val_acc: 0.9167\n",
            "Epoch 795/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0227 - acc: 0.9929 - val_loss: 0.5379 - val_acc: 0.9218\n",
            "Epoch 796/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0262 - acc: 0.9876 - val_loss: 0.5259 - val_acc: 0.9262\n",
            "Epoch 797/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0258 - acc: 0.9907 - val_loss: 0.5338 - val_acc: 0.9205\n",
            "Epoch 798/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0305 - acc: 0.9866 - val_loss: 0.5275 - val_acc: 0.9211\n",
            "Epoch 799/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0280 - acc: 0.9910 - val_loss: 0.5237 - val_acc: 0.9256\n",
            "Epoch 800/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0327 - acc: 0.9894 - val_loss: 0.5358 - val_acc: 0.9224\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff023939128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "C76Kfm_Z8ryl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "85caf6b7-3bd9-4052-b37a-1e5213d9124b"
      },
      "cell_type": "code",
      "source": [
        "! pip install spotipy"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spotipy\n",
            "  Downloading https://files.pythonhosted.org/packages/59/46/3c957255c96910a8a0e2d9c25db1de51a8676ebba01d7966bedc6e748822/spotipy-2.4.4.tar.gz\n",
            "Requirement already satisfied: requests>=1.0 in /usr/local/lib/python3.6/dist-packages (from spotipy) (2.18.4)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=1.0->spotipy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=1.0->spotipy) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=1.0->spotipy) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=1.0->spotipy) (2.6)\n",
            "Building wheels for collected packages: spotipy\n",
            "  Building wheel for spotipy (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/76/28/19/a86ca9bb0e32dbd4a4f580870250f5aeef852870578e0427e6\n",
            "Successfully built spotipy\n",
            "Installing collected packages: spotipy\n",
            "Successfully installed spotipy-2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1NjoXc2F80qK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import spotipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CihpWXaQ829O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
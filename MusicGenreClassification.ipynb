{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusicGenreClassification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhyatiMahendru/MusicGenreClassification/blob/master/MusicGenreClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "gz4XqyDOPKxW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Music Genre Classification: Rock v/s Hip-Hop"
      ]
    },
    {
      "metadata": {
        "id": "iEe-LLrVw7LB",
        "colab_type": "code",
        "outputId": "d1939d9e-651b-4403-fd29-09a390941db3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#importing required dependencies and libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "hxiXRhnsxCjz",
        "colab_type": "code",
        "outputId": "b071af43-fdc4-4d38-d212-509f8c00f582",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-793c6b56-689a-465b-926a-0a40a7162f5f\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-793c6b56-689a-465b-926a-0a40a7162f5f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving echonest-metrics.json to echonest-metrics.json\n",
            "Saving fma-rock-vs-hiphop.csv to fma-rock-vs-hiphop.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wuPDweXrV_mt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Collecting dataset"
      ]
    },
    {
      "metadata": {
        "id": "a9By7kDAxGRF",
        "colab_type": "code",
        "outputId": "a1f6259c-7084-4b51-a8ae-bf4a48596b1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "# meta-data file\n",
        "tracks = pd.read_csv(io.BytesIO(uploaded['fma-rock-vs-hiphop.csv']))\n",
        "\n",
        "# metrics file\n",
        "echonest_metrics = pd.read_json(io.BytesIO(uploaded['echonest-metrics.json']))\n",
        "\n",
        "#merging to get final data-set\n",
        "echo_tracks = pd.merge(echonest_metrics, tracks[[\"track_id\", \"genre_top\"]], on = \"track_id\")\n",
        "echo_tracks.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 4802 entries, 0 to 4801\n",
            "Data columns (total 10 columns):\n",
            "track_id            4802 non-null int64\n",
            "acousticness        4802 non-null float64\n",
            "danceability        4802 non-null float64\n",
            "energy              4802 non-null float64\n",
            "instrumentalness    4802 non-null float64\n",
            "liveness            4802 non-null float64\n",
            "speechiness         4802 non-null float64\n",
            "tempo               4802 non-null float64\n",
            "valence             4802 non-null float64\n",
            "genre_top           4802 non-null object\n",
            "dtypes: float64(8), int64(1), object(1)\n",
            "memory usage: 412.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BxHybYtmV1JO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Correlation Analysis"
      ]
    },
    {
      "metadata": {
        "id": "xyvZkfIOxrJq",
        "colab_type": "code",
        "outputId": "a715df0f-82a6-4d1c-e5db-4659469545ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "cell_type": "code",
      "source": [
        "corr_metrics = echo_tracks.corr()\n",
        "corr_metrics.style.background_gradient()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row0_col0 {\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row0_col1 {\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row0_col2 {\n",
              "            background-color:  #d2d2e7;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row0_col3 {\n",
              "            background-color:  #b5c4df;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row0_col4 {\n",
              "            background-color:  #f5eef6;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row0_col5 {\n",
              "            background-color:  #e9e5f1;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row0_col6 {\n",
              "            background-color:  #d1d2e6;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row0_col7 {\n",
              "            background-color:  #e1dfed;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row0_col8 {\n",
              "            background-color:  #dedcec;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row1_col0 {\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row1_col1 {\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row1_col2 {\n",
              "            background-color:  #e0dded;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row1_col3 {\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row1_col4 {\n",
              "            background-color:  #97b7d7;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row1_col5 {\n",
              "            background-color:  #f3edf5;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row1_col6 {\n",
              "            background-color:  #b8c6e0;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row1_col7 {\n",
              "            background-color:  #e1dfed;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row1_col8 {\n",
              "            background-color:  #e2dfee;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row2_col0 {\n",
              "            background-color:  #bdc8e1;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row2_col1 {\n",
              "            background-color:  #d0d1e6;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row2_col2 {\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row2_col3 {\n",
              "            background-color:  #fbf3f9;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row2_col4 {\n",
              "            background-color:  #f3edf5;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row2_col5 {\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row2_col6 {\n",
              "            background-color:  #80aed2;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row2_col7 {\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row2_col8 {\n",
              "            background-color:  #529bc7;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row3_col0 {\n",
              "            background-color:  #a7bddb;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row3_col1 {\n",
              "            background-color:  #f5eff6;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row3_col2 {\n",
              "            background-color:  #fef6fa;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row3_col3 {\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row3_col4 {\n",
              "            background-color:  #c4cbe3;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row3_col5 {\n",
              "            background-color:  #dcdaeb;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row3_col6 {\n",
              "            background-color:  #dedcec;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row3_col7 {\n",
              "            background-color:  #adc1dd;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row3_col8 {\n",
              "            background-color:  #d9d8ea;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row4_col0 {\n",
              "            background-color:  #f4eef6;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row4_col1 {\n",
              "            background-color:  #97b7d7;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row4_col2 {\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row4_col3 {\n",
              "            background-color:  #d2d3e7;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row4_col4 {\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row4_col5 {\n",
              "            background-color:  #fdf5fa;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row4_col6 {\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row4_col7 {\n",
              "            background-color:  #d9d8ea;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row4_col8 {\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row5_col0 {\n",
              "            background-color:  #bdc8e1;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row5_col1 {\n",
              "            background-color:  #ced0e6;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row5_col2 {\n",
              "            background-color:  #ede8f3;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row5_col3 {\n",
              "            background-color:  #bdc8e1;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row5_col4 {\n",
              "            background-color:  #dbdaeb;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row5_col5 {\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row5_col6 {\n",
              "            background-color:  #c0c9e2;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row5_col7 {\n",
              "            background-color:  #dcdaeb;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row5_col8 {\n",
              "            background-color:  #e8e4f0;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row6_col0 {\n",
              "            background-color:  #d0d1e6;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row6_col1 {\n",
              "            background-color:  #b8c6e0;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row6_col2 {\n",
              "            background-color:  #93b5d6;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row6_col3 {\n",
              "            background-color:  #eae6f1;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row6_col4 {\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row6_col5 {\n",
              "            background-color:  #eae6f1;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row6_col6 {\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row6_col7 {\n",
              "            background-color:  #dbdaeb;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row6_col8 {\n",
              "            background-color:  #bfc9e1;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row7_col0 {\n",
              "            background-color:  #d0d1e6;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row7_col1 {\n",
              "            background-color:  #d0d1e6;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row7_col2 {\n",
              "            background-color:  #fef6fa;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row7_col3 {\n",
              "            background-color:  #a7bddb;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row7_col4 {\n",
              "            background-color:  #c5cce3;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row7_col5 {\n",
              "            background-color:  #f0eaf4;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row7_col6 {\n",
              "            background-color:  #c8cde4;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row7_col7 {\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row7_col8 {\n",
              "            background-color:  #d6d6e9;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row8_col0 {\n",
              "            background-color:  #c6cce3;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row8_col1 {\n",
              "            background-color:  #cdd0e5;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row8_col2 {\n",
              "            background-color:  #4c99c5;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row8_col3 {\n",
              "            background-color:  #d1d2e6;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row8_col4 {\n",
              "            background-color:  #efe9f3;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row8_col5 {\n",
              "            background-color:  #f7f0f7;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row8_col6 {\n",
              "            background-color:  #a5bddb;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row8_col7 {\n",
              "            background-color:  #d3d4e7;\n",
              "            color:  #000000;\n",
              "        }    #T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row8_col8 {\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }</style><table id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >track_id</th>        <th class=\"col_heading level0 col1\" >acousticness</th>        <th class=\"col_heading level0 col2\" >danceability</th>        <th class=\"col_heading level0 col3\" >energy</th>        <th class=\"col_heading level0 col4\" >instrumentalness</th>        <th class=\"col_heading level0 col5\" >liveness</th>        <th class=\"col_heading level0 col6\" >speechiness</th>        <th class=\"col_heading level0 col7\" >tempo</th>        <th class=\"col_heading level0 col8\" >valence</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >track_id</th>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row0_col0\" class=\"data row0 col0\" >1</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row0_col1\" class=\"data row0 col1\" >-0.372282</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row0_col2\" class=\"data row0 col2\" >0.0494541</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row0_col3\" class=\"data row0 col3\" >0.140703</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row0_col4\" class=\"data row0 col4\" >-0.275623</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row0_col5\" class=\"data row0 col5\" >0.0482307</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row0_col6\" class=\"data row0 col6\" >-0.0269951</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row0_col7\" class=\"data row0 col7\" >-0.0253918</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row0_col8\" class=\"data row0 col8\" >0.0100698</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >acousticness</th>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row1_col0\" class=\"data row1 col0\" >-0.372282</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row1_col1\" class=\"data row1 col1\" >1</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row1_col2\" class=\"data row1 col2\" >-0.0289537</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row1_col3\" class=\"data row1 col3\" >-0.281619</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row1_col4\" class=\"data row1 col4\" >0.19478</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row1_col5\" class=\"data row1 col5\" >-0.0199914</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row1_col6\" class=\"data row1 col6\" >0.072204</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row1_col7\" class=\"data row1 col7\" >-0.0263097</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row1_col8\" class=\"data row1 col8\" >-0.0138406</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >danceability</th>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row2_col0\" class=\"data row2 col0\" >0.0494541</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row2_col1\" class=\"data row2 col1\" >-0.0289537</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row2_col2\" class=\"data row2 col2\" >1</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row2_col3\" class=\"data row2 col3\" >-0.242032</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row2_col4\" class=\"data row2 col4\" >-0.255217</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row2_col5\" class=\"data row2 col5\" >-0.106584</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row2_col6\" class=\"data row2 col6\" >0.276206</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row2_col7\" class=\"data row2 col7\" >-0.242089</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row2_col8\" class=\"data row2 col8\" >0.473165</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >energy</th>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row3_col0\" class=\"data row3 col0\" >0.140703</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row3_col1\" class=\"data row3 col1\" >-0.281619</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row3_col2\" class=\"data row3 col2\" >-0.242032</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row3_col3\" class=\"data row3 col3\" >1</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row3_col4\" class=\"data row3 col4\" >0.0282377</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row3_col5\" class=\"data row3 col5\" >0.113331</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row3_col6\" class=\"data row3 col6\" >-0.109983</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row3_col7\" class=\"data row3 col7\" >0.195227</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row3_col8\" class=\"data row3 col8\" >0.0386027</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >instrumentalness</th>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row4_col0\" class=\"data row4 col0\" >-0.275623</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row4_col1\" class=\"data row4 col1\" >0.19478</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row4_col2\" class=\"data row4 col2\" >-0.255217</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row4_col3\" class=\"data row4 col3\" >0.0282377</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row4_col4\" class=\"data row4 col4\" >1</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row4_col5\" class=\"data row4 col5\" >-0.0910218</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row4_col6\" class=\"data row4 col6\" >-0.366762</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row4_col7\" class=\"data row4 col7\" >0.022215</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row4_col8\" class=\"data row4 col8\" >-0.219967</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >liveness</th>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row5_col0\" class=\"data row5 col0\" >0.0482307</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row5_col1\" class=\"data row5 col1\" >-0.0199914</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row5_col2\" class=\"data row5 col2\" >-0.106584</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row5_col3\" class=\"data row5 col3\" >0.113331</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row5_col4\" class=\"data row5 col4\" >-0.0910218</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row5_col5\" class=\"data row5 col5\" >1</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row5_col6\" class=\"data row5 col6\" >0.0411725</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row5_col7\" class=\"data row5 col7\" >0.00273169</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row5_col8\" class=\"data row5 col8\" >-0.0450931</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >speechiness</th>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row6_col0\" class=\"data row6 col0\" >-0.0269951</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row6_col1\" class=\"data row6 col1\" >0.072204</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row6_col2\" class=\"data row6 col2\" >0.276206</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row6_col3\" class=\"data row6 col3\" >-0.109983</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row6_col4\" class=\"data row6 col4\" >-0.366762</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row6_col5\" class=\"data row6 col5\" >0.0411725</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row6_col6\" class=\"data row6 col6\" >1</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row6_col7\" class=\"data row6 col7\" >0.00824055</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row6_col8\" class=\"data row6 col8\" >0.149894</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >tempo</th>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row7_col0\" class=\"data row7 col0\" >-0.0253918</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row7_col1\" class=\"data row7 col1\" >-0.0263097</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row7_col2\" class=\"data row7 col2\" >-0.242089</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row7_col3\" class=\"data row7 col3\" >0.195227</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row7_col4\" class=\"data row7 col4\" >0.022215</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row7_col5\" class=\"data row7 col5\" >0.00273169</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row7_col6\" class=\"data row7 col6\" >0.00824055</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row7_col7\" class=\"data row7 col7\" >1</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row7_col8\" class=\"data row7 col8\" >0.0522212</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >valence</th>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row8_col0\" class=\"data row8 col0\" >0.0100698</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row8_col1\" class=\"data row8 col1\" >-0.0138406</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row8_col2\" class=\"data row8 col2\" >0.473165</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row8_col3\" class=\"data row8 col3\" >0.0386027</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row8_col4\" class=\"data row8 col4\" >-0.219967</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row8_col5\" class=\"data row8 col5\" >-0.0450931</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row8_col6\" class=\"data row8 col6\" >0.149894</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row8_col7\" class=\"data row8 col7\" >0.0522212</td>\n",
              "                        <td id=\"T_aa61ebdc_6670_11e9_a0b3_0242ac1c0002row8_col8\" class=\"data row8 col8\" >1</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fd02dedb0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "B6P-NNpMWJOk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Creating training and testing datasets"
      ]
    },
    {
      "metadata": {
        "id": "IPeLUYtEzdpQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = echo_tracks.drop(['track_id','genre_top'], axis = 1)\n",
        "Y = echo_tracks.loc[:, 'genre_top']\n",
        "trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.33, random_state = 33, stratify = Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uOxgHgoCWUkW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Normalising the independent variables"
      ]
    },
    {
      "metadata": {
        "id": "q28lrBwZz3VF",
        "colab_type": "code",
        "outputId": "d7892f49-e109-46b7-fab7-e00a63171f86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "trainX = scaler.fit_transform(trainX)\n",
        "testX = scaler.transform(testX)\n",
        "echo_tracks.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>track_id</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>liveness</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "      <th>valence</th>\n",
              "      <th>genre_top</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0.416675</td>\n",
              "      <td>0.675894</td>\n",
              "      <td>0.634476</td>\n",
              "      <td>0.010628</td>\n",
              "      <td>0.177647</td>\n",
              "      <td>0.159310</td>\n",
              "      <td>165.922</td>\n",
              "      <td>0.576661</td>\n",
              "      <td>Hip-Hop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0.374408</td>\n",
              "      <td>0.528643</td>\n",
              "      <td>0.817461</td>\n",
              "      <td>0.001851</td>\n",
              "      <td>0.105880</td>\n",
              "      <td>0.461818</td>\n",
              "      <td>126.957</td>\n",
              "      <td>0.269240</td>\n",
              "      <td>Hip-Hop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>341</td>\n",
              "      <td>0.977282</td>\n",
              "      <td>0.468808</td>\n",
              "      <td>0.134975</td>\n",
              "      <td>0.687700</td>\n",
              "      <td>0.105381</td>\n",
              "      <td>0.073124</td>\n",
              "      <td>119.646</td>\n",
              "      <td>0.430707</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>46204</td>\n",
              "      <td>0.953349</td>\n",
              "      <td>0.498525</td>\n",
              "      <td>0.552503</td>\n",
              "      <td>0.924391</td>\n",
              "      <td>0.684914</td>\n",
              "      <td>0.028885</td>\n",
              "      <td>78.958</td>\n",
              "      <td>0.430448</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>46205</td>\n",
              "      <td>0.613229</td>\n",
              "      <td>0.500320</td>\n",
              "      <td>0.487992</td>\n",
              "      <td>0.936811</td>\n",
              "      <td>0.637750</td>\n",
              "      <td>0.030327</td>\n",
              "      <td>112.667</td>\n",
              "      <td>0.824749</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   track_id  acousticness  danceability    energy  instrumentalness  liveness  \\\n",
              "0         2      0.416675      0.675894  0.634476          0.010628  0.177647   \n",
              "1         3      0.374408      0.528643  0.817461          0.001851  0.105880   \n",
              "2       341      0.977282      0.468808  0.134975          0.687700  0.105381   \n",
              "3     46204      0.953349      0.498525  0.552503          0.924391  0.684914   \n",
              "4     46205      0.613229      0.500320  0.487992          0.936811  0.637750   \n",
              "\n",
              "   speechiness    tempo   valence genre_top  \n",
              "0     0.159310  165.922  0.576661   Hip-Hop  \n",
              "1     0.461818  126.957  0.269240   Hip-Hop  \n",
              "2     0.073124  119.646  0.430707      Rock  \n",
              "3     0.028885   78.958  0.430448      Rock  \n",
              "4     0.030327  112.667  0.824749      Rock  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "emA5LjngbLfv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ]
    },
    {
      "metadata": {
        "id": "1czQK53dWjzl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1. Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "K0-olbGUz7-B",
        "colab_type": "code",
        "outputId": "647c8b60-eb1a-45a0-ae79-cf715f756cbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf1 = LogisticRegression(random_state = 0, max_iter = 1000, solver = 'lbfgs')\n",
        "clf1.fit(trainX, trainY)\n",
        "pred1 = clf1.predict(testX)\n",
        "print(\"Accuracy Score using Logistic Regression = \", accuracy_score(testY, pred1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score using Logistic Regression =  0.9022082018927445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aXMXl4PxW343",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. Decision Tree Classifier"
      ]
    },
    {
      "metadata": {
        "id": "uRdB7Quy0quo",
        "colab_type": "code",
        "outputId": "da97bf41-e25d-4142-c57b-883707347962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf2 = DecisionTreeClassifier()\n",
        "clf2.fit(trainX, trainY)\n",
        "pred2 = clf2.predict(testX)\n",
        "print(\"Accuracy Score using Decision Tree Classifier = \", accuracy_score(testY, pred2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score using Decision Tree Classifier =  0.8769716088328076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wufAwjKoW_rO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. k-Nearest Neighbors"
      ]
    },
    {
      "metadata": {
        "id": "j0CkZJ8q0unG",
        "colab_type": "code",
        "outputId": "07c8a421-670f-42c9-dcc4-ab2847505506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf3 = KNeighborsClassifier(n_neighbors = 10)\n",
        "clf3.fit(trainX, trainY)\n",
        "pred3 = clf3.predict(testX)\n",
        "print(\"Accuracy Score using kNN (k = 10) = \", accuracy_score(testY, pred3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score using kNN (k = 10) =  0.9141955835962146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kS0qiReEXdOg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4. Naive Bayes Classifier"
      ]
    },
    {
      "metadata": {
        "id": "P9IZyc-1068h",
        "colab_type": "code",
        "outputId": "c88c94fd-333b-4958-a421-1be751081d92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf4 = GaussianNB()\n",
        "clf4.fit(trainX, trainY)\n",
        "pred4 = clf4.predict(testX)\n",
        "print(\"Accuracy Score using Naive Baiyes Classifier = \", accuracy_score(testY, pred4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score using Naive Baiyes Classifier =  0.8958990536277602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KTh0vuQ4XpzM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 5. Support Vector Machine Classifier"
      ]
    },
    {
      "metadata": {
        "id": "xty387Wi1SG2",
        "colab_type": "code",
        "outputId": "5d3658b6-484d-40a7-cf08-649d22446a03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf3 = SVC(gamma='scale', decision_function_shape='ovo')\n",
        "clf3.fit(trainX, trainY)\n",
        "pred3 = clf3.predict(testX)\n",
        "print(\"Accuracy Score using Support Vector Machine Classifier = \", accuracy_score(testY, pred3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score using Support Vector Machine Classifier =  0.9211356466876972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Z9jV7S1X-WS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 6. Multi Layer Perceptron"
      ]
    },
    {
      "metadata": {
        "id": "hzu3kN0Q1WYI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# setting seed for replicating results\n",
        "np.random.seed(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6K5izl5W1Zbd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(trainY)\n",
        "encoded_Y = encoder.transform(trainY)\n",
        "encoded_test_Y = encoder.transform(testY)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)\n",
        "dummy_test_y = np_utils.to_categorical(encoded_test_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CjTc5zz81iVa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# building the model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_shape=(8,))) #8 features\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(2))                     #2 classes\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x4LIfWO51nem",
        "colab_type": "code",
        "outputId": "b4c2c6fb-5e8b-40dc-f951-588bfdbd33c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 27322
        }
      },
      "cell_type": "code",
      "source": [
        "#Training the model, simultanoeusly validating\n",
        "model.fit(trainX, dummy_y, epochs=800, batch_size = 32, validation_data=(testX, dummy_test_y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 3217 samples, validate on 1585 samples\n",
            "Epoch 1/800\n",
            "3217/3217 [==============================] - 1s 311us/step - loss: 0.4078 - acc: 0.8241 - val_loss: 0.2517 - val_acc: 0.9066\n",
            "Epoch 2/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.2882 - acc: 0.8865 - val_loss: 0.2298 - val_acc: 0.9117\n",
            "Epoch 3/800\n",
            "3217/3217 [==============================] - 0s 109us/step - loss: 0.2630 - acc: 0.8962 - val_loss: 0.2127 - val_acc: 0.9155\n",
            "Epoch 4/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.2451 - acc: 0.9033 - val_loss: 0.2172 - val_acc: 0.9148\n",
            "Epoch 5/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.2467 - acc: 0.9024 - val_loss: 0.2054 - val_acc: 0.9205\n",
            "Epoch 6/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.2324 - acc: 0.9077 - val_loss: 0.2026 - val_acc: 0.9243\n",
            "Epoch 7/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.2307 - acc: 0.9117 - val_loss: 0.2009 - val_acc: 0.9211\n",
            "Epoch 8/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.2264 - acc: 0.9148 - val_loss: 0.2032 - val_acc: 0.9186\n",
            "Epoch 9/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.2234 - acc: 0.9127 - val_loss: 0.1949 - val_acc: 0.9249\n",
            "Epoch 10/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.2162 - acc: 0.9186 - val_loss: 0.2128 - val_acc: 0.9167\n",
            "Epoch 11/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.2167 - acc: 0.9145 - val_loss: 0.1944 - val_acc: 0.9256\n",
            "Epoch 12/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.2153 - acc: 0.9192 - val_loss: 0.2016 - val_acc: 0.9192\n",
            "Epoch 13/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.2127 - acc: 0.9158 - val_loss: 0.1918 - val_acc: 0.9249\n",
            "Epoch 14/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.2068 - acc: 0.9223 - val_loss: 0.2043 - val_acc: 0.9199\n",
            "Epoch 15/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.2094 - acc: 0.9189 - val_loss: 0.1928 - val_acc: 0.9262\n",
            "Epoch 16/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.2044 - acc: 0.9226 - val_loss: 0.1934 - val_acc: 0.9256\n",
            "Epoch 17/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.2046 - acc: 0.9242 - val_loss: 0.1974 - val_acc: 0.9230\n",
            "Epoch 18/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.2039 - acc: 0.9229 - val_loss: 0.1957 - val_acc: 0.9249\n",
            "Epoch 19/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.2074 - acc: 0.9201 - val_loss: 0.1960 - val_acc: 0.9249\n",
            "Epoch 20/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.2001 - acc: 0.9242 - val_loss: 0.1916 - val_acc: 0.9249\n",
            "Epoch 21/800\n",
            "3217/3217 [==============================] - 0s 108us/step - loss: 0.1981 - acc: 0.9238 - val_loss: 0.1870 - val_acc: 0.9287\n",
            "Epoch 22/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1952 - acc: 0.9245 - val_loss: 0.1895 - val_acc: 0.9281\n",
            "Epoch 23/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.2014 - acc: 0.9254 - val_loss: 0.1861 - val_acc: 0.9287\n",
            "Epoch 24/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.1956 - acc: 0.9251 - val_loss: 0.1872 - val_acc: 0.9268\n",
            "Epoch 25/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1934 - acc: 0.9257 - val_loss: 0.1852 - val_acc: 0.9306\n",
            "Epoch 26/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1939 - acc: 0.9254 - val_loss: 0.1995 - val_acc: 0.9211\n",
            "Epoch 27/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1916 - acc: 0.9248 - val_loss: 0.1852 - val_acc: 0.9268\n",
            "Epoch 28/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1932 - acc: 0.9260 - val_loss: 0.1935 - val_acc: 0.9243\n",
            "Epoch 29/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1909 - acc: 0.9260 - val_loss: 0.1894 - val_acc: 0.9262\n",
            "Epoch 30/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1905 - acc: 0.9270 - val_loss: 0.1860 - val_acc: 0.9287\n",
            "Epoch 31/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1861 - acc: 0.9276 - val_loss: 0.1867 - val_acc: 0.9287\n",
            "Epoch 32/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1872 - acc: 0.9279 - val_loss: 0.1870 - val_acc: 0.9268\n",
            "Epoch 33/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.1854 - acc: 0.9279 - val_loss: 0.1844 - val_acc: 0.9300\n",
            "Epoch 34/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1823 - acc: 0.9276 - val_loss: 0.1928 - val_acc: 0.9256\n",
            "Epoch 35/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1833 - acc: 0.9301 - val_loss: 0.1982 - val_acc: 0.9249\n",
            "Epoch 36/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1853 - acc: 0.9288 - val_loss: 0.1857 - val_acc: 0.9306\n",
            "Epoch 37/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1839 - acc: 0.9270 - val_loss: 0.1949 - val_acc: 0.9262\n",
            "Epoch 38/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.1852 - acc: 0.9301 - val_loss: 0.1865 - val_acc: 0.9274\n",
            "Epoch 39/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1809 - acc: 0.9304 - val_loss: 0.1829 - val_acc: 0.9319\n",
            "Epoch 40/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1801 - acc: 0.9341 - val_loss: 0.1889 - val_acc: 0.9262\n",
            "Epoch 41/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1807 - acc: 0.9301 - val_loss: 0.1921 - val_acc: 0.9287\n",
            "Epoch 42/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1794 - acc: 0.9329 - val_loss: 0.1859 - val_acc: 0.9287\n",
            "Epoch 43/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1775 - acc: 0.9332 - val_loss: 0.1961 - val_acc: 0.9274\n",
            "Epoch 44/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1788 - acc: 0.9322 - val_loss: 0.1857 - val_acc: 0.9344\n",
            "Epoch 45/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1731 - acc: 0.9325 - val_loss: 0.1884 - val_acc: 0.9319\n",
            "Epoch 46/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1766 - acc: 0.9350 - val_loss: 0.1942 - val_acc: 0.9268\n",
            "Epoch 47/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1796 - acc: 0.9313 - val_loss: 0.1939 - val_acc: 0.9249\n",
            "Epoch 48/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.1717 - acc: 0.9344 - val_loss: 0.1889 - val_acc: 0.9306\n",
            "Epoch 49/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1721 - acc: 0.9329 - val_loss: 0.1869 - val_acc: 0.9300\n",
            "Epoch 50/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1715 - acc: 0.9347 - val_loss: 0.1964 - val_acc: 0.9293\n",
            "Epoch 51/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1732 - acc: 0.9360 - val_loss: 0.1915 - val_acc: 0.9319\n",
            "Epoch 52/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1743 - acc: 0.9341 - val_loss: 0.1881 - val_acc: 0.9319\n",
            "Epoch 53/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1687 - acc: 0.9369 - val_loss: 0.1900 - val_acc: 0.9293\n",
            "Epoch 54/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.1698 - acc: 0.9338 - val_loss: 0.1881 - val_acc: 0.9325\n",
            "Epoch 55/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1705 - acc: 0.9363 - val_loss: 0.1915 - val_acc: 0.9306\n",
            "Epoch 56/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1709 - acc: 0.9335 - val_loss: 0.1919 - val_acc: 0.9274\n",
            "Epoch 57/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.1677 - acc: 0.9353 - val_loss: 0.1900 - val_acc: 0.9306\n",
            "Epoch 58/800\n",
            "3217/3217 [==============================] - 0s 108us/step - loss: 0.1643 - acc: 0.9350 - val_loss: 0.1961 - val_acc: 0.9300\n",
            "Epoch 59/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1684 - acc: 0.9363 - val_loss: 0.1943 - val_acc: 0.9319\n",
            "Epoch 60/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1665 - acc: 0.9403 - val_loss: 0.2016 - val_acc: 0.9256\n",
            "Epoch 61/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1660 - acc: 0.9357 - val_loss: 0.1929 - val_acc: 0.9281\n",
            "Epoch 62/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1600 - acc: 0.9400 - val_loss: 0.1927 - val_acc: 0.9319\n",
            "Epoch 63/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1616 - acc: 0.9369 - val_loss: 0.1948 - val_acc: 0.9293\n",
            "Epoch 64/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1631 - acc: 0.9403 - val_loss: 0.1914 - val_acc: 0.9319\n",
            "Epoch 65/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1597 - acc: 0.9394 - val_loss: 0.1935 - val_acc: 0.9325\n",
            "Epoch 66/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1617 - acc: 0.9391 - val_loss: 0.1907 - val_acc: 0.9306\n",
            "Epoch 67/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1658 - acc: 0.9360 - val_loss: 0.1925 - val_acc: 0.9306\n",
            "Epoch 68/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1608 - acc: 0.9369 - val_loss: 0.1947 - val_acc: 0.9306\n",
            "Epoch 69/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1629 - acc: 0.9388 - val_loss: 0.1918 - val_acc: 0.9300\n",
            "Epoch 70/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1598 - acc: 0.9397 - val_loss: 0.1926 - val_acc: 0.9312\n",
            "Epoch 71/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1603 - acc: 0.9381 - val_loss: 0.1937 - val_acc: 0.9300\n",
            "Epoch 72/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1631 - acc: 0.9338 - val_loss: 0.1959 - val_acc: 0.9274\n",
            "Epoch 73/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.1529 - acc: 0.9397 - val_loss: 0.2069 - val_acc: 0.9287\n",
            "Epoch 74/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1620 - acc: 0.9385 - val_loss: 0.1937 - val_acc: 0.9344\n",
            "Epoch 75/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1575 - acc: 0.9385 - val_loss: 0.1958 - val_acc: 0.9338\n",
            "Epoch 76/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1518 - acc: 0.9444 - val_loss: 0.1954 - val_acc: 0.9325\n",
            "Epoch 77/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1535 - acc: 0.9369 - val_loss: 0.1961 - val_acc: 0.9312\n",
            "Epoch 78/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1552 - acc: 0.9400 - val_loss: 0.1905 - val_acc: 0.9325\n",
            "Epoch 79/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1522 - acc: 0.9366 - val_loss: 0.1975 - val_acc: 0.9312\n",
            "Epoch 80/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1552 - acc: 0.9409 - val_loss: 0.2030 - val_acc: 0.9274\n",
            "Epoch 81/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1487 - acc: 0.9425 - val_loss: 0.1990 - val_acc: 0.9319\n",
            "Epoch 82/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1539 - acc: 0.9391 - val_loss: 0.1965 - val_acc: 0.9306\n",
            "Epoch 83/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1478 - acc: 0.9406 - val_loss: 0.1965 - val_acc: 0.9325\n",
            "Epoch 84/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1470 - acc: 0.9444 - val_loss: 0.2010 - val_acc: 0.9300\n",
            "Epoch 85/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1532 - acc: 0.9416 - val_loss: 0.2014 - val_acc: 0.9287\n",
            "Epoch 86/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1555 - acc: 0.9369 - val_loss: 0.2074 - val_acc: 0.9262\n",
            "Epoch 87/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1452 - acc: 0.9459 - val_loss: 0.2002 - val_acc: 0.9331\n",
            "Epoch 88/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1512 - acc: 0.9462 - val_loss: 0.2051 - val_acc: 0.9293\n",
            "Epoch 89/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1506 - acc: 0.9428 - val_loss: 0.2023 - val_acc: 0.9287\n",
            "Epoch 90/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1536 - acc: 0.9453 - val_loss: 0.2089 - val_acc: 0.9268\n",
            "Epoch 91/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1533 - acc: 0.9425 - val_loss: 0.2027 - val_acc: 0.9262\n",
            "Epoch 92/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1446 - acc: 0.9419 - val_loss: 0.2041 - val_acc: 0.9300\n",
            "Epoch 93/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1492 - acc: 0.9397 - val_loss: 0.2028 - val_acc: 0.9293\n",
            "Epoch 94/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1454 - acc: 0.9422 - val_loss: 0.1985 - val_acc: 0.9331\n",
            "Epoch 95/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1423 - acc: 0.9462 - val_loss: 0.1989 - val_acc: 0.9312\n",
            "Epoch 96/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1478 - acc: 0.9453 - val_loss: 0.2040 - val_acc: 0.9312\n",
            "Epoch 97/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1451 - acc: 0.9434 - val_loss: 0.2001 - val_acc: 0.9293\n",
            "Epoch 98/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1438 - acc: 0.9428 - val_loss: 0.2042 - val_acc: 0.9325\n",
            "Epoch 99/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1409 - acc: 0.9453 - val_loss: 0.2022 - val_acc: 0.9293\n",
            "Epoch 100/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1505 - acc: 0.9419 - val_loss: 0.1994 - val_acc: 0.9319\n",
            "Epoch 101/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1369 - acc: 0.9500 - val_loss: 0.2179 - val_acc: 0.9256\n",
            "Epoch 102/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1420 - acc: 0.9434 - val_loss: 0.2131 - val_acc: 0.9274\n",
            "Epoch 103/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1434 - acc: 0.9425 - val_loss: 0.2013 - val_acc: 0.9274\n",
            "Epoch 104/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1423 - acc: 0.9462 - val_loss: 0.2039 - val_acc: 0.9300\n",
            "Epoch 105/800\n",
            "3217/3217 [==============================] - 0s 108us/step - loss: 0.1364 - acc: 0.9459 - val_loss: 0.2118 - val_acc: 0.9256\n",
            "Epoch 106/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1371 - acc: 0.9465 - val_loss: 0.2195 - val_acc: 0.9256\n",
            "Epoch 107/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1450 - acc: 0.9440 - val_loss: 0.2081 - val_acc: 0.9300\n",
            "Epoch 108/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1409 - acc: 0.9459 - val_loss: 0.2039 - val_acc: 0.9306\n",
            "Epoch 109/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1433 - acc: 0.9481 - val_loss: 0.2097 - val_acc: 0.9274\n",
            "Epoch 110/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1463 - acc: 0.9412 - val_loss: 0.2054 - val_acc: 0.9268\n",
            "Epoch 111/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1332 - acc: 0.9496 - val_loss: 0.2048 - val_acc: 0.9300\n",
            "Epoch 112/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1407 - acc: 0.9478 - val_loss: 0.2050 - val_acc: 0.9331\n",
            "Epoch 113/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1371 - acc: 0.9456 - val_loss: 0.2052 - val_acc: 0.9312\n",
            "Epoch 114/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1355 - acc: 0.9468 - val_loss: 0.2138 - val_acc: 0.9331\n",
            "Epoch 115/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1344 - acc: 0.9509 - val_loss: 0.2096 - val_acc: 0.9281\n",
            "Epoch 116/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1322 - acc: 0.9493 - val_loss: 0.2112 - val_acc: 0.9306\n",
            "Epoch 117/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1357 - acc: 0.9515 - val_loss: 0.2073 - val_acc: 0.9331\n",
            "Epoch 118/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1336 - acc: 0.9496 - val_loss: 0.2101 - val_acc: 0.9287\n",
            "Epoch 119/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1353 - acc: 0.9465 - val_loss: 0.2089 - val_acc: 0.9281\n",
            "Epoch 120/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1354 - acc: 0.9496 - val_loss: 0.2109 - val_acc: 0.9300\n",
            "Epoch 121/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1331 - acc: 0.9490 - val_loss: 0.2143 - val_acc: 0.9287\n",
            "Epoch 122/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1318 - acc: 0.9475 - val_loss: 0.2151 - val_acc: 0.9268\n",
            "Epoch 123/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1343 - acc: 0.9462 - val_loss: 0.2218 - val_acc: 0.9249\n",
            "Epoch 124/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1364 - acc: 0.9465 - val_loss: 0.2115 - val_acc: 0.9287\n",
            "Epoch 125/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1267 - acc: 0.9481 - val_loss: 0.2214 - val_acc: 0.9281\n",
            "Epoch 126/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1379 - acc: 0.9493 - val_loss: 0.2081 - val_acc: 0.9293\n",
            "Epoch 127/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1273 - acc: 0.9518 - val_loss: 0.2132 - val_acc: 0.9300\n",
            "Epoch 128/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1291 - acc: 0.9481 - val_loss: 0.2126 - val_acc: 0.9268\n",
            "Epoch 129/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1275 - acc: 0.9509 - val_loss: 0.2110 - val_acc: 0.9281\n",
            "Epoch 130/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1334 - acc: 0.9493 - val_loss: 0.2193 - val_acc: 0.9312\n",
            "Epoch 131/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1286 - acc: 0.9487 - val_loss: 0.2144 - val_acc: 0.9249\n",
            "Epoch 132/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1299 - acc: 0.9462 - val_loss: 0.2147 - val_acc: 0.9256\n",
            "Epoch 133/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1224 - acc: 0.9515 - val_loss: 0.2231 - val_acc: 0.9274\n",
            "Epoch 134/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1314 - acc: 0.9496 - val_loss: 0.2195 - val_acc: 0.9281\n",
            "Epoch 135/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1287 - acc: 0.9487 - val_loss: 0.2153 - val_acc: 0.9287\n",
            "Epoch 136/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1258 - acc: 0.9493 - val_loss: 0.2251 - val_acc: 0.9274\n",
            "Epoch 137/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1242 - acc: 0.9531 - val_loss: 0.2206 - val_acc: 0.9293\n",
            "Epoch 138/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1235 - acc: 0.9534 - val_loss: 0.2142 - val_acc: 0.9268\n",
            "Epoch 139/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1195 - acc: 0.9521 - val_loss: 0.2245 - val_acc: 0.9300\n",
            "Epoch 140/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1280 - acc: 0.9509 - val_loss: 0.2238 - val_acc: 0.9256\n",
            "Epoch 141/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1228 - acc: 0.9506 - val_loss: 0.2301 - val_acc: 0.9281\n",
            "Epoch 142/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1248 - acc: 0.9512 - val_loss: 0.2226 - val_acc: 0.9249\n",
            "Epoch 143/800\n",
            "3217/3217 [==============================] - 0s 110us/step - loss: 0.1289 - acc: 0.9506 - val_loss: 0.2180 - val_acc: 0.9306\n",
            "Epoch 144/800\n",
            "3217/3217 [==============================] - 0s 115us/step - loss: 0.1200 - acc: 0.9549 - val_loss: 0.2222 - val_acc: 0.9256\n",
            "Epoch 145/800\n",
            "3217/3217 [==============================] - 0s 115us/step - loss: 0.1210 - acc: 0.9515 - val_loss: 0.2249 - val_acc: 0.9287\n",
            "Epoch 146/800\n",
            "3217/3217 [==============================] - 0s 116us/step - loss: 0.1165 - acc: 0.9531 - val_loss: 0.2169 - val_acc: 0.9274\n",
            "Epoch 147/800\n",
            "3217/3217 [==============================] - 0s 110us/step - loss: 0.1143 - acc: 0.9552 - val_loss: 0.2243 - val_acc: 0.9281\n",
            "Epoch 148/800\n",
            "3217/3217 [==============================] - 0s 116us/step - loss: 0.1191 - acc: 0.9521 - val_loss: 0.2210 - val_acc: 0.9262\n",
            "Epoch 149/800\n",
            "3217/3217 [==============================] - 0s 114us/step - loss: 0.1247 - acc: 0.9521 - val_loss: 0.2380 - val_acc: 0.9262\n",
            "Epoch 150/800\n",
            "3217/3217 [==============================] - 0s 115us/step - loss: 0.1269 - acc: 0.9503 - val_loss: 0.2190 - val_acc: 0.9268\n",
            "Epoch 151/800\n",
            "3217/3217 [==============================] - 0s 114us/step - loss: 0.1195 - acc: 0.9555 - val_loss: 0.2294 - val_acc: 0.9237\n",
            "Epoch 152/800\n",
            "3217/3217 [==============================] - 0s 117us/step - loss: 0.1205 - acc: 0.9521 - val_loss: 0.2260 - val_acc: 0.9262\n",
            "Epoch 153/800\n",
            "3217/3217 [==============================] - 0s 117us/step - loss: 0.1193 - acc: 0.9521 - val_loss: 0.2320 - val_acc: 0.9262\n",
            "Epoch 154/800\n",
            "3217/3217 [==============================] - 0s 115us/step - loss: 0.1160 - acc: 0.9546 - val_loss: 0.2220 - val_acc: 0.9281\n",
            "Epoch 155/800\n",
            "3217/3217 [==============================] - 0s 113us/step - loss: 0.1157 - acc: 0.9543 - val_loss: 0.2350 - val_acc: 0.9243\n",
            "Epoch 156/800\n",
            "3217/3217 [==============================] - 0s 114us/step - loss: 0.1232 - acc: 0.9540 - val_loss: 0.2250 - val_acc: 0.9274\n",
            "Epoch 157/800\n",
            "3217/3217 [==============================] - 0s 112us/step - loss: 0.1156 - acc: 0.9540 - val_loss: 0.2365 - val_acc: 0.9249\n",
            "Epoch 158/800\n",
            "3217/3217 [==============================] - 0s 114us/step - loss: 0.1167 - acc: 0.9562 - val_loss: 0.2283 - val_acc: 0.9287\n",
            "Epoch 159/800\n",
            "3217/3217 [==============================] - 0s 114us/step - loss: 0.1180 - acc: 0.9518 - val_loss: 0.2349 - val_acc: 0.9243\n",
            "Epoch 160/800\n",
            "3217/3217 [==============================] - 0s 113us/step - loss: 0.1134 - acc: 0.9562 - val_loss: 0.2340 - val_acc: 0.9287\n",
            "Epoch 161/800\n",
            "3217/3217 [==============================] - 0s 114us/step - loss: 0.1145 - acc: 0.9528 - val_loss: 0.2266 - val_acc: 0.9256\n",
            "Epoch 162/800\n",
            "3217/3217 [==============================] - 0s 116us/step - loss: 0.1116 - acc: 0.9540 - val_loss: 0.2413 - val_acc: 0.9224\n",
            "Epoch 163/800\n",
            "3217/3217 [==============================] - 0s 116us/step - loss: 0.1124 - acc: 0.9580 - val_loss: 0.2267 - val_acc: 0.9268\n",
            "Epoch 164/800\n",
            "3217/3217 [==============================] - 0s 116us/step - loss: 0.1120 - acc: 0.9555 - val_loss: 0.2371 - val_acc: 0.9256\n",
            "Epoch 165/800\n",
            "3217/3217 [==============================] - 0s 112us/step - loss: 0.1094 - acc: 0.9571 - val_loss: 0.2331 - val_acc: 0.9249\n",
            "Epoch 166/800\n",
            "3217/3217 [==============================] - 0s 114us/step - loss: 0.1125 - acc: 0.9543 - val_loss: 0.2320 - val_acc: 0.9237\n",
            "Epoch 167/800\n",
            "3217/3217 [==============================] - 0s 113us/step - loss: 0.1123 - acc: 0.9565 - val_loss: 0.2365 - val_acc: 0.9256\n",
            "Epoch 168/800\n",
            "3217/3217 [==============================] - 0s 117us/step - loss: 0.1082 - acc: 0.9587 - val_loss: 0.2422 - val_acc: 0.9268\n",
            "Epoch 169/800\n",
            "3217/3217 [==============================] - 0s 114us/step - loss: 0.1183 - acc: 0.9559 - val_loss: 0.2338 - val_acc: 0.9237\n",
            "Epoch 170/800\n",
            "3217/3217 [==============================] - 0s 114us/step - loss: 0.1146 - acc: 0.9552 - val_loss: 0.2368 - val_acc: 0.9249\n",
            "Epoch 171/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1117 - acc: 0.9546 - val_loss: 0.2321 - val_acc: 0.9249\n",
            "Epoch 172/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1105 - acc: 0.9574 - val_loss: 0.2367 - val_acc: 0.9256\n",
            "Epoch 173/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1110 - acc: 0.9555 - val_loss: 0.2441 - val_acc: 0.9224\n",
            "Epoch 174/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1094 - acc: 0.9565 - val_loss: 0.2393 - val_acc: 0.9256\n",
            "Epoch 175/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.1169 - acc: 0.9571 - val_loss: 0.2322 - val_acc: 0.9205\n",
            "Epoch 176/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1050 - acc: 0.9590 - val_loss: 0.2419 - val_acc: 0.9224\n",
            "Epoch 177/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.1044 - acc: 0.9593 - val_loss: 0.2518 - val_acc: 0.9230\n",
            "Epoch 178/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1045 - acc: 0.9587 - val_loss: 0.2431 - val_acc: 0.9199\n",
            "Epoch 179/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0985 - acc: 0.9574 - val_loss: 0.2455 - val_acc: 0.9192\n",
            "Epoch 180/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1076 - acc: 0.9571 - val_loss: 0.2437 - val_acc: 0.9230\n",
            "Epoch 181/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1003 - acc: 0.9593 - val_loss: 0.2387 - val_acc: 0.9230\n",
            "Epoch 182/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1056 - acc: 0.9608 - val_loss: 0.2507 - val_acc: 0.9211\n",
            "Epoch 183/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1052 - acc: 0.9568 - val_loss: 0.2460 - val_acc: 0.9230\n",
            "Epoch 184/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1048 - acc: 0.9590 - val_loss: 0.2450 - val_acc: 0.9218\n",
            "Epoch 185/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1128 - acc: 0.9552 - val_loss: 0.2462 - val_acc: 0.9237\n",
            "Epoch 186/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1069 - acc: 0.9580 - val_loss: 0.2445 - val_acc: 0.9237\n",
            "Epoch 187/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0981 - acc: 0.9611 - val_loss: 0.2390 - val_acc: 0.9262\n",
            "Epoch 188/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1023 - acc: 0.9596 - val_loss: 0.2530 - val_acc: 0.9230\n",
            "Epoch 189/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1069 - acc: 0.9574 - val_loss: 0.2425 - val_acc: 0.9218\n",
            "Epoch 190/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.0978 - acc: 0.9630 - val_loss: 0.2566 - val_acc: 0.9211\n",
            "Epoch 191/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.1018 - acc: 0.9596 - val_loss: 0.2462 - val_acc: 0.9224\n",
            "Epoch 192/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1074 - acc: 0.9528 - val_loss: 0.2501 - val_acc: 0.9218\n",
            "Epoch 193/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0972 - acc: 0.9624 - val_loss: 0.2476 - val_acc: 0.9243\n",
            "Epoch 194/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0990 - acc: 0.9633 - val_loss: 0.2508 - val_acc: 0.9268\n",
            "Epoch 195/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.0980 - acc: 0.9621 - val_loss: 0.2480 - val_acc: 0.9243\n",
            "Epoch 196/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.1092 - acc: 0.9555 - val_loss: 0.2554 - val_acc: 0.9218\n",
            "Epoch 197/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0985 - acc: 0.9593 - val_loss: 0.2487 - val_acc: 0.9237\n",
            "Epoch 198/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0968 - acc: 0.9602 - val_loss: 0.2546 - val_acc: 0.9230\n",
            "Epoch 199/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0966 - acc: 0.9618 - val_loss: 0.2536 - val_acc: 0.9218\n",
            "Epoch 200/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1013 - acc: 0.9602 - val_loss: 0.2485 - val_acc: 0.9237\n",
            "Epoch 201/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1041 - acc: 0.9593 - val_loss: 0.2512 - val_acc: 0.9274\n",
            "Epoch 202/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1024 - acc: 0.9608 - val_loss: 0.2468 - val_acc: 0.9237\n",
            "Epoch 203/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1021 - acc: 0.9587 - val_loss: 0.2465 - val_acc: 0.9224\n",
            "Epoch 204/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0917 - acc: 0.9646 - val_loss: 0.2576 - val_acc: 0.9230\n",
            "Epoch 205/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.1042 - acc: 0.9596 - val_loss: 0.2439 - val_acc: 0.9199\n",
            "Epoch 206/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.1004 - acc: 0.9611 - val_loss: 0.2437 - val_acc: 0.9249\n",
            "Epoch 207/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0909 - acc: 0.9633 - val_loss: 0.2599 - val_acc: 0.9268\n",
            "Epoch 208/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0915 - acc: 0.9633 - val_loss: 0.2555 - val_acc: 0.9262\n",
            "Epoch 209/800\n",
            "3217/3217 [==============================] - 0s 108us/step - loss: 0.0943 - acc: 0.9608 - val_loss: 0.2526 - val_acc: 0.9256\n",
            "Epoch 210/800\n",
            "3217/3217 [==============================] - 0s 108us/step - loss: 0.0929 - acc: 0.9608 - val_loss: 0.2558 - val_acc: 0.9230\n",
            "Epoch 211/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0918 - acc: 0.9649 - val_loss: 0.2584 - val_acc: 0.9186\n",
            "Epoch 212/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0980 - acc: 0.9608 - val_loss: 0.2538 - val_acc: 0.9237\n",
            "Epoch 213/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.1012 - acc: 0.9593 - val_loss: 0.2557 - val_acc: 0.9218\n",
            "Epoch 214/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0899 - acc: 0.9658 - val_loss: 0.2548 - val_acc: 0.9186\n",
            "Epoch 215/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0887 - acc: 0.9649 - val_loss: 0.2709 - val_acc: 0.9174\n",
            "Epoch 216/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0955 - acc: 0.9630 - val_loss: 0.2735 - val_acc: 0.9199\n",
            "Epoch 217/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0992 - acc: 0.9605 - val_loss: 0.2526 - val_acc: 0.9249\n",
            "Epoch 218/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0841 - acc: 0.9705 - val_loss: 0.2681 - val_acc: 0.9186\n",
            "Epoch 219/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0940 - acc: 0.9590 - val_loss: 0.2725 - val_acc: 0.9274\n",
            "Epoch 220/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0989 - acc: 0.9590 - val_loss: 0.2527 - val_acc: 0.9224\n",
            "Epoch 221/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0903 - acc: 0.9615 - val_loss: 0.2609 - val_acc: 0.9237\n",
            "Epoch 222/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0899 - acc: 0.9618 - val_loss: 0.2518 - val_acc: 0.9224\n",
            "Epoch 223/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0817 - acc: 0.9655 - val_loss: 0.2777 - val_acc: 0.9199\n",
            "Epoch 224/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0903 - acc: 0.9643 - val_loss: 0.2492 - val_acc: 0.9256\n",
            "Epoch 225/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0920 - acc: 0.9643 - val_loss: 0.2699 - val_acc: 0.9274\n",
            "Epoch 226/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0897 - acc: 0.9667 - val_loss: 0.2627 - val_acc: 0.9230\n",
            "Epoch 227/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0872 - acc: 0.9677 - val_loss: 0.2717 - val_acc: 0.9186\n",
            "Epoch 228/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0873 - acc: 0.9652 - val_loss: 0.2617 - val_acc: 0.9167\n",
            "Epoch 229/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0862 - acc: 0.9655 - val_loss: 0.2627 - val_acc: 0.9205\n",
            "Epoch 230/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0844 - acc: 0.9636 - val_loss: 0.2755 - val_acc: 0.9224\n",
            "Epoch 231/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0853 - acc: 0.9683 - val_loss: 0.2758 - val_acc: 0.9192\n",
            "Epoch 232/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0876 - acc: 0.9661 - val_loss: 0.2631 - val_acc: 0.9243\n",
            "Epoch 233/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0820 - acc: 0.9692 - val_loss: 0.2671 - val_acc: 0.9243\n",
            "Epoch 234/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0853 - acc: 0.9671 - val_loss: 0.2798 - val_acc: 0.9230\n",
            "Epoch 235/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0849 - acc: 0.9683 - val_loss: 0.2816 - val_acc: 0.9237\n",
            "Epoch 236/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0822 - acc: 0.9658 - val_loss: 0.2790 - val_acc: 0.9249\n",
            "Epoch 237/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0797 - acc: 0.9695 - val_loss: 0.2856 - val_acc: 0.9218\n",
            "Epoch 238/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0940 - acc: 0.9636 - val_loss: 0.2702 - val_acc: 0.9237\n",
            "Epoch 239/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0774 - acc: 0.9692 - val_loss: 0.3010 - val_acc: 0.9262\n",
            "Epoch 240/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0875 - acc: 0.9664 - val_loss: 0.2655 - val_acc: 0.9230\n",
            "Epoch 241/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0907 - acc: 0.9643 - val_loss: 0.2740 - val_acc: 0.9224\n",
            "Epoch 242/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0805 - acc: 0.9689 - val_loss: 0.2839 - val_acc: 0.9224\n",
            "Epoch 243/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0850 - acc: 0.9671 - val_loss: 0.2786 - val_acc: 0.9224\n",
            "Epoch 244/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0784 - acc: 0.9667 - val_loss: 0.2824 - val_acc: 0.9224\n",
            "Epoch 245/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0826 - acc: 0.9680 - val_loss: 0.2782 - val_acc: 0.9211\n",
            "Epoch 246/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0802 - acc: 0.9667 - val_loss: 0.2746 - val_acc: 0.9237\n",
            "Epoch 247/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0795 - acc: 0.9686 - val_loss: 0.2775 - val_acc: 0.9237\n",
            "Epoch 248/800\n",
            "3217/3217 [==============================] - 0s 108us/step - loss: 0.0846 - acc: 0.9664 - val_loss: 0.2742 - val_acc: 0.9224\n",
            "Epoch 249/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0806 - acc: 0.9702 - val_loss: 0.2959 - val_acc: 0.9224\n",
            "Epoch 250/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0752 - acc: 0.9677 - val_loss: 0.2763 - val_acc: 0.9262\n",
            "Epoch 251/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0814 - acc: 0.9689 - val_loss: 0.2772 - val_acc: 0.9243\n",
            "Epoch 252/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0815 - acc: 0.9661 - val_loss: 0.2859 - val_acc: 0.9186\n",
            "Epoch 253/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0803 - acc: 0.9711 - val_loss: 0.2855 - val_acc: 0.9211\n",
            "Epoch 254/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0764 - acc: 0.9689 - val_loss: 0.2875 - val_acc: 0.9218\n",
            "Epoch 255/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0844 - acc: 0.9674 - val_loss: 0.2965 - val_acc: 0.9224\n",
            "Epoch 256/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0777 - acc: 0.9692 - val_loss: 0.3082 - val_acc: 0.9211\n",
            "Epoch 257/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0794 - acc: 0.9695 - val_loss: 0.3085 - val_acc: 0.9230\n",
            "Epoch 258/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0784 - acc: 0.9674 - val_loss: 0.3004 - val_acc: 0.9230\n",
            "Epoch 259/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0828 - acc: 0.9692 - val_loss: 0.2864 - val_acc: 0.9218\n",
            "Epoch 260/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0714 - acc: 0.9711 - val_loss: 0.2832 - val_acc: 0.9211\n",
            "Epoch 261/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0712 - acc: 0.9733 - val_loss: 0.3098 - val_acc: 0.9211\n",
            "Epoch 262/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0796 - acc: 0.9658 - val_loss: 0.3090 - val_acc: 0.9281\n",
            "Epoch 263/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0709 - acc: 0.9717 - val_loss: 0.2883 - val_acc: 0.9205\n",
            "Epoch 264/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0765 - acc: 0.9717 - val_loss: 0.2959 - val_acc: 0.9205\n",
            "Epoch 265/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0793 - acc: 0.9692 - val_loss: 0.2971 - val_acc: 0.9205\n",
            "Epoch 266/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0770 - acc: 0.9717 - val_loss: 0.3004 - val_acc: 0.9180\n",
            "Epoch 267/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0786 - acc: 0.9677 - val_loss: 0.2960 - val_acc: 0.9186\n",
            "Epoch 268/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0777 - acc: 0.9711 - val_loss: 0.2960 - val_acc: 0.9199\n",
            "Epoch 269/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0765 - acc: 0.9711 - val_loss: 0.2986 - val_acc: 0.9230\n",
            "Epoch 270/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0766 - acc: 0.9680 - val_loss: 0.2887 - val_acc: 0.9180\n",
            "Epoch 271/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0802 - acc: 0.9661 - val_loss: 0.2896 - val_acc: 0.9161\n",
            "Epoch 272/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0769 - acc: 0.9702 - val_loss: 0.2982 - val_acc: 0.9249\n",
            "Epoch 273/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0735 - acc: 0.9720 - val_loss: 0.3012 - val_acc: 0.9230\n",
            "Epoch 274/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0780 - acc: 0.9702 - val_loss: 0.2880 - val_acc: 0.9186\n",
            "Epoch 275/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0732 - acc: 0.9705 - val_loss: 0.3014 - val_acc: 0.9205\n",
            "Epoch 276/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0709 - acc: 0.9717 - val_loss: 0.3150 - val_acc: 0.9224\n",
            "Epoch 277/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0710 - acc: 0.9723 - val_loss: 0.3135 - val_acc: 0.9136\n",
            "Epoch 278/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.0694 - acc: 0.9689 - val_loss: 0.3146 - val_acc: 0.9186\n",
            "Epoch 279/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0764 - acc: 0.9708 - val_loss: 0.3010 - val_acc: 0.9186\n",
            "Epoch 280/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0707 - acc: 0.9726 - val_loss: 0.3120 - val_acc: 0.9180\n",
            "Epoch 281/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0675 - acc: 0.9742 - val_loss: 0.3094 - val_acc: 0.9205\n",
            "Epoch 282/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0671 - acc: 0.9714 - val_loss: 0.3230 - val_acc: 0.9205\n",
            "Epoch 283/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0660 - acc: 0.9739 - val_loss: 0.3033 - val_acc: 0.9192\n",
            "Epoch 284/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0783 - acc: 0.9705 - val_loss: 0.3107 - val_acc: 0.9180\n",
            "Epoch 285/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0673 - acc: 0.9748 - val_loss: 0.3108 - val_acc: 0.9167\n",
            "Epoch 286/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0712 - acc: 0.9751 - val_loss: 0.3139 - val_acc: 0.9218\n",
            "Epoch 287/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0683 - acc: 0.9720 - val_loss: 0.3245 - val_acc: 0.9211\n",
            "Epoch 288/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0715 - acc: 0.9702 - val_loss: 0.3277 - val_acc: 0.9155\n",
            "Epoch 289/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0679 - acc: 0.9748 - val_loss: 0.3173 - val_acc: 0.9205\n",
            "Epoch 290/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0684 - acc: 0.9717 - val_loss: 0.3246 - val_acc: 0.9167\n",
            "Epoch 291/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0622 - acc: 0.9767 - val_loss: 0.3232 - val_acc: 0.9186\n",
            "Epoch 292/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0721 - acc: 0.9711 - val_loss: 0.3261 - val_acc: 0.9192\n",
            "Epoch 293/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0589 - acc: 0.9770 - val_loss: 0.3286 - val_acc: 0.9180\n",
            "Epoch 294/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.0808 - acc: 0.9695 - val_loss: 0.3161 - val_acc: 0.9199\n",
            "Epoch 295/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0653 - acc: 0.9733 - val_loss: 0.3192 - val_acc: 0.9218\n",
            "Epoch 296/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0645 - acc: 0.9736 - val_loss: 0.3326 - val_acc: 0.9218\n",
            "Epoch 297/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0759 - acc: 0.9692 - val_loss: 0.3185 - val_acc: 0.9199\n",
            "Epoch 298/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0689 - acc: 0.9736 - val_loss: 0.3277 - val_acc: 0.9174\n",
            "Epoch 299/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0694 - acc: 0.9723 - val_loss: 0.3216 - val_acc: 0.9186\n",
            "Epoch 300/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0705 - acc: 0.9714 - val_loss: 0.3098 - val_acc: 0.9192\n",
            "Epoch 301/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0656 - acc: 0.9714 - val_loss: 0.3078 - val_acc: 0.9180\n",
            "Epoch 302/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0670 - acc: 0.9767 - val_loss: 0.3138 - val_acc: 0.9205\n",
            "Epoch 303/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0726 - acc: 0.9739 - val_loss: 0.3054 - val_acc: 0.9205\n",
            "Epoch 304/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0635 - acc: 0.9761 - val_loss: 0.3136 - val_acc: 0.9237\n",
            "Epoch 305/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0723 - acc: 0.9708 - val_loss: 0.3181 - val_acc: 0.9199\n",
            "Epoch 306/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0602 - acc: 0.9764 - val_loss: 0.3183 - val_acc: 0.9243\n",
            "Epoch 307/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0664 - acc: 0.9742 - val_loss: 0.3170 - val_acc: 0.9230\n",
            "Epoch 308/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0684 - acc: 0.9720 - val_loss: 0.3161 - val_acc: 0.9180\n",
            "Epoch 309/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0689 - acc: 0.9739 - val_loss: 0.3160 - val_acc: 0.9230\n",
            "Epoch 310/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0655 - acc: 0.9739 - val_loss: 0.3282 - val_acc: 0.9281\n",
            "Epoch 311/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0680 - acc: 0.9739 - val_loss: 0.3312 - val_acc: 0.9174\n",
            "Epoch 312/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0673 - acc: 0.9720 - val_loss: 0.3332 - val_acc: 0.9224\n",
            "Epoch 313/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0652 - acc: 0.9751 - val_loss: 0.3351 - val_acc: 0.9230\n",
            "Epoch 314/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0677 - acc: 0.9748 - val_loss: 0.3314 - val_acc: 0.9192\n",
            "Epoch 315/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0573 - acc: 0.9767 - val_loss: 0.3283 - val_acc: 0.9186\n",
            "Epoch 316/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0555 - acc: 0.9754 - val_loss: 0.3476 - val_acc: 0.9205\n",
            "Epoch 317/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.0607 - acc: 0.9770 - val_loss: 0.3377 - val_acc: 0.9167\n",
            "Epoch 318/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0711 - acc: 0.9723 - val_loss: 0.3262 - val_acc: 0.9211\n",
            "Epoch 319/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0594 - acc: 0.9779 - val_loss: 0.3273 - val_acc: 0.9205\n",
            "Epoch 320/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0580 - acc: 0.9761 - val_loss: 0.3409 - val_acc: 0.9224\n",
            "Epoch 321/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0579 - acc: 0.9761 - val_loss: 0.3466 - val_acc: 0.9199\n",
            "Epoch 322/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0696 - acc: 0.9745 - val_loss: 0.3301 - val_acc: 0.9174\n",
            "Epoch 323/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0605 - acc: 0.9764 - val_loss: 0.3377 - val_acc: 0.9167\n",
            "Epoch 324/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0586 - acc: 0.9761 - val_loss: 0.3392 - val_acc: 0.9192\n",
            "Epoch 325/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0589 - acc: 0.9779 - val_loss: 0.3310 - val_acc: 0.9211\n",
            "Epoch 326/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0598 - acc: 0.9776 - val_loss: 0.3389 - val_acc: 0.9205\n",
            "Epoch 327/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0598 - acc: 0.9758 - val_loss: 0.3438 - val_acc: 0.9249\n",
            "Epoch 328/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0685 - acc: 0.9723 - val_loss: 0.3297 - val_acc: 0.9180\n",
            "Epoch 329/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0550 - acc: 0.9779 - val_loss: 0.3356 - val_acc: 0.9224\n",
            "Epoch 330/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0682 - acc: 0.9717 - val_loss: 0.3325 - val_acc: 0.9186\n",
            "Epoch 331/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0560 - acc: 0.9758 - val_loss: 0.3605 - val_acc: 0.9211\n",
            "Epoch 332/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0568 - acc: 0.9779 - val_loss: 0.3580 - val_acc: 0.9211\n",
            "Epoch 333/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0619 - acc: 0.9764 - val_loss: 0.3380 - val_acc: 0.9218\n",
            "Epoch 334/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0613 - acc: 0.9764 - val_loss: 0.3501 - val_acc: 0.9211\n",
            "Epoch 335/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0530 - acc: 0.9795 - val_loss: 0.3538 - val_acc: 0.9205\n",
            "Epoch 336/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0565 - acc: 0.9786 - val_loss: 0.3643 - val_acc: 0.9205\n",
            "Epoch 337/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0667 - acc: 0.9708 - val_loss: 0.3438 - val_acc: 0.9205\n",
            "Epoch 338/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0690 - acc: 0.9711 - val_loss: 0.3456 - val_acc: 0.9224\n",
            "Epoch 339/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0549 - acc: 0.9795 - val_loss: 0.3675 - val_acc: 0.9268\n",
            "Epoch 340/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0559 - acc: 0.9789 - val_loss: 0.3508 - val_acc: 0.9205\n",
            "Epoch 341/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0662 - acc: 0.9733 - val_loss: 0.3621 - val_acc: 0.9218\n",
            "Epoch 342/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0508 - acc: 0.9823 - val_loss: 0.3497 - val_acc: 0.9218\n",
            "Epoch 343/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0550 - acc: 0.9770 - val_loss: 0.3481 - val_acc: 0.9205\n",
            "Epoch 344/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0644 - acc: 0.9754 - val_loss: 0.3339 - val_acc: 0.9243\n",
            "Epoch 345/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0554 - acc: 0.9779 - val_loss: 0.3432 - val_acc: 0.9218\n",
            "Epoch 346/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0542 - acc: 0.9773 - val_loss: 0.3600 - val_acc: 0.9174\n",
            "Epoch 347/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0555 - acc: 0.9776 - val_loss: 0.3482 - val_acc: 0.9237\n",
            "Epoch 348/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0560 - acc: 0.9770 - val_loss: 0.3671 - val_acc: 0.9218\n",
            "Epoch 349/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0540 - acc: 0.9789 - val_loss: 0.3644 - val_acc: 0.9237\n",
            "Epoch 350/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0627 - acc: 0.9736 - val_loss: 0.3580 - val_acc: 0.9249\n",
            "Epoch 351/800\n",
            "3217/3217 [==============================] - 0s 113us/step - loss: 0.0595 - acc: 0.9776 - val_loss: 0.3550 - val_acc: 0.9224\n",
            "Epoch 352/800\n",
            "3217/3217 [==============================] - 0s 113us/step - loss: 0.0627 - acc: 0.9767 - val_loss: 0.3597 - val_acc: 0.9218\n",
            "Epoch 353/800\n",
            "3217/3217 [==============================] - 0s 111us/step - loss: 0.0572 - acc: 0.9786 - val_loss: 0.3554 - val_acc: 0.9218\n",
            "Epoch 354/800\n",
            "3217/3217 [==============================] - 0s 111us/step - loss: 0.0555 - acc: 0.9786 - val_loss: 0.3519 - val_acc: 0.9224\n",
            "Epoch 355/800\n",
            "3217/3217 [==============================] - 0s 110us/step - loss: 0.0619 - acc: 0.9758 - val_loss: 0.3520 - val_acc: 0.9186\n",
            "Epoch 356/800\n",
            "3217/3217 [==============================] - 0s 113us/step - loss: 0.0566 - acc: 0.9779 - val_loss: 0.3580 - val_acc: 0.9224\n",
            "Epoch 357/800\n",
            "3217/3217 [==============================] - 0s 109us/step - loss: 0.0495 - acc: 0.9786 - val_loss: 0.3645 - val_acc: 0.9218\n",
            "Epoch 358/800\n",
            "3217/3217 [==============================] - 0s 113us/step - loss: 0.0531 - acc: 0.9807 - val_loss: 0.3494 - val_acc: 0.9174\n",
            "Epoch 359/800\n",
            "3217/3217 [==============================] - 0s 111us/step - loss: 0.0565 - acc: 0.9807 - val_loss: 0.3439 - val_acc: 0.9186\n",
            "Epoch 360/800\n",
            "3217/3217 [==============================] - 0s 112us/step - loss: 0.0475 - acc: 0.9804 - val_loss: 0.3633 - val_acc: 0.9205\n",
            "Epoch 361/800\n",
            "3217/3217 [==============================] - 0s 112us/step - loss: 0.0594 - acc: 0.9770 - val_loss: 0.3753 - val_acc: 0.9174\n",
            "Epoch 362/800\n",
            "3217/3217 [==============================] - 0s 111us/step - loss: 0.0554 - acc: 0.9779 - val_loss: 0.3627 - val_acc: 0.9211\n",
            "Epoch 363/800\n",
            "3217/3217 [==============================] - 0s 111us/step - loss: 0.0536 - acc: 0.9786 - val_loss: 0.3655 - val_acc: 0.9205\n",
            "Epoch 364/800\n",
            "3217/3217 [==============================] - 0s 110us/step - loss: 0.0567 - acc: 0.9792 - val_loss: 0.3591 - val_acc: 0.9167\n",
            "Epoch 365/800\n",
            "3217/3217 [==============================] - 0s 108us/step - loss: 0.0525 - acc: 0.9801 - val_loss: 0.3592 - val_acc: 0.9224\n",
            "Epoch 366/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0508 - acc: 0.9801 - val_loss: 0.3689 - val_acc: 0.9218\n",
            "Epoch 367/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0598 - acc: 0.9792 - val_loss: 0.3555 - val_acc: 0.9192\n",
            "Epoch 368/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0509 - acc: 0.9807 - val_loss: 0.3591 - val_acc: 0.9174\n",
            "Epoch 369/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0533 - acc: 0.9786 - val_loss: 0.3792 - val_acc: 0.9211\n",
            "Epoch 370/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0460 - acc: 0.9820 - val_loss: 0.3635 - val_acc: 0.9180\n",
            "Epoch 371/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0447 - acc: 0.9829 - val_loss: 0.3669 - val_acc: 0.9224\n",
            "Epoch 372/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0524 - acc: 0.9758 - val_loss: 0.3822 - val_acc: 0.9199\n",
            "Epoch 373/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0605 - acc: 0.9754 - val_loss: 0.3703 - val_acc: 0.9167\n",
            "Epoch 374/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0542 - acc: 0.9789 - val_loss: 0.3564 - val_acc: 0.9192\n",
            "Epoch 375/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0521 - acc: 0.9804 - val_loss: 0.3693 - val_acc: 0.9186\n",
            "Epoch 376/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0568 - acc: 0.9789 - val_loss: 0.3596 - val_acc: 0.9199\n",
            "Epoch 377/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0479 - acc: 0.9798 - val_loss: 0.3631 - val_acc: 0.9237\n",
            "Epoch 378/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0448 - acc: 0.9810 - val_loss: 0.3708 - val_acc: 0.9237\n",
            "Epoch 379/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0466 - acc: 0.9817 - val_loss: 0.3818 - val_acc: 0.9237\n",
            "Epoch 380/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0509 - acc: 0.9786 - val_loss: 0.3807 - val_acc: 0.9218\n",
            "Epoch 381/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0483 - acc: 0.9779 - val_loss: 0.3727 - val_acc: 0.9186\n",
            "Epoch 382/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0515 - acc: 0.9801 - val_loss: 0.3746 - val_acc: 0.9237\n",
            "Epoch 383/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0511 - acc: 0.9792 - val_loss: 0.3686 - val_acc: 0.9243\n",
            "Epoch 384/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0504 - acc: 0.9823 - val_loss: 0.3639 - val_acc: 0.9287\n",
            "Epoch 385/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0537 - acc: 0.9779 - val_loss: 0.3792 - val_acc: 0.9230\n",
            "Epoch 386/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0450 - acc: 0.9820 - val_loss: 0.3691 - val_acc: 0.9205\n",
            "Epoch 387/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0552 - acc: 0.9795 - val_loss: 0.3600 - val_acc: 0.9262\n",
            "Epoch 388/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0508 - acc: 0.9798 - val_loss: 0.3679 - val_acc: 0.9262\n",
            "Epoch 389/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0499 - acc: 0.9798 - val_loss: 0.3733 - val_acc: 0.9230\n",
            "Epoch 390/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0522 - acc: 0.9773 - val_loss: 0.3796 - val_acc: 0.9192\n",
            "Epoch 391/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0521 - acc: 0.9786 - val_loss: 0.3713 - val_acc: 0.9218\n",
            "Epoch 392/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0461 - acc: 0.9807 - val_loss: 0.3781 - val_acc: 0.9192\n",
            "Epoch 393/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0539 - acc: 0.9792 - val_loss: 0.3735 - val_acc: 0.9211\n",
            "Epoch 394/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0491 - acc: 0.9807 - val_loss: 0.3751 - val_acc: 0.9180\n",
            "Epoch 395/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0515 - acc: 0.9823 - val_loss: 0.3673 - val_acc: 0.9180\n",
            "Epoch 396/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0458 - acc: 0.9823 - val_loss: 0.3742 - val_acc: 0.9224\n",
            "Epoch 397/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0492 - acc: 0.9813 - val_loss: 0.3708 - val_acc: 0.9205\n",
            "Epoch 398/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0486 - acc: 0.9798 - val_loss: 0.3896 - val_acc: 0.9192\n",
            "Epoch 399/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0497 - acc: 0.9804 - val_loss: 0.3827 - val_acc: 0.9192\n",
            "Epoch 400/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0474 - acc: 0.9817 - val_loss: 0.3887 - val_acc: 0.9186\n",
            "Epoch 401/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0507 - acc: 0.9813 - val_loss: 0.3999 - val_acc: 0.9180\n",
            "Epoch 402/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0623 - acc: 0.9789 - val_loss: 0.3889 - val_acc: 0.9180\n",
            "Epoch 403/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0495 - acc: 0.9804 - val_loss: 0.3895 - val_acc: 0.9211\n",
            "Epoch 404/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0502 - acc: 0.9838 - val_loss: 0.4048 - val_acc: 0.9192\n",
            "Epoch 405/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0505 - acc: 0.9807 - val_loss: 0.3917 - val_acc: 0.9161\n",
            "Epoch 406/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0472 - acc: 0.9807 - val_loss: 0.3850 - val_acc: 0.9199\n",
            "Epoch 407/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0464 - acc: 0.9845 - val_loss: 0.3954 - val_acc: 0.9211\n",
            "Epoch 408/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0517 - acc: 0.9798 - val_loss: 0.3848 - val_acc: 0.9167\n",
            "Epoch 409/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0459 - acc: 0.9823 - val_loss: 0.3941 - val_acc: 0.9199\n",
            "Epoch 410/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0455 - acc: 0.9820 - val_loss: 0.3912 - val_acc: 0.9230\n",
            "Epoch 411/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0533 - acc: 0.9795 - val_loss: 0.3794 - val_acc: 0.9218\n",
            "Epoch 412/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0536 - acc: 0.9776 - val_loss: 0.3718 - val_acc: 0.9218\n",
            "Epoch 413/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0538 - acc: 0.9798 - val_loss: 0.3623 - val_acc: 0.9224\n",
            "Epoch 414/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0549 - acc: 0.9792 - val_loss: 0.3747 - val_acc: 0.9237\n",
            "Epoch 415/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0415 - acc: 0.9835 - val_loss: 0.3844 - val_acc: 0.9205\n",
            "Epoch 416/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0534 - acc: 0.9798 - val_loss: 0.3972 - val_acc: 0.9161\n",
            "Epoch 417/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0415 - acc: 0.9838 - val_loss: 0.3943 - val_acc: 0.9155\n",
            "Epoch 418/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0481 - acc: 0.9826 - val_loss: 0.3846 - val_acc: 0.9167\n",
            "Epoch 419/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0474 - acc: 0.9832 - val_loss: 0.4032 - val_acc: 0.9211\n",
            "Epoch 420/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0459 - acc: 0.9823 - val_loss: 0.3858 - val_acc: 0.9167\n",
            "Epoch 421/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0459 - acc: 0.9823 - val_loss: 0.3859 - val_acc: 0.9205\n",
            "Epoch 422/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0441 - acc: 0.9829 - val_loss: 0.4281 - val_acc: 0.9192\n",
            "Epoch 423/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0494 - acc: 0.9829 - val_loss: 0.3976 - val_acc: 0.9174\n",
            "Epoch 424/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0403 - acc: 0.9829 - val_loss: 0.3946 - val_acc: 0.9161\n",
            "Epoch 425/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0452 - acc: 0.9838 - val_loss: 0.3844 - val_acc: 0.9186\n",
            "Epoch 426/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0405 - acc: 0.9866 - val_loss: 0.4012 - val_acc: 0.9199\n",
            "Epoch 427/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0422 - acc: 0.9832 - val_loss: 0.4178 - val_acc: 0.9218\n",
            "Epoch 428/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0465 - acc: 0.9829 - val_loss: 0.3910 - val_acc: 0.9148\n",
            "Epoch 429/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0412 - acc: 0.9835 - val_loss: 0.3953 - val_acc: 0.9199\n",
            "Epoch 430/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0474 - acc: 0.9813 - val_loss: 0.4012 - val_acc: 0.9155\n",
            "Epoch 431/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0502 - acc: 0.9829 - val_loss: 0.3976 - val_acc: 0.9180\n",
            "Epoch 432/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0424 - acc: 0.9826 - val_loss: 0.4086 - val_acc: 0.9161\n",
            "Epoch 433/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0428 - acc: 0.9826 - val_loss: 0.3820 - val_acc: 0.9180\n",
            "Epoch 434/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0446 - acc: 0.9807 - val_loss: 0.3917 - val_acc: 0.9224\n",
            "Epoch 435/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0418 - acc: 0.9820 - val_loss: 0.3940 - val_acc: 0.9129\n",
            "Epoch 436/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0400 - acc: 0.9841 - val_loss: 0.3850 - val_acc: 0.9224\n",
            "Epoch 437/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0481 - acc: 0.9835 - val_loss: 0.3845 - val_acc: 0.9230\n",
            "Epoch 438/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0477 - acc: 0.9801 - val_loss: 0.4009 - val_acc: 0.9249\n",
            "Epoch 439/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0530 - acc: 0.9820 - val_loss: 0.3883 - val_acc: 0.9224\n",
            "Epoch 440/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0411 - acc: 0.9829 - val_loss: 0.3825 - val_acc: 0.9186\n",
            "Epoch 441/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0526 - acc: 0.9807 - val_loss: 0.4115 - val_acc: 0.9192\n",
            "Epoch 442/800\n",
            "3217/3217 [==============================] - 0s 109us/step - loss: 0.0445 - acc: 0.9817 - val_loss: 0.3977 - val_acc: 0.9205\n",
            "Epoch 443/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0409 - acc: 0.9845 - val_loss: 0.3912 - val_acc: 0.9192\n",
            "Epoch 444/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0442 - acc: 0.9823 - val_loss: 0.3957 - val_acc: 0.9205\n",
            "Epoch 445/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0448 - acc: 0.9826 - val_loss: 0.3883 - val_acc: 0.9218\n",
            "Epoch 446/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0371 - acc: 0.9863 - val_loss: 0.4005 - val_acc: 0.9243\n",
            "Epoch 447/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0474 - acc: 0.9810 - val_loss: 0.3797 - val_acc: 0.9218\n",
            "Epoch 448/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0438 - acc: 0.9838 - val_loss: 0.4142 - val_acc: 0.9148\n",
            "Epoch 449/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0479 - acc: 0.9835 - val_loss: 0.4018 - val_acc: 0.9180\n",
            "Epoch 450/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0484 - acc: 0.9789 - val_loss: 0.4098 - val_acc: 0.9205\n",
            "Epoch 451/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0375 - acc: 0.9876 - val_loss: 0.4225 - val_acc: 0.9199\n",
            "Epoch 452/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0443 - acc: 0.9851 - val_loss: 0.4013 - val_acc: 0.9174\n",
            "Epoch 453/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0471 - acc: 0.9804 - val_loss: 0.4250 - val_acc: 0.9186\n",
            "Epoch 454/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0380 - acc: 0.9838 - val_loss: 0.4248 - val_acc: 0.9230\n",
            "Epoch 455/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0471 - acc: 0.9832 - val_loss: 0.3921 - val_acc: 0.9199\n",
            "Epoch 456/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0396 - acc: 0.9832 - val_loss: 0.3890 - val_acc: 0.9224\n",
            "Epoch 457/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0386 - acc: 0.9832 - val_loss: 0.3944 - val_acc: 0.9174\n",
            "Epoch 458/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0463 - acc: 0.9829 - val_loss: 0.4215 - val_acc: 0.9199\n",
            "Epoch 459/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0414 - acc: 0.9848 - val_loss: 0.4128 - val_acc: 0.9174\n",
            "Epoch 460/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0444 - acc: 0.9835 - val_loss: 0.4229 - val_acc: 0.9155\n",
            "Epoch 461/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0450 - acc: 0.9801 - val_loss: 0.4099 - val_acc: 0.9142\n",
            "Epoch 462/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0397 - acc: 0.9835 - val_loss: 0.4132 - val_acc: 0.9180\n",
            "Epoch 463/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0392 - acc: 0.9857 - val_loss: 0.4257 - val_acc: 0.9167\n",
            "Epoch 464/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0443 - acc: 0.9829 - val_loss: 0.4260 - val_acc: 0.9192\n",
            "Epoch 465/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0515 - acc: 0.9817 - val_loss: 0.4148 - val_acc: 0.9161\n",
            "Epoch 466/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0402 - acc: 0.9854 - val_loss: 0.4144 - val_acc: 0.9148\n",
            "Epoch 467/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0562 - acc: 0.9807 - val_loss: 0.4077 - val_acc: 0.9211\n",
            "Epoch 468/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0468 - acc: 0.9826 - val_loss: 0.4020 - val_acc: 0.9186\n",
            "Epoch 469/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0406 - acc: 0.9851 - val_loss: 0.4288 - val_acc: 0.9180\n",
            "Epoch 470/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0394 - acc: 0.9863 - val_loss: 0.4188 - val_acc: 0.9199\n",
            "Epoch 471/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0401 - acc: 0.9823 - val_loss: 0.4128 - val_acc: 0.9192\n",
            "Epoch 472/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0435 - acc: 0.9829 - val_loss: 0.4135 - val_acc: 0.9199\n",
            "Epoch 473/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0369 - acc: 0.9869 - val_loss: 0.4155 - val_acc: 0.9218\n",
            "Epoch 474/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0390 - acc: 0.9869 - val_loss: 0.4226 - val_acc: 0.9205\n",
            "Epoch 475/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0445 - acc: 0.9826 - val_loss: 0.4254 - val_acc: 0.9155\n",
            "Epoch 476/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0486 - acc: 0.9807 - val_loss: 0.4126 - val_acc: 0.9161\n",
            "Epoch 477/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0384 - acc: 0.9838 - val_loss: 0.4162 - val_acc: 0.9180\n",
            "Epoch 478/800\n",
            "3217/3217 [==============================] - 0s 112us/step - loss: 0.0408 - acc: 0.9826 - val_loss: 0.4117 - val_acc: 0.9161\n",
            "Epoch 479/800\n",
            "3217/3217 [==============================] - 0s 118us/step - loss: 0.0396 - acc: 0.9854 - val_loss: 0.4069 - val_acc: 0.9142\n",
            "Epoch 480/800\n",
            "3217/3217 [==============================] - 0s 108us/step - loss: 0.0421 - acc: 0.9810 - val_loss: 0.4097 - val_acc: 0.9136\n",
            "Epoch 481/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0410 - acc: 0.9845 - val_loss: 0.4359 - val_acc: 0.9174\n",
            "Epoch 482/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0337 - acc: 0.9866 - val_loss: 0.4145 - val_acc: 0.9174\n",
            "Epoch 483/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0377 - acc: 0.9845 - val_loss: 0.4083 - val_acc: 0.9167\n",
            "Epoch 484/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0450 - acc: 0.9810 - val_loss: 0.4264 - val_acc: 0.9211\n",
            "Epoch 485/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0432 - acc: 0.9863 - val_loss: 0.4338 - val_acc: 0.9186\n",
            "Epoch 486/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0339 - acc: 0.9848 - val_loss: 0.4223 - val_acc: 0.9180\n",
            "Epoch 487/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0336 - acc: 0.9857 - val_loss: 0.4366 - val_acc: 0.9205\n",
            "Epoch 488/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0370 - acc: 0.9845 - val_loss: 0.4131 - val_acc: 0.9180\n",
            "Epoch 489/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0452 - acc: 0.9838 - val_loss: 0.4252 - val_acc: 0.9161\n",
            "Epoch 490/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0417 - acc: 0.9838 - val_loss: 0.4489 - val_acc: 0.9167\n",
            "Epoch 491/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0404 - acc: 0.9876 - val_loss: 0.4312 - val_acc: 0.9142\n",
            "Epoch 492/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0462 - acc: 0.9832 - val_loss: 0.4106 - val_acc: 0.9218\n",
            "Epoch 493/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0340 - acc: 0.9863 - val_loss: 0.4227 - val_acc: 0.9237\n",
            "Epoch 494/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0426 - acc: 0.9823 - val_loss: 0.4184 - val_acc: 0.9167\n",
            "Epoch 495/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0357 - acc: 0.9832 - val_loss: 0.4268 - val_acc: 0.9161\n",
            "Epoch 496/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0359 - acc: 0.9854 - val_loss: 0.4333 - val_acc: 0.9237\n",
            "Epoch 497/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0391 - acc: 0.9829 - val_loss: 0.4322 - val_acc: 0.9155\n",
            "Epoch 498/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0426 - acc: 0.9835 - val_loss: 0.4483 - val_acc: 0.9186\n",
            "Epoch 499/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0410 - acc: 0.9838 - val_loss: 0.4210 - val_acc: 0.9186\n",
            "Epoch 500/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0365 - acc: 0.9848 - val_loss: 0.4315 - val_acc: 0.9205\n",
            "Epoch 501/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0381 - acc: 0.9866 - val_loss: 0.4290 - val_acc: 0.9186\n",
            "Epoch 502/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0370 - acc: 0.9845 - val_loss: 0.4361 - val_acc: 0.9161\n",
            "Epoch 503/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0339 - acc: 0.9876 - val_loss: 0.4480 - val_acc: 0.9192\n",
            "Epoch 504/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0386 - acc: 0.9820 - val_loss: 0.4527 - val_acc: 0.9237\n",
            "Epoch 505/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0369 - acc: 0.9869 - val_loss: 0.4534 - val_acc: 0.9249\n",
            "Epoch 506/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0376 - acc: 0.9832 - val_loss: 0.4551 - val_acc: 0.9186\n",
            "Epoch 507/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0379 - acc: 0.9857 - val_loss: 0.4284 - val_acc: 0.9174\n",
            "Epoch 508/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0424 - acc: 0.9848 - val_loss: 0.4355 - val_acc: 0.9224\n",
            "Epoch 509/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0396 - acc: 0.9848 - val_loss: 0.4147 - val_acc: 0.9237\n",
            "Epoch 510/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0453 - acc: 0.9832 - val_loss: 0.4057 - val_acc: 0.9218\n",
            "Epoch 511/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0356 - acc: 0.9863 - val_loss: 0.4378 - val_acc: 0.9199\n",
            "Epoch 512/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0336 - acc: 0.9885 - val_loss: 0.4341 - val_acc: 0.9218\n",
            "Epoch 513/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0397 - acc: 0.9863 - val_loss: 0.4079 - val_acc: 0.9148\n",
            "Epoch 514/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0351 - acc: 0.9869 - val_loss: 0.4347 - val_acc: 0.9205\n",
            "Epoch 515/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0442 - acc: 0.9826 - val_loss: 0.4366 - val_acc: 0.9224\n",
            "Epoch 516/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0402 - acc: 0.9823 - val_loss: 0.4160 - val_acc: 0.9205\n",
            "Epoch 517/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0365 - acc: 0.9863 - val_loss: 0.4248 - val_acc: 0.9211\n",
            "Epoch 518/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0380 - acc: 0.9838 - val_loss: 0.4311 - val_acc: 0.9205\n",
            "Epoch 519/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0399 - acc: 0.9845 - val_loss: 0.4249 - val_acc: 0.9199\n",
            "Epoch 520/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0363 - acc: 0.9876 - val_loss: 0.4208 - val_acc: 0.9174\n",
            "Epoch 521/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0377 - acc: 0.9838 - val_loss: 0.4468 - val_acc: 0.9155\n",
            "Epoch 522/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0338 - acc: 0.9860 - val_loss: 0.4343 - val_acc: 0.9186\n",
            "Epoch 523/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0340 - acc: 0.9863 - val_loss: 0.4185 - val_acc: 0.9224\n",
            "Epoch 524/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0386 - acc: 0.9835 - val_loss: 0.4533 - val_acc: 0.9180\n",
            "Epoch 525/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0421 - acc: 0.9854 - val_loss: 0.4284 - val_acc: 0.9180\n",
            "Epoch 526/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0390 - acc: 0.9838 - val_loss: 0.4128 - val_acc: 0.9186\n",
            "Epoch 527/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0396 - acc: 0.9866 - val_loss: 0.4330 - val_acc: 0.9211\n",
            "Epoch 528/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0388 - acc: 0.9845 - val_loss: 0.4414 - val_acc: 0.9161\n",
            "Epoch 529/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0397 - acc: 0.9860 - val_loss: 0.4404 - val_acc: 0.9186\n",
            "Epoch 530/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0392 - acc: 0.9879 - val_loss: 0.4494 - val_acc: 0.9167\n",
            "Epoch 531/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0367 - acc: 0.9851 - val_loss: 0.4247 - val_acc: 0.9211\n",
            "Epoch 532/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0382 - acc: 0.9860 - val_loss: 0.4378 - val_acc: 0.9155\n",
            "Epoch 533/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0372 - acc: 0.9851 - val_loss: 0.4277 - val_acc: 0.9180\n",
            "Epoch 534/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0348 - acc: 0.9863 - val_loss: 0.4339 - val_acc: 0.9199\n",
            "Epoch 535/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0317 - acc: 0.9873 - val_loss: 0.4339 - val_acc: 0.9161\n",
            "Epoch 536/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0364 - acc: 0.9869 - val_loss: 0.4325 - val_acc: 0.9205\n",
            "Epoch 537/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0368 - acc: 0.9860 - val_loss: 0.4156 - val_acc: 0.9174\n",
            "Epoch 538/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0408 - acc: 0.9826 - val_loss: 0.4308 - val_acc: 0.9174\n",
            "Epoch 539/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0420 - acc: 0.9835 - val_loss: 0.4274 - val_acc: 0.9192\n",
            "Epoch 540/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0382 - acc: 0.9860 - val_loss: 0.4383 - val_acc: 0.9186\n",
            "Epoch 541/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0301 - acc: 0.9885 - val_loss: 0.4437 - val_acc: 0.9205\n",
            "Epoch 542/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0292 - acc: 0.9913 - val_loss: 0.4436 - val_acc: 0.9218\n",
            "Epoch 543/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0346 - acc: 0.9857 - val_loss: 0.4564 - val_acc: 0.9186\n",
            "Epoch 544/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0364 - acc: 0.9876 - val_loss: 0.4379 - val_acc: 0.9186\n",
            "Epoch 545/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0304 - acc: 0.9891 - val_loss: 0.4435 - val_acc: 0.9199\n",
            "Epoch 546/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0342 - acc: 0.9885 - val_loss: 0.4274 - val_acc: 0.9167\n",
            "Epoch 547/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0353 - acc: 0.9879 - val_loss: 0.4298 - val_acc: 0.9211\n",
            "Epoch 548/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0339 - acc: 0.9891 - val_loss: 0.4504 - val_acc: 0.9142\n",
            "Epoch 549/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0363 - acc: 0.9845 - val_loss: 0.4403 - val_acc: 0.9199\n",
            "Epoch 550/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0363 - acc: 0.9888 - val_loss: 0.4615 - val_acc: 0.9224\n",
            "Epoch 551/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0274 - acc: 0.9894 - val_loss: 0.4454 - val_acc: 0.9224\n",
            "Epoch 552/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0371 - acc: 0.9860 - val_loss: 0.4392 - val_acc: 0.9174\n",
            "Epoch 553/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0312 - acc: 0.9866 - val_loss: 0.4339 - val_acc: 0.9205\n",
            "Epoch 554/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0390 - acc: 0.9845 - val_loss: 0.4388 - val_acc: 0.9148\n",
            "Epoch 555/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0278 - acc: 0.9894 - val_loss: 0.4454 - val_acc: 0.9174\n",
            "Epoch 556/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0309 - acc: 0.9876 - val_loss: 0.4606 - val_acc: 0.9161\n",
            "Epoch 557/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0416 - acc: 0.9857 - val_loss: 0.4674 - val_acc: 0.9186\n",
            "Epoch 558/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0359 - acc: 0.9863 - val_loss: 0.4531 - val_acc: 0.9174\n",
            "Epoch 559/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0326 - acc: 0.9885 - val_loss: 0.4552 - val_acc: 0.9205\n",
            "Epoch 560/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0308 - acc: 0.9888 - val_loss: 0.4446 - val_acc: 0.9211\n",
            "Epoch 561/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0333 - acc: 0.9860 - val_loss: 0.4652 - val_acc: 0.9192\n",
            "Epoch 562/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0362 - acc: 0.9860 - val_loss: 0.4433 - val_acc: 0.9199\n",
            "Epoch 563/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0302 - acc: 0.9885 - val_loss: 0.4510 - val_acc: 0.9192\n",
            "Epoch 564/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0320 - acc: 0.9882 - val_loss: 0.4597 - val_acc: 0.9192\n",
            "Epoch 565/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0392 - acc: 0.9851 - val_loss: 0.4447 - val_acc: 0.9186\n",
            "Epoch 566/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0308 - acc: 0.9885 - val_loss: 0.4694 - val_acc: 0.9186\n",
            "Epoch 567/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0305 - acc: 0.9910 - val_loss: 0.4551 - val_acc: 0.9136\n",
            "Epoch 568/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0341 - acc: 0.9873 - val_loss: 0.4597 - val_acc: 0.9174\n",
            "Epoch 569/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0329 - acc: 0.9851 - val_loss: 0.4381 - val_acc: 0.9186\n",
            "Epoch 570/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0406 - acc: 0.9845 - val_loss: 0.4477 - val_acc: 0.9224\n",
            "Epoch 571/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0390 - acc: 0.9857 - val_loss: 0.4464 - val_acc: 0.9129\n",
            "Epoch 572/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0386 - acc: 0.9841 - val_loss: 0.4507 - val_acc: 0.9211\n",
            "Epoch 573/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0354 - acc: 0.9873 - val_loss: 0.4311 - val_acc: 0.9230\n",
            "Epoch 574/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0273 - acc: 0.9897 - val_loss: 0.4350 - val_acc: 0.9224\n",
            "Epoch 575/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0442 - acc: 0.9845 - val_loss: 0.4227 - val_acc: 0.9230\n",
            "Epoch 576/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0330 - acc: 0.9866 - val_loss: 0.4360 - val_acc: 0.9211\n",
            "Epoch 577/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0326 - acc: 0.9901 - val_loss: 0.4438 - val_acc: 0.9224\n",
            "Epoch 578/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0299 - acc: 0.9885 - val_loss: 0.4638 - val_acc: 0.9224\n",
            "Epoch 579/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0372 - acc: 0.9863 - val_loss: 0.4306 - val_acc: 0.9237\n",
            "Epoch 580/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0280 - acc: 0.9885 - val_loss: 0.4504 - val_acc: 0.9218\n",
            "Epoch 581/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0352 - acc: 0.9866 - val_loss: 0.4263 - val_acc: 0.9186\n",
            "Epoch 582/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0335 - acc: 0.9860 - val_loss: 0.4595 - val_acc: 0.9167\n",
            "Epoch 583/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0395 - acc: 0.9882 - val_loss: 0.4621 - val_acc: 0.9148\n",
            "Epoch 584/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.0292 - acc: 0.9897 - val_loss: 0.4654 - val_acc: 0.9174\n",
            "Epoch 585/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0327 - acc: 0.9873 - val_loss: 0.4602 - val_acc: 0.9167\n",
            "Epoch 586/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0328 - acc: 0.9882 - val_loss: 0.4635 - val_acc: 0.9167\n",
            "Epoch 587/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0318 - acc: 0.9901 - val_loss: 0.4569 - val_acc: 0.9186\n",
            "Epoch 588/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0375 - acc: 0.9823 - val_loss: 0.4400 - val_acc: 0.9205\n",
            "Epoch 589/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0308 - acc: 0.9876 - val_loss: 0.4479 - val_acc: 0.9211\n",
            "Epoch 590/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0304 - acc: 0.9882 - val_loss: 0.4461 - val_acc: 0.9186\n",
            "Epoch 591/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0348 - acc: 0.9863 - val_loss: 0.4673 - val_acc: 0.9218\n",
            "Epoch 592/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0288 - acc: 0.9876 - val_loss: 0.4490 - val_acc: 0.9218\n",
            "Epoch 593/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0330 - acc: 0.9888 - val_loss: 0.4444 - val_acc: 0.9218\n",
            "Epoch 594/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0418 - acc: 0.9854 - val_loss: 0.4549 - val_acc: 0.9142\n",
            "Epoch 595/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0263 - acc: 0.9904 - val_loss: 0.4448 - val_acc: 0.9192\n",
            "Epoch 596/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0292 - acc: 0.9891 - val_loss: 0.4536 - val_acc: 0.9192\n",
            "Epoch 597/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0345 - acc: 0.9873 - val_loss: 0.4541 - val_acc: 0.9224\n",
            "Epoch 598/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0321 - acc: 0.9885 - val_loss: 0.4541 - val_acc: 0.9192\n",
            "Epoch 599/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0297 - acc: 0.9885 - val_loss: 0.4316 - val_acc: 0.9192\n",
            "Epoch 600/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0402 - acc: 0.9854 - val_loss: 0.4655 - val_acc: 0.9199\n",
            "Epoch 601/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0290 - acc: 0.9897 - val_loss: 0.4336 - val_acc: 0.9256\n",
            "Epoch 602/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0270 - acc: 0.9904 - val_loss: 0.4755 - val_acc: 0.9230\n",
            "Epoch 603/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0335 - acc: 0.9860 - val_loss: 0.4489 - val_acc: 0.9205\n",
            "Epoch 604/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0400 - acc: 0.9845 - val_loss: 0.4651 - val_acc: 0.9199\n",
            "Epoch 605/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0306 - acc: 0.9869 - val_loss: 0.4705 - val_acc: 0.9205\n",
            "Epoch 606/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0261 - acc: 0.9888 - val_loss: 0.4749 - val_acc: 0.9199\n",
            "Epoch 607/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0305 - acc: 0.9869 - val_loss: 0.4669 - val_acc: 0.9192\n",
            "Epoch 608/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0345 - acc: 0.9904 - val_loss: 0.4697 - val_acc: 0.9224\n",
            "Epoch 609/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0345 - acc: 0.9882 - val_loss: 0.4716 - val_acc: 0.9186\n",
            "Epoch 610/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0314 - acc: 0.9888 - val_loss: 0.4522 - val_acc: 0.9218\n",
            "Epoch 611/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0359 - acc: 0.9841 - val_loss: 0.4506 - val_acc: 0.9180\n",
            "Epoch 612/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0291 - acc: 0.9882 - val_loss: 0.4799 - val_acc: 0.9199\n",
            "Epoch 613/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0382 - acc: 0.9848 - val_loss: 0.4815 - val_acc: 0.9174\n",
            "Epoch 614/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0317 - acc: 0.9885 - val_loss: 0.4569 - val_acc: 0.9237\n",
            "Epoch 615/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0298 - acc: 0.9879 - val_loss: 0.4829 - val_acc: 0.9180\n",
            "Epoch 616/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0296 - acc: 0.9876 - val_loss: 0.4589 - val_acc: 0.9218\n",
            "Epoch 617/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0336 - acc: 0.9869 - val_loss: 0.4638 - val_acc: 0.9186\n",
            "Epoch 618/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0385 - acc: 0.9873 - val_loss: 0.4692 - val_acc: 0.9155\n",
            "Epoch 619/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0404 - acc: 0.9866 - val_loss: 0.4367 - val_acc: 0.9161\n",
            "Epoch 620/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0331 - acc: 0.9882 - val_loss: 0.4698 - val_acc: 0.9186\n",
            "Epoch 621/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0289 - acc: 0.9882 - val_loss: 0.4442 - val_acc: 0.9174\n",
            "Epoch 622/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0344 - acc: 0.9891 - val_loss: 0.4747 - val_acc: 0.9174\n",
            "Epoch 623/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0326 - acc: 0.9882 - val_loss: 0.4675 - val_acc: 0.9148\n",
            "Epoch 624/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0283 - acc: 0.9910 - val_loss: 0.4665 - val_acc: 0.9155\n",
            "Epoch 625/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0307 - acc: 0.9888 - val_loss: 0.4681 - val_acc: 0.9192\n",
            "Epoch 626/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0292 - acc: 0.9885 - val_loss: 0.4706 - val_acc: 0.9192\n",
            "Epoch 627/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0292 - acc: 0.9873 - val_loss: 0.4681 - val_acc: 0.9186\n",
            "Epoch 628/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0337 - acc: 0.9876 - val_loss: 0.4739 - val_acc: 0.9211\n",
            "Epoch 629/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0368 - acc: 0.9857 - val_loss: 0.4724 - val_acc: 0.9230\n",
            "Epoch 630/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0354 - acc: 0.9857 - val_loss: 0.4513 - val_acc: 0.9186\n",
            "Epoch 631/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0330 - acc: 0.9845 - val_loss: 0.4473 - val_acc: 0.9199\n",
            "Epoch 632/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0278 - acc: 0.9907 - val_loss: 0.4584 - val_acc: 0.9211\n",
            "Epoch 633/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0292 - acc: 0.9894 - val_loss: 0.4743 - val_acc: 0.9211\n",
            "Epoch 634/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0279 - acc: 0.9904 - val_loss: 0.4968 - val_acc: 0.9237\n",
            "Epoch 635/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0374 - acc: 0.9879 - val_loss: 0.4935 - val_acc: 0.9205\n",
            "Epoch 636/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0373 - acc: 0.9876 - val_loss: 0.4819 - val_acc: 0.9192\n",
            "Epoch 637/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0315 - acc: 0.9885 - val_loss: 0.4673 - val_acc: 0.9211\n",
            "Epoch 638/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0267 - acc: 0.9894 - val_loss: 0.4544 - val_acc: 0.9167\n",
            "Epoch 639/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0320 - acc: 0.9885 - val_loss: 0.4585 - val_acc: 0.9205\n",
            "Epoch 640/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0286 - acc: 0.9894 - val_loss: 0.4628 - val_acc: 0.9199\n",
            "Epoch 641/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0297 - acc: 0.9894 - val_loss: 0.4659 - val_acc: 0.9218\n",
            "Epoch 642/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0296 - acc: 0.9910 - val_loss: 0.4704 - val_acc: 0.9174\n",
            "Epoch 643/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0328 - acc: 0.9882 - val_loss: 0.4627 - val_acc: 0.9192\n",
            "Epoch 644/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0301 - acc: 0.9869 - val_loss: 0.4670 - val_acc: 0.9136\n",
            "Epoch 645/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0331 - acc: 0.9873 - val_loss: 0.4788 - val_acc: 0.9211\n",
            "Epoch 646/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0415 - acc: 0.9835 - val_loss: 0.4517 - val_acc: 0.9161\n",
            "Epoch 647/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0311 - acc: 0.9891 - val_loss: 0.4414 - val_acc: 0.9129\n",
            "Epoch 648/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0264 - acc: 0.9904 - val_loss: 0.4438 - val_acc: 0.9180\n",
            "Epoch 649/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0326 - acc: 0.9885 - val_loss: 0.4864 - val_acc: 0.9161\n",
            "Epoch 650/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0239 - acc: 0.9919 - val_loss: 0.4910 - val_acc: 0.9199\n",
            "Epoch 651/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0251 - acc: 0.9910 - val_loss: 0.4707 - val_acc: 0.9174\n",
            "Epoch 652/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0300 - acc: 0.9894 - val_loss: 0.4636 - val_acc: 0.9180\n",
            "Epoch 653/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0254 - acc: 0.9904 - val_loss: 0.4967 - val_acc: 0.9167\n",
            "Epoch 654/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0327 - acc: 0.9888 - val_loss: 0.4648 - val_acc: 0.9192\n",
            "Epoch 655/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0293 - acc: 0.9894 - val_loss: 0.4818 - val_acc: 0.9148\n",
            "Epoch 656/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0222 - acc: 0.9922 - val_loss: 0.4633 - val_acc: 0.9155\n",
            "Epoch 657/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0345 - acc: 0.9882 - val_loss: 0.4774 - val_acc: 0.9142\n",
            "Epoch 658/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0258 - acc: 0.9907 - val_loss: 0.4808 - val_acc: 0.9192\n",
            "Epoch 659/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0352 - acc: 0.9866 - val_loss: 0.4790 - val_acc: 0.9218\n",
            "Epoch 660/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.0274 - acc: 0.9885 - val_loss: 0.4752 - val_acc: 0.9186\n",
            "Epoch 661/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0335 - acc: 0.9885 - val_loss: 0.4487 - val_acc: 0.9161\n",
            "Epoch 662/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0317 - acc: 0.9873 - val_loss: 0.4720 - val_acc: 0.9192\n",
            "Epoch 663/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0248 - acc: 0.9904 - val_loss: 0.4782 - val_acc: 0.9243\n",
            "Epoch 664/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0260 - acc: 0.9897 - val_loss: 0.4738 - val_acc: 0.9180\n",
            "Epoch 665/800\n",
            "3217/3217 [==============================] - 0s 100us/step - loss: 0.0344 - acc: 0.9863 - val_loss: 0.4783 - val_acc: 0.9167\n",
            "Epoch 666/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0277 - acc: 0.9897 - val_loss: 0.4840 - val_acc: 0.9167\n",
            "Epoch 667/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0369 - acc: 0.9860 - val_loss: 0.4664 - val_acc: 0.9205\n",
            "Epoch 668/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0321 - acc: 0.9901 - val_loss: 0.4621 - val_acc: 0.9205\n",
            "Epoch 669/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0361 - acc: 0.9888 - val_loss: 0.4831 - val_acc: 0.9174\n",
            "Epoch 670/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0300 - acc: 0.9888 - val_loss: 0.4508 - val_acc: 0.9211\n",
            "Epoch 671/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0253 - acc: 0.9891 - val_loss: 0.4703 - val_acc: 0.9205\n",
            "Epoch 672/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0300 - acc: 0.9904 - val_loss: 0.4580 - val_acc: 0.9186\n",
            "Epoch 673/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0282 - acc: 0.9904 - val_loss: 0.4659 - val_acc: 0.9224\n",
            "Epoch 674/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0266 - acc: 0.9901 - val_loss: 0.4728 - val_acc: 0.9205\n",
            "Epoch 675/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0293 - acc: 0.9891 - val_loss: 0.4784 - val_acc: 0.9199\n",
            "Epoch 676/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0316 - acc: 0.9907 - val_loss: 0.4654 - val_acc: 0.9205\n",
            "Epoch 677/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0271 - acc: 0.9891 - val_loss: 0.4600 - val_acc: 0.9192\n",
            "Epoch 678/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0324 - acc: 0.9882 - val_loss: 0.4779 - val_acc: 0.9136\n",
            "Epoch 679/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0299 - acc: 0.9897 - val_loss: 0.4729 - val_acc: 0.9199\n",
            "Epoch 680/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0264 - acc: 0.9907 - val_loss: 0.4849 - val_acc: 0.9224\n",
            "Epoch 681/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0276 - acc: 0.9901 - val_loss: 0.4776 - val_acc: 0.9211\n",
            "Epoch 682/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0315 - acc: 0.9863 - val_loss: 0.4810 - val_acc: 0.9186\n",
            "Epoch 683/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0269 - acc: 0.9913 - val_loss: 0.4958 - val_acc: 0.9199\n",
            "Epoch 684/800\n",
            "3217/3217 [==============================] - 0s 108us/step - loss: 0.0289 - acc: 0.9888 - val_loss: 0.4794 - val_acc: 0.9218\n",
            "Epoch 685/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0287 - acc: 0.9897 - val_loss: 0.4909 - val_acc: 0.9218\n",
            "Epoch 686/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0368 - acc: 0.9891 - val_loss: 0.4675 - val_acc: 0.9205\n",
            "Epoch 687/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0267 - acc: 0.9919 - val_loss: 0.4950 - val_acc: 0.9186\n",
            "Epoch 688/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0286 - acc: 0.9910 - val_loss: 0.4978 - val_acc: 0.9211\n",
            "Epoch 689/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0267 - acc: 0.9916 - val_loss: 0.4917 - val_acc: 0.9224\n",
            "Epoch 690/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0299 - acc: 0.9888 - val_loss: 0.4907 - val_acc: 0.9180\n",
            "Epoch 691/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0329 - acc: 0.9882 - val_loss: 0.5022 - val_acc: 0.9174\n",
            "Epoch 692/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0246 - acc: 0.9922 - val_loss: 0.4913 - val_acc: 0.9205\n",
            "Epoch 693/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0262 - acc: 0.9897 - val_loss: 0.4946 - val_acc: 0.9192\n",
            "Epoch 694/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0297 - acc: 0.9901 - val_loss: 0.4724 - val_acc: 0.9224\n",
            "Epoch 695/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0257 - acc: 0.9907 - val_loss: 0.4758 - val_acc: 0.9211\n",
            "Epoch 696/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0300 - acc: 0.9894 - val_loss: 0.4872 - val_acc: 0.9186\n",
            "Epoch 697/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0296 - acc: 0.9891 - val_loss: 0.4483 - val_acc: 0.9180\n",
            "Epoch 698/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0328 - acc: 0.9891 - val_loss: 0.4748 - val_acc: 0.9167\n",
            "Epoch 699/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0286 - acc: 0.9901 - val_loss: 0.4991 - val_acc: 0.9192\n",
            "Epoch 700/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0277 - acc: 0.9894 - val_loss: 0.4861 - val_acc: 0.9174\n",
            "Epoch 701/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0263 - acc: 0.9907 - val_loss: 0.4944 - val_acc: 0.9192\n",
            "Epoch 702/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0284 - acc: 0.9910 - val_loss: 0.4905 - val_acc: 0.9192\n",
            "Epoch 703/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0292 - acc: 0.9866 - val_loss: 0.4882 - val_acc: 0.9224\n",
            "Epoch 704/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0247 - acc: 0.9904 - val_loss: 0.4980 - val_acc: 0.9192\n",
            "Epoch 705/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0283 - acc: 0.9904 - val_loss: 0.4879 - val_acc: 0.9186\n",
            "Epoch 706/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0338 - acc: 0.9876 - val_loss: 0.5026 - val_acc: 0.9155\n",
            "Epoch 707/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0255 - acc: 0.9907 - val_loss: 0.5133 - val_acc: 0.9199\n",
            "Epoch 708/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0337 - acc: 0.9891 - val_loss: 0.4821 - val_acc: 0.9136\n",
            "Epoch 709/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0302 - acc: 0.9897 - val_loss: 0.4831 - val_acc: 0.9148\n",
            "Epoch 710/800\n",
            "3217/3217 [==============================] - 0s 107us/step - loss: 0.0264 - acc: 0.9891 - val_loss: 0.4939 - val_acc: 0.9148\n",
            "Epoch 711/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0274 - acc: 0.9885 - val_loss: 0.5117 - val_acc: 0.9142\n",
            "Epoch 712/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0310 - acc: 0.9891 - val_loss: 0.4979 - val_acc: 0.9211\n",
            "Epoch 713/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0244 - acc: 0.9910 - val_loss: 0.4722 - val_acc: 0.9180\n",
            "Epoch 714/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0248 - acc: 0.9891 - val_loss: 0.4812 - val_acc: 0.9186\n",
            "Epoch 715/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0325 - acc: 0.9894 - val_loss: 0.4874 - val_acc: 0.9218\n",
            "Epoch 716/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0337 - acc: 0.9891 - val_loss: 0.4930 - val_acc: 0.9174\n",
            "Epoch 717/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0299 - acc: 0.9919 - val_loss: 0.4924 - val_acc: 0.9211\n",
            "Epoch 718/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0318 - acc: 0.9882 - val_loss: 0.4993 - val_acc: 0.9186\n",
            "Epoch 719/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0247 - acc: 0.9891 - val_loss: 0.5019 - val_acc: 0.9180\n",
            "Epoch 720/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0268 - acc: 0.9894 - val_loss: 0.4940 - val_acc: 0.9142\n",
            "Epoch 721/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0264 - acc: 0.9907 - val_loss: 0.5258 - val_acc: 0.9167\n",
            "Epoch 722/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0244 - acc: 0.9916 - val_loss: 0.5036 - val_acc: 0.9186\n",
            "Epoch 723/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0306 - acc: 0.9879 - val_loss: 0.4839 - val_acc: 0.9237\n",
            "Epoch 724/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0295 - acc: 0.9882 - val_loss: 0.4936 - val_acc: 0.9199\n",
            "Epoch 725/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0282 - acc: 0.9916 - val_loss: 0.4963 - val_acc: 0.9167\n",
            "Epoch 726/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0251 - acc: 0.9901 - val_loss: 0.5192 - val_acc: 0.9148\n",
            "Epoch 727/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0266 - acc: 0.9922 - val_loss: 0.5216 - val_acc: 0.9211\n",
            "Epoch 728/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0207 - acc: 0.9925 - val_loss: 0.5092 - val_acc: 0.9186\n",
            "Epoch 729/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0224 - acc: 0.9925 - val_loss: 0.5110 - val_acc: 0.9211\n",
            "Epoch 730/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0252 - acc: 0.9910 - val_loss: 0.5066 - val_acc: 0.9192\n",
            "Epoch 731/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0304 - acc: 0.9904 - val_loss: 0.4828 - val_acc: 0.9167\n",
            "Epoch 732/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0238 - acc: 0.9919 - val_loss: 0.4962 - val_acc: 0.9161\n",
            "Epoch 733/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0333 - acc: 0.9869 - val_loss: 0.4991 - val_acc: 0.9180\n",
            "Epoch 734/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0256 - acc: 0.9904 - val_loss: 0.5035 - val_acc: 0.9205\n",
            "Epoch 735/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0367 - acc: 0.9876 - val_loss: 0.5068 - val_acc: 0.9155\n",
            "Epoch 736/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0282 - acc: 0.9907 - val_loss: 0.5186 - val_acc: 0.9161\n",
            "Epoch 737/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0319 - acc: 0.9885 - val_loss: 0.4998 - val_acc: 0.9142\n",
            "Epoch 738/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0307 - acc: 0.9879 - val_loss: 0.4798 - val_acc: 0.9180\n",
            "Epoch 739/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0253 - acc: 0.9910 - val_loss: 0.5127 - val_acc: 0.9136\n",
            "Epoch 740/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0239 - acc: 0.9904 - val_loss: 0.5178 - val_acc: 0.9186\n",
            "Epoch 741/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0296 - acc: 0.9885 - val_loss: 0.5027 - val_acc: 0.9205\n",
            "Epoch 742/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0358 - acc: 0.9901 - val_loss: 0.5123 - val_acc: 0.9186\n",
            "Epoch 743/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0202 - acc: 0.9925 - val_loss: 0.4858 - val_acc: 0.9224\n",
            "Epoch 744/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0246 - acc: 0.9916 - val_loss: 0.5011 - val_acc: 0.9167\n",
            "Epoch 745/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0283 - acc: 0.9910 - val_loss: 0.5037 - val_acc: 0.9199\n",
            "Epoch 746/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0219 - acc: 0.9925 - val_loss: 0.4992 - val_acc: 0.9211\n",
            "Epoch 747/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0231 - acc: 0.9894 - val_loss: 0.4986 - val_acc: 0.9230\n",
            "Epoch 748/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0317 - acc: 0.9888 - val_loss: 0.5005 - val_acc: 0.9186\n",
            "Epoch 749/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0247 - acc: 0.9916 - val_loss: 0.4943 - val_acc: 0.9192\n",
            "Epoch 750/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0271 - acc: 0.9891 - val_loss: 0.4938 - val_acc: 0.9230\n",
            "Epoch 751/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0263 - acc: 0.9876 - val_loss: 0.4831 - val_acc: 0.9237\n",
            "Epoch 752/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0329 - acc: 0.9873 - val_loss: 0.4924 - val_acc: 0.9199\n",
            "Epoch 753/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0325 - acc: 0.9888 - val_loss: 0.5036 - val_acc: 0.9192\n",
            "Epoch 754/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0233 - acc: 0.9897 - val_loss: 0.4971 - val_acc: 0.9224\n",
            "Epoch 755/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0274 - acc: 0.9907 - val_loss: 0.5147 - val_acc: 0.9218\n",
            "Epoch 756/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0225 - acc: 0.9916 - val_loss: 0.5195 - val_acc: 0.9186\n",
            "Epoch 757/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0326 - acc: 0.9869 - val_loss: 0.4884 - val_acc: 0.9180\n",
            "Epoch 758/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0239 - acc: 0.9913 - val_loss: 0.5134 - val_acc: 0.9167\n",
            "Epoch 759/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0300 - acc: 0.9916 - val_loss: 0.4904 - val_acc: 0.9186\n",
            "Epoch 760/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0240 - acc: 0.9913 - val_loss: 0.5044 - val_acc: 0.9174\n",
            "Epoch 761/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0293 - acc: 0.9894 - val_loss: 0.5037 - val_acc: 0.9186\n",
            "Epoch 762/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0248 - acc: 0.9904 - val_loss: 0.5122 - val_acc: 0.9186\n",
            "Epoch 763/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0276 - acc: 0.9888 - val_loss: 0.5024 - val_acc: 0.9224\n",
            "Epoch 764/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0234 - acc: 0.9904 - val_loss: 0.5170 - val_acc: 0.9205\n",
            "Epoch 765/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0222 - acc: 0.9932 - val_loss: 0.4950 - val_acc: 0.9224\n",
            "Epoch 766/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0306 - acc: 0.9901 - val_loss: 0.5012 - val_acc: 0.9218\n",
            "Epoch 767/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0244 - acc: 0.9904 - val_loss: 0.5068 - val_acc: 0.9224\n",
            "Epoch 768/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0241 - acc: 0.9919 - val_loss: 0.5153 - val_acc: 0.9186\n",
            "Epoch 769/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0277 - acc: 0.9882 - val_loss: 0.5192 - val_acc: 0.9192\n",
            "Epoch 770/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0190 - acc: 0.9913 - val_loss: 0.5294 - val_acc: 0.9205\n",
            "Epoch 771/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0298 - acc: 0.9904 - val_loss: 0.5101 - val_acc: 0.9180\n",
            "Epoch 772/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0246 - acc: 0.9888 - val_loss: 0.5233 - val_acc: 0.9218\n",
            "Epoch 773/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0259 - acc: 0.9897 - val_loss: 0.4995 - val_acc: 0.9211\n",
            "Epoch 774/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0287 - acc: 0.9913 - val_loss: 0.5085 - val_acc: 0.9205\n",
            "Epoch 775/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0234 - acc: 0.9922 - val_loss: 0.5071 - val_acc: 0.9167\n",
            "Epoch 776/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0225 - acc: 0.9907 - val_loss: 0.5055 - val_acc: 0.9167\n",
            "Epoch 777/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0298 - acc: 0.9897 - val_loss: 0.5212 - val_acc: 0.9148\n",
            "Epoch 778/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0180 - acc: 0.9925 - val_loss: 0.5296 - val_acc: 0.9155\n",
            "Epoch 779/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0290 - acc: 0.9876 - val_loss: 0.5024 - val_acc: 0.9174\n",
            "Epoch 780/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0252 - acc: 0.9904 - val_loss: 0.5516 - val_acc: 0.9174\n",
            "Epoch 781/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0271 - acc: 0.9901 - val_loss: 0.5478 - val_acc: 0.9186\n",
            "Epoch 782/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0283 - acc: 0.9904 - val_loss: 0.5347 - val_acc: 0.9192\n",
            "Epoch 783/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0231 - acc: 0.9916 - val_loss: 0.5097 - val_acc: 0.9199\n",
            "Epoch 784/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0264 - acc: 0.9913 - val_loss: 0.5039 - val_acc: 0.9224\n",
            "Epoch 785/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0185 - acc: 0.9932 - val_loss: 0.5191 - val_acc: 0.9224\n",
            "Epoch 786/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0286 - acc: 0.9922 - val_loss: 0.4985 - val_acc: 0.9249\n",
            "Epoch 787/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0214 - acc: 0.9932 - val_loss: 0.4974 - val_acc: 0.9211\n",
            "Epoch 788/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0288 - acc: 0.9882 - val_loss: 0.5114 - val_acc: 0.9199\n",
            "Epoch 789/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0238 - acc: 0.9907 - val_loss: 0.4973 - val_acc: 0.9205\n",
            "Epoch 790/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0210 - acc: 0.9925 - val_loss: 0.5316 - val_acc: 0.9211\n",
            "Epoch 791/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0377 - acc: 0.9873 - val_loss: 0.5038 - val_acc: 0.9192\n",
            "Epoch 792/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0252 - acc: 0.9922 - val_loss: 0.5276 - val_acc: 0.9192\n",
            "Epoch 793/800\n",
            "3217/3217 [==============================] - 0s 102us/step - loss: 0.0296 - acc: 0.9869 - val_loss: 0.4983 - val_acc: 0.9186\n",
            "Epoch 794/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0262 - acc: 0.9913 - val_loss: 0.5035 - val_acc: 0.9180\n",
            "Epoch 795/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0267 - acc: 0.9907 - val_loss: 0.5141 - val_acc: 0.9180\n",
            "Epoch 796/800\n",
            "3217/3217 [==============================] - 0s 106us/step - loss: 0.0252 - acc: 0.9907 - val_loss: 0.4797 - val_acc: 0.9161\n",
            "Epoch 797/800\n",
            "3217/3217 [==============================] - 0s 103us/step - loss: 0.0228 - acc: 0.9901 - val_loss: 0.4865 - val_acc: 0.9211\n",
            "Epoch 798/800\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0293 - acc: 0.9907 - val_loss: 0.4796 - val_acc: 0.9167\n",
            "Epoch 799/800\n",
            "3217/3217 [==============================] - 0s 101us/step - loss: 0.0248 - acc: 0.9932 - val_loss: 0.5058 - val_acc: 0.9117\n",
            "Epoch 800/800\n",
            "3217/3217 [==============================] - 0s 104us/step - loss: 0.0188 - acc: 0.9932 - val_loss: 0.4906 - val_acc: 0.9174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f11092720f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "TDXshp-FZlJc",
        "colab_type": "code",
        "outputId": "4f0fd7fd-2ef9-4934-868a-87c9b7977773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "testScore = model.evaluate(testX, dummy_test_y, verbose = 0)\n",
        "print('Model loss = ', testScore[0])\n",
        "print('Model accuracy = ', testScore[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loss =  0.49057236880722105\n",
            "Model accuracy =  0.9173501577663121\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}